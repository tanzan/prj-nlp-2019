{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "Спочатку завантажуємо вектори ConceptNet Numberbutch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl https://conceptnet.s3.amazonaws.com/downloads/2017/numberbatch/numberbatch-en-17.06.txt.gz --output numberbatch-en-17.06.txt.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gunzip numberbatch-en-17.06.txt.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "numberbatch = KeyedVectors.load_word2vec_format(\"numberbatch-en-17.06.txt\", binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('2nd', 0.8383364677429199),\n",
       " ('3rd', 0.7933375835418701),\n",
       " ('4th', 0.763849139213562),\n",
       " ('first', 0.7570372819900513),\n",
       " ('5th', 0.7545791864395142),\n",
       " ('6th', 0.7477511167526245),\n",
       " ('7th', 0.7396888732910156),\n",
       " ('8th', 0.7219843864440918),\n",
       " ('9th', 0.6965588331222534),\n",
       " ('oneth', 0.6686497926712036)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numberbatch.most_similar(['1st'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Потім парсимо тренувальні і тестові датасети."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "Phrase = namedtuple('Phrase', 'original candidate label')\n",
    "Token = namedtuple('Token', 'text tags')\n",
    "\n",
    "def split_tokens(sent):\n",
    "    tokens = []\n",
    "    for token in sent.split():\n",
    "        tags = token.split('/')\n",
    "        tokens.append(Token(tags[0].lower(), tuple(tags[1:])))\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def readData(filename, eval_label, ignoreNone):\n",
    "    data = []\n",
    "    with open(filename) as f:\n",
    "        for line in f:\n",
    "            fields = line.strip().split('\\t')\n",
    "            if len(fields) == 7:\n",
    "                (trendid, trendname, origsent, candsent, judge, origsenttag, candsenttag) = fields\n",
    "            else:\n",
    "                continue\n",
    "            label = eval_label(judge)\n",
    "            if ((label is None) and ignoreNone):\n",
    "                continue\n",
    "            data.append(Phrase(split_tokens(origsenttag), split_tokens(candsenttag), label))\n",
    "    \n",
    "    return data\n",
    "                \n",
    "def eval_amt_label(label):\n",
    "    nYes = eval(label)[0]            \n",
    "    \n",
    "    if nYes >= 3:\n",
    "        return True\n",
    "    elif nYes <= 1:\n",
    "        return False\n",
    "    \n",
    "    return None\n",
    "\n",
    "def eval_expert_label(label):\n",
    "    nYes = int(label[0])\n",
    "    \n",
    "    if nYes >= 4:\n",
    "        return True\n",
    "    elif nYes <= 2:\n",
    "        return False\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def readTrainData(filename):\n",
    "    return readData(filename, eval_amt_label, True)\n",
    "\n",
    "def readTestData(filename):\n",
    "    return readData(filename, eval_expert_label, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = readTrainData(\"SemEval-PIT2015-py3/data/train.data\")\n",
    "dev_data = readTrainData(\"SemEval-PIT2015-py3/data/dev.data\")\n",
    "test_data = [p for p in readTestData(\"SemEval-PIT2015-py3/data/test.data\") if p.label is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Phrase(original=[Token(text='ej', tags=('B-person', 'NNP', 'B-NP', 'O')), Token(text='manuel', tags=('I-person', 'NNP', 'B-VP', 'O')), Token(text='the', tags=('O', 'DT', 'B-NP', 'O')), Token(text='1st', tags=('O', 'CD', 'I-NP', 'O')), Token(text='qb', tags=('O', 'NNP', 'I-NP', 'O')), Token(text='to', tags=('O', 'TO', 'B-VP', 'O')), Token(text='go', tags=('O', 'VB', 'I-VP', 'B-EVENT')), Token(text='in', tags=('O', 'IN', 'B-PP', 'I-EVENT')), Token(text='this', tags=('O', 'DT', 'B-NP', 'O')), Token(text='draft', tags=('O', 'NN', 'I-NP', 'O'))], candidate=[Token(text='but', tags=('O', 'CC', 'O', 'O')), Token(text='my', tags=('O', 'PRP$', 'B-NP', 'O')), Token(text='bro', tags=('O', 'NN', 'I-NP', 'O')), Token(text='from', tags=('O', 'IN', 'B-PP', 'O')), Token(text='the', tags=('O', 'DT', 'B-NP', 'O')), Token(text='757', tags=('O', 'CD', 'I-NP', 'O')), Token(text='ej', tags=('B-person', 'NNP', 'I-NP', 'O')), Token(text='manuel', tags=('I-person', 'NNP', 'I-NP', 'O')), Token(text='is', tags=('O', 'VBZ', 'B-VP', 'O')), Token(text='the', tags=('O', 'DT', 'B-NP', 'O')), Token(text='1st', tags=('O', 'CD', 'I-NP', 'O')), Token(text='qb', tags=('O', 'NNP', 'I-NP', 'O')), Token(text='gone', tags=('O', 'NN', 'I-NP', 'O'))], label=True),\n",
       " Phrase(original=[Token(text='ej', tags=('B-person', 'NNP', 'B-NP', 'O')), Token(text='manuel', tags=('I-person', 'NNP', 'B-VP', 'O')), Token(text='the', tags=('O', 'DT', 'B-NP', 'O')), Token(text='1st', tags=('O', 'CD', 'I-NP', 'O')), Token(text='qb', tags=('O', 'NNP', 'I-NP', 'O')), Token(text='to', tags=('O', 'TO', 'B-VP', 'O')), Token(text='go', tags=('O', 'VB', 'I-VP', 'B-EVENT')), Token(text='in', tags=('O', 'IN', 'B-PP', 'I-EVENT')), Token(text='this', tags=('O', 'DT', 'B-NP', 'O')), Token(text='draft', tags=('O', 'NN', 'I-NP', 'O'))], candidate=[Token(text='can', tags=('O', 'MD', 'B-VP', 'O')), Token(text='believe', tags=('O', 'VB', 'I-VP', 'B-EVENT')), Token(text='ej', tags=('B-person', 'NNP', 'B-NP', 'O')), Token(text='manuel', tags=('I-person', 'NNP', 'I-NP', 'O')), Token(text='went', tags=('O', 'VBD', 'B-VP', 'O')), Token(text='as', tags=('O', 'IN', 'B-PP', 'O')), Token(text='the', tags=('O', 'DT', 'B-NP', 'O')), Token(text='1st', tags=('O', 'CD', 'I-NP', 'O')), Token(text='qb', tags=('O', 'NNP', 'I-NP', 'O')), Token(text='in', tags=('O', 'IN', 'B-PP', 'O')), Token(text='the', tags=('O', 'DT', 'B-NP', 'O')), Token(text='draft', tags=('O', 'NN', 'I-NP', 'O'))], label=True),\n",
       " Phrase(original=[Token(text='ej', tags=('B-person', 'NNP', 'B-NP', 'O')), Token(text='manuel', tags=('I-person', 'NNP', 'B-VP', 'O')), Token(text='the', tags=('O', 'DT', 'B-NP', 'O')), Token(text='1st', tags=('O', 'CD', 'I-NP', 'O')), Token(text='qb', tags=('O', 'NNP', 'I-NP', 'O')), Token(text='to', tags=('O', 'TO', 'B-VP', 'O')), Token(text='go', tags=('O', 'VB', 'I-VP', 'B-EVENT')), Token(text='in', tags=('O', 'IN', 'B-PP', 'I-EVENT')), Token(text='this', tags=('O', 'DT', 'B-NP', 'O')), Token(text='draft', tags=('O', 'NN', 'I-NP', 'O'))], candidate=[Token(text='ej', tags=('B-person', 'NNP', 'B-NP', 'O')), Token(text='manuel', tags=('I-person', 'NNP', 'I-NP', 'O')), Token(text='is', tags=('O', 'VBZ', 'B-VP', 'O')), Token(text='the', tags=('O', 'DT', 'B-NP', 'O')), Token(text='1st', tags=('O', 'CD', 'I-NP', 'O')), Token(text='qb', tags=('O', 'NNP', 'I-NP', 'O')), Token(text='what', tags=('O', 'WP', 'I-NP', 'O'))], label=True)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Phrase(original=[Token(text='all', tags=('O', 'DT', 'B-NP', 'O')), Token(text='the', tags=('O', 'DT', 'I-NP', 'O')), Token(text='home', tags=('O', 'NN', 'I-NP', 'O')), Token(text='alones', tags=('O', 'VBZ', 'B-VP', 'O')), Token(text='watching', tags=('O', 'VBG', 'I-VP', 'B-EVENT')), Token(text='8', tags=('O', 'CD', 'B-NP', 'O')), Token(text='mile', tags=('O', 'NN', 'I-NP', 'O'))], candidate=[Token(text='the', tags=('O', 'DT', 'B-NP', 'O')), Token(text='last', tags=('O', 'JJ', 'I-NP', 'O')), Token(text='rap', tags=('O', 'NN', 'I-NP', 'B-EVENT')), Token(text='battle', tags=('O', 'NN', 'I-NP', 'B-EVENT')), Token(text='in', tags=('O', 'IN', 'B-PP', 'O')), Token(text='8', tags=('O', 'CD', 'B-NP', 'O')), Token(text='mile', tags=('O', 'NNP', 'I-NP', 'O')), Token(text='nevr', tags=('O', 'NN', 'I-NP', 'O')), Token(text='gets', tags=('O', 'VBZ', 'B-VP', 'O')), Token(text='old', tags=('O', 'JJ', 'B-NP', 'O')), Token(text='ahah', tags=('O', 'JJ', 'I-NP', 'O'))], label=False),\n",
       " Phrase(original=[Token(text='all', tags=('O', 'DT', 'B-NP', 'O')), Token(text='the', tags=('O', 'DT', 'I-NP', 'O')), Token(text='home', tags=('O', 'NN', 'I-NP', 'O')), Token(text='alones', tags=('O', 'VBZ', 'B-VP', 'O')), Token(text='watching', tags=('O', 'VBG', 'I-VP', 'B-EVENT')), Token(text='8', tags=('O', 'CD', 'B-NP', 'O')), Token(text='mile', tags=('O', 'NN', 'I-NP', 'O'))], candidate=[Token(text='the', tags=('O', 'DT', 'B-NP', 'O')), Token(text='rap', tags=('O', 'NN', 'I-NP', 'O')), Token(text='battle', tags=('O', 'NN', 'I-NP', 'B-EVENT')), Token(text='at', tags=('O', 'IN', 'B-PP', 'O')), Token(text='the', tags=('O', 'DT', 'B-NP', 'O')), Token(text='end', tags=('O', 'NN', 'I-NP', 'O')), Token(text='of', tags=('O', 'IN', 'B-PP', 'O')), Token(text='8', tags=('O', 'CD', 'B-NP', 'O')), Token(text='mile', tags=('O', 'NN', 'I-NP', 'O')), Token(text='gets', tags=('O', 'VBZ', 'B-VP', 'O')), Token(text='me', tags=('O', 'PRP', 'B-NP', 'O')), Token(text='so', tags=('O', 'RB', 'B-ADVP', 'O')), Token(text='hype', tags=('O', 'JJ', 'I-ADVP', 'O'))], label=False),\n",
       " Phrase(original=[Token(text='the', tags=('O', 'DT', 'B-NP', 'O')), Token(text='ending', tags=('O', 'VBG', 'I-NP', 'B-EVENT')), Token(text='to', tags=('O', 'TO', 'I-NP', 'O')), Token(text='8', tags=('O', 'CD', 'I-NP', 'O')), Token(text='mile', tags=('O', 'NNP', 'I-NP', 'O')), Token(text='is', tags=('O', 'VBZ', 'B-VP', 'O')), Token(text='my', tags=('O', 'PRP$', 'B-NP', 'O')), Token(text='fav', tags=('O', 'JJ', 'I-NP', 'O')), Token(text='part', tags=('O', 'NN', 'I-NP', 'O')), Token(text='of', tags=('O', 'IN', 'B-PP', 'O')), Token(text='the', tags=('O', 'DT', 'B-NP', 'O')), Token(text='whole', tags=('O', 'JJ', 'I-NP', 'O')), Token(text='movie', tags=('O', 'NN', 'I-NP', 'B-EVENT'))], candidate=[Token(text='rabbit', tags=('O', 'NNP', 'B-NP', 'O')), Token(text='on', tags=('O', 'IN', 'B-PP', 'O')), Token(text='8', tags=('O', 'CD', 'B-NP', 'O')), Token(text='mile', tags=('O', 'NN', 'I-NP', 'O')), Token(text='out', tags=('O', 'IN', 'B-PP', 'O')), Token(text='of', tags=('O', 'IN', 'B-PP', 'O')), Token(text='place', tags=('O', 'NN', 'B-NP', 'O')), Token(text='but', tags=('O', 'CC', 'O', 'O')), Token(text='determined', tags=('O', 'VBD', 'B-VP', 'B-EVENT')), Token(text='to', tags=('O', 'TO', 'I-VP', 'O')), Token(text='make', tags=('O', 'VB', 'I-VP', 'O')), Token(text='it', tags=('O', 'PRP', 'B-NP', 'O'))], label=False)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Робимо обробку данних - видаляємо стоп-слова та замінюємо іменовані сутності на більш генералізовані поняття."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "stops = stopwords.words('english')\n",
    "\n",
    "def clean_sent(sent):\n",
    "    new_sent = []\n",
    "    for token in sent:\n",
    "        if token.tags[0].startswith('B-'):\n",
    "            new_sent.append(token.tags[0].split('-')[1])\n",
    "            continue\n",
    "        if token.tags[0].startswith('I-') or token.text in stops:\n",
    "            continue\n",
    "        new_sent.append(token.text)\n",
    "                            \n",
    "    return new_sent\n",
    "\n",
    "def clean_data(data):\n",
    "    return [Phrase(clean_sent(phrase.original), clean_sent(phrase.candidate), phrase.label) \\\n",
    "            for phrase in tqdm_notebook(data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb0ecc042a9949b78e9a259f2659de3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=11530), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "clean_train_data = clean_data(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72339c6e98b14b05bd28674f6a0db6da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4142), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "clean_dev_data = clean_data(dev_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8841e19081f74e109cfe6146ebb36687",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=838), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "clean_test_data = clean_data(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Phrase(original=['person', '1st', 'qb', 'go', 'draft'], candidate=['bro', '757', 'person', '1st', 'qb', 'gone'], label=True),\n",
       " Phrase(original=['person', '1st', 'qb', 'go', 'draft'], candidate=['believe', 'person', 'went', '1st', 'qb', 'draft'], label=True),\n",
       " Phrase(original=['person', '1st', 'qb', 'go', 'draft'], candidate=['person', '1st', 'qb'], label=True)]"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_train_data[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Phrase(original=['walk', 'remember', 'definition', 'true', 'love'], candidate=['walk', 'remember', 'im', 'town', 'im', 'upset'], label=False),\n",
       " Phrase(original=['walk', 'remember', 'definition', 'true', 'love'], candidate=['walk', 'remember', 'cutest', 'thing'], label=True),\n",
       " Phrase(original=['walk', 'remember', 'definition', 'true', 'love'], candidate=['walk', 'remember', 'other', 'family', 'youre', 'welcome'], label=False)]"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_dev_data[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "Ідея заключається в тому щоб попрацювати з нейромережами. Спочатку підготуємо для цього дані і зробимо векторизацію тексту."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9060"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "\n",
    "def phrase_tokens(phrase):\n",
    "    return [token for token in (phrase.original + phrase.candidate)]\n",
    "    \n",
    "\n",
    "vocab = Dictionary([phrase_tokens(p) for p in clean_train_data + clean_dev_data + clean_test_data])\n",
    "\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9061\n"
     ]
    }
   ],
   "source": [
    "VOCAB_SIZE = len(vocab) + 1 # +1 for padding\n",
    "\n",
    "print(VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2token = dict([(i, token)for token, i in vocab.token2id.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_sequence(words):\n",
    "    return [i + 1 for i in vocab.doc2idx(words)]\n",
    "\n",
    "def sequence_to_text(seq):\n",
    "    return [id2token[i - 1] for i in seq if i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11530\n",
      "11530\n",
      "11530\n"
     ]
    }
   ],
   "source": [
    "def data_to_sequences(data):\n",
    "    \n",
    "    encoder_seqs = []\n",
    "    decoder_seqs = []\n",
    "    labels = []\n",
    "    \n",
    "    for phrase in data:\n",
    "        encoder_seqs.append(text_to_sequence([t for t in phrase.original]))\n",
    "        decoder_seqs.append(text_to_sequence([t for t in phrase.candidate]))\n",
    "        labels.append(phrase.label)\n",
    "        \n",
    "    return encoder_seqs, decoder_seqs, labels \n",
    "\n",
    "train_encoder_seqs, train_decoder_seqs, train_labels = data_to_sequences(clean_train_data)\n",
    "\n",
    "print(len(train_encoder_seqs))\n",
    "print(len(train_decoder_seqs))\n",
    "print(len(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['person', '1st', 'qb', 'go', 'draft']\n",
      "['bro', '757', 'person', '1st', 'qb', 'gone']\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(sequence_to_text(train_encoder_seqs[0]))\n",
    "print(sequence_to_text(train_decoder_seqs[0]))\n",
    "print(train_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_encoder_seqs, dev_decoder_seqs, dev_labels = data_to_sequences(clean_dev_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_encoder_seqs, test_decoder_seqs, test_labels = data_to_sequences(clean_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "MAX_SEQ_LEN = max([len(seq) for seq in (train_encoder_seqs + train_decoder_seqs + \\\n",
    "                                       dev_encoder_seqs + dev_decoder_seqs + \\\n",
    "                                       test_decoder_seqs + test_encoder_seqs)])\n",
    "\n",
    "print(MAX_SEQ_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def padding(sequences):\n",
    "    return pad_sequences(sequences, maxlen=MAX_SEQ_LEN, dtype='int32', padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "EMBEDDING_SIZE = 300\n",
    "\n",
    "EMBEDDING_MATRIX = np.zeros((VOCAB_SIZE, EMBEDDING_SIZE))\n",
    "  \n",
    "for word, i in vocab.token2id.items():\n",
    "    try:\n",
    "        EMBEDDING_MATRIX[i] = numberbatch[word]\n",
    "    except KeyError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Готуємо базовий клас для подальших моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, LSTM, Embedding, Dense\n",
    "from keras.models import Model\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "class SemevalModel:\n",
    "    def __init__(self, left_seqs, right_seqs, labels):\n",
    "        self.left_seqs = left_seqs\n",
    "        self.right_seqs = right_seqs\n",
    "        self.labels = labels\n",
    "        \n",
    "    def train(self, val_left_seqs, val_right_seqs, val_labels, batch_size, epochs):\n",
    "        self.history = self.model.fit([self.left_seqs, self.right_seqs],\n",
    "                                      self.labels, batch_size = batch_size, epochs = epochs, \n",
    "                                      validation_data = ([val_left_seqs, val_right_seqs], val_labels))\n",
    "    \n",
    "    def test(self, test_left_seqs, test_right_seqs, test_labels):\n",
    "        predicted_similarity = self.model.predict([test_left_seqs, test_right_seqs])\n",
    "        predicted_labels = [p.item() > 0.5 for p in predicted_similarity]\n",
    "        report = classification_report(test_labels, predicted_labels, output_dict = True)\n",
    "        report['accuracy'] = accuracy_score(test_labels, predicted_labels)\n",
    "        return predicted_labels, predicted_similarity, report\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seq2Seq\n",
    "\n",
    "Ідея цієї моделі інспірована autoencoder архітектурою. Цікаво як вона буде працювати на нашій задачі."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import RMSprop\n",
    "\n",
    "embedding_layer = Embedding(input_dim = VOCAB_SIZE, \n",
    "                            output_dim = EMBEDDING_SIZE,\n",
    "                            input_length = MAX_SEQ_LEN,\n",
    "                            weights = [EMBEDDING_MATRIX], trainable = False)\n",
    "\n",
    "class Seq2SeqModel(SemevalModel):\n",
    "    def __init__(self, left_seqs, right_seqs, labels):\n",
    "        super().__init__(left_seqs, right_seqs, labels)\n",
    "        hidden_dim = 300\n",
    "\n",
    "        encoder_inputs = Input(shape=(MAX_SEQ_LEN, ), dtype='int32',)\n",
    "        encoder_embedding = embedding_layer(encoder_inputs)\n",
    "        encoder_LSTM = LSTM(hidden_dim, return_state=True)\n",
    "        encoder_outputs, state_h, state_c = encoder_LSTM(encoder_embedding)\n",
    "    \n",
    "        decoder_inputs = Input(shape=(MAX_SEQ_LEN, ), dtype='int32',)\n",
    "        decoder_embedding = embedding_layer(decoder_inputs)\n",
    "        decoder_LSTM = LSTM(hidden_dim, return_state=True)\n",
    "        decoder_outputs, _, _ = decoder_LSTM(decoder_embedding, initial_state=[state_h, state_c])\n",
    "    \n",
    "        outputs = Dense(1, activation='sigmoid')(decoder_outputs)\n",
    "        self.model = Model([encoder_inputs, decoder_inputs], outputs)\n",
    "        self.model.compile(optimizer=RMSprop(lr=5e-5), loss='binary_crossentropy', metrics=['acc'])\n",
    "        self.model.summary()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            (None, 13)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            (None, 13)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 13, 300)      2718300     input_5[0][0]                    \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_5 (LSTM)                   [(None, 300), (None, 721200      embedding_1[4][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_6 (LSTM)                   [(None, 300), (None, 721200      embedding_1[5][0]                \n",
      "                                                                 lstm_5[0][1]                     \n",
      "                                                                 lstm_5[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            301         lstm_6[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 4,161,001\n",
      "Trainable params: 1,442,701\n",
      "Non-trainable params: 2,718,300\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "seq2seq = Seq2SeqModel(padding(train_encoder_seqs), padding(train_decoder_seqs), train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11530 samples, validate on 4142 samples\n",
      "Epoch 1/4\n",
      "11530/11530 [==============================] - 9s 741us/step - loss: 0.6432 - acc: 0.6534 - val_loss: 0.6448 - val_acc: 0.6451\n",
      "Epoch 2/4\n",
      "11530/11530 [==============================] - 7s 619us/step - loss: 0.6310 - acc: 0.6537 - val_loss: 0.6344 - val_acc: 0.6451\n",
      "Epoch 3/4\n",
      "11530/11530 [==============================] - 7s 617us/step - loss: 0.6088 - acc: 0.6733 - val_loss: 0.6420 - val_acc: 0.6610\n",
      "Epoch 4/4\n",
      "11530/11530 [==============================] - 7s 616us/step - loss: 0.5910 - acc: 0.6953 - val_loss: 0.6421 - val_acc: 0.6415\n"
     ]
    }
   ],
   "source": [
    "seq2seq.train(padding(dev_decoder_seqs), padding(dev_encoder_seqs), dev_labels, batch_size = 100, epochs = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тільки 4 епохи бо модель швидко оверфітиться. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'False': {'precision': 0.6958099637083471,\n",
       "  'recall': 0.7892964071856288,\n",
       "  'f1-score': 0.7396107311941084,\n",
       "  'support': 2672},\n",
       " 'True': {'precision': 0.49324932493249324,\n",
       "  'recall': 0.3727891156462585,\n",
       "  'f1-score': 0.42464161177838045,\n",
       "  'support': 1470},\n",
       " 'micro avg': {'precision': 0.641477547078706,\n",
       "  'recall': 0.641477547078706,\n",
       "  'f1-score': 0.641477547078706,\n",
       "  'support': 4142},\n",
       " 'macro avg': {'precision': 0.5945296443204202,\n",
       "  'recall': 0.5810427614159437,\n",
       "  'f1-score': 0.5821261714862445,\n",
       "  'support': 4142},\n",
       " 'weighted avg': {'precision': 0.623920987609722,\n",
       "  'recall': 0.641477547078706,\n",
       "  'f1-score': 0.6278278713338669,\n",
       "  'support': 4142},\n",
       " 'accuracy': 0.641477547078706}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, _, seq2seq_report = seq2seq.test(padding(dev_decoder_seqs), padding(dev_encoder_seqs), dev_labels)\n",
    "\n",
    "seq2seq_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'False': {'precision': 0.8237885462555066,\n",
       "  'recall': 0.8461538461538461,\n",
       "  'f1-score': 0.8348214285714285,\n",
       "  'support': 663},\n",
       " 'True': {'precision': 0.3503184713375796,\n",
       "  'recall': 0.3142857142857143,\n",
       "  'f1-score': 0.3313253012048193,\n",
       "  'support': 175},\n",
       " 'micro avg': {'precision': 0.7350835322195705,\n",
       "  'recall': 0.7350835322195705,\n",
       "  'f1-score': 0.7350835322195703,\n",
       "  'support': 838},\n",
       " 'macro avg': {'precision': 0.587053508796543,\n",
       "  'recall': 0.5802197802197802,\n",
       "  'f1-score': 0.5830733648881239,\n",
       "  'support': 838},\n",
       " 'weighted avg': {'precision': 0.7249135306103548,\n",
       "  'recall': 0.7350835322195705,\n",
       "  'f1-score': 0.7296760559113371,\n",
       "  'support': 838},\n",
       " 'accuracy': 0.7350835322195705}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq2seq_test_lablels, seq2seq_test_similarity, seq2seq_test_report = seq2seq.test(padding(test_decoder_seqs),\n",
    "                                                                                  padding(test_encoder_seqs), test_labels)\n",
    "seq2seq_test_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Бачимо ще результати гірше ніж у бейзлайна, якщо дивитися тільки на True клас."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manhattan LSTM\n",
    "\n",
    "Тепер спробуємо архітектуру яка вже використовувалась на подібній задачі https://www.kaggle.com/c/quora-question-pairs. Більш детальний опис можна знайти тут https://medium.com/mlreview/implementing-malstm-on-kaggles-quora-question-pairs-competition-8b31b0b16a07 або в оригіналі https://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/download/12195/12023."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.layers import Lambda\n",
    "from keras.optimizers import Adadelta\n",
    "\n",
    "def exponent_neg_manhattan_distance(left, right):\n",
    "    return K.exp(-K.sum(K.abs(left-right), axis=1, keepdims=True))\n",
    "\n",
    "class MaLstmModel(SemevalModel):\n",
    "    def __init__(self, left_seqs, right_seqs, labels):\n",
    "        super().__init__(left_seqs, right_seqs, labels)\n",
    "    \n",
    "        left_input = Input(shape=(MAX_SEQ_LEN,), dtype='int32')\n",
    "        right_input = Input(shape=(MAX_SEQ_LEN,), dtype='int32')\n",
    "\n",
    "        left_embedding = embedding_layer(left_input)\n",
    "        right_embedding = embedding_layer(right_input)\n",
    "\n",
    "        shared_lstm = LSTM(100)\n",
    "\n",
    "        left_output = shared_lstm(left_embedding)\n",
    "        right_output = shared_lstm(right_embedding)\n",
    "\n",
    "        ma_distance = Lambda(function = lambda x: exponent_neg_manhattan_distance(x[0], x[1]),\n",
    "                             output_shape = lambda x: (x[0][0], 1))([left_output, right_output])\n",
    "\n",
    "        self.model = Model([left_input, right_input], [ma_distance])\n",
    "\n",
    "        self.model.compile(optimizer = Adadelta(clipnorm = 1.25),\n",
    "                           loss='mean_squared_error', metrics=['accuracy'])\n",
    "        self.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_11 (InputLayer)           (None, 13)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_12 (InputLayer)           (None, 13)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 13, 300)      2718300     input_11[0][0]                   \n",
      "                                                                 input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_9 (LSTM)                   (None, 100)          160400      embedding_1[10][0]               \n",
      "                                                                 embedding_1[11][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 1)            0           lstm_9[0][0]                     \n",
      "                                                                 lstm_9[1][0]                     \n",
      "==================================================================================================\n",
      "Total params: 2,878,700\n",
      "Trainable params: 160,400\n",
      "Non-trainable params: 2,718,300\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "malstm = MaLstmModel(padding(train_encoder_seqs), padding(train_decoder_seqs), train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11530 samples, validate on 4142 samples\n",
      "Epoch 1/5\n",
      "11530/11530 [==============================] - 7s 608us/step - loss: 0.2448 - acc: 0.6144 - val_loss: 0.2637 - val_acc: 0.6241\n",
      "Epoch 2/5\n",
      "11530/11530 [==============================] - 5s 448us/step - loss: 0.2054 - acc: 0.6859 - val_loss: 0.2364 - val_acc: 0.6161\n",
      "Epoch 3/5\n",
      "11530/11530 [==============================] - 5s 444us/step - loss: 0.1888 - acc: 0.7140 - val_loss: 0.2312 - val_acc: 0.6265\n",
      "Epoch 4/5\n",
      "11530/11530 [==============================] - 5s 443us/step - loss: 0.1787 - acc: 0.7428 - val_loss: 0.2363 - val_acc: 0.5951\n",
      "Epoch 5/5\n",
      "11530/11530 [==============================] - 5s 445us/step - loss: 0.1706 - acc: 0.7573 - val_loss: 0.2342 - val_acc: 0.6033\n"
     ]
    }
   ],
   "source": [
    "malstm.train(padding(dev_decoder_seqs), padding(dev_encoder_seqs), dev_labels, batch_size = 64, epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'False': {'precision': 0.6793307772743116,\n",
       "  'recall': 0.7294161676646707,\n",
       "  'f1-score': 0.7034831257895687,\n",
       "  'support': 2672},\n",
       " 'True': {'precision': 0.43205027494108406,\n",
       "  'recall': 0.3741496598639456,\n",
       "  'f1-score': 0.4010207801676996,\n",
       "  'support': 1470},\n",
       " 'micro avg': {'precision': 0.6033317238049252,\n",
       "  'recall': 0.6033317238049252,\n",
       "  'f1-score': 0.6033317238049252,\n",
       "  'support': 4142},\n",
       " 'macro avg': {'precision': 0.5556905261076979,\n",
       "  'recall': 0.5517829137643081,\n",
       "  'f1-score': 0.5522519529786342,\n",
       "  'support': 4142},\n",
       " 'weighted avg': {'precision': 0.5915706762531033,\n",
       "  'recall': 0.6033317238049252,\n",
       "  'f1-score': 0.5961389326306726,\n",
       "  'support': 4142},\n",
       " 'accuracy': 0.6033317238049252}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, _, malstm_report = malstm.test(padding(dev_decoder_seqs), padding(dev_encoder_seqs), dev_labels)\n",
    "\n",
    "malstm_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'False': {'precision': 0.8171334431630972,\n",
       "  'recall': 0.7481146304675717,\n",
       "  'f1-score': 0.7811023622047244,\n",
       "  'support': 663},\n",
       " 'True': {'precision': 0.27705627705627706,\n",
       "  'recall': 0.3657142857142857,\n",
       "  'f1-score': 0.31527093596059114,\n",
       "  'support': 175},\n",
       " 'micro avg': {'precision': 0.6682577565632458,\n",
       "  'recall': 0.6682577565632458,\n",
       "  'f1-score': 0.6682577565632458,\n",
       "  'support': 838},\n",
       " 'macro avg': {'precision': 0.5470948601096871,\n",
       "  'recall': 0.5569144580909287,\n",
       "  'f1-score': 0.5481866490826578,\n",
       "  'support': 838},\n",
       " 'weighted avg': {'precision': 0.7043488321026037,\n",
       "  'recall': 0.6682577565632458,\n",
       "  'f1-score': 0.6838225297551739,\n",
       "  'support': 838},\n",
       " 'accuracy': 0.6682577565632458}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "malstm_test_lablels, malstm_test_similarity, malstm_test_report = malstm.test(padding(test_decoder_seqs),\n",
    "                                                                              padding(test_encoder_seqs), test_labels)\n",
    "malstm_test_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Бачимо що результати приблизно однакові, але все одно гірше бейзлайна."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Universal Sentence Encoder\n",
    "\n",
    "Спробуємо використати transfer learning. Для цього візьмемо https://tfhub.dev/google/universal-sentence-encoder/2 яка обіцяє покращення на аналогічних задачах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def originals(data):\n",
    "    return np.array([' '.join(p.original) for p in data])\n",
    "                    \n",
    "def candidates(data):\n",
    "    return np.array([' '.join(p.candidate) for p in data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0528 14:10:36.570930 139747452421952 __init__.py:56] Some hub symbols are not available because TensorFlow version is less than 1.14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/szubovych/.virtualenvs/nlp/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0528 14:10:37.480704 139747452421952 deprecation.py:323] From /home/szubovych/.virtualenvs/nlp/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "embed = hub.Module(\"https://tfhub.dev/google/universal-sentence-encoder-large/3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def universal_embedding(x):\n",
    "    return embed(tf.squeeze(tf.cast(x, tf.string)), \n",
    "                 signature=\"default\", as_dict=True)[\"default\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import concatenate\n",
    "\n",
    "class UniversalModel(SemevalModel):\n",
    "    def __init__(self, left_seqs, right_seqs, labels):\n",
    "        super().__init__(left_seqs, right_seqs, labels)\n",
    "    \n",
    "        left_input = Input(shape=(1,), dtype=tf.string)\n",
    "        right_input = Input(shape=(1,), dtype=tf.string)\n",
    "\n",
    "        left_embedding = Lambda(universal_embedding, output_shape=(512,))(left_input)\n",
    "        right_embedding = Lambda(universal_embedding, output_shape=(512,))(right_input)\n",
    "\n",
    "        left_hidden = Dense(512, activation = \"relu\")(left_embedding)\n",
    "        right_hidden = Dense(512, activation = \"relu\")(right_embedding)\n",
    "        \n",
    "        concats = concatenate([left_hidden, right_hidden], axis=-1)\n",
    "        \n",
    "        hidden = Dense(256, activation = \"relu\")(concats)\n",
    "        \n",
    "        out = Dense(1, activation = \"sigmoid\")(hidden)\n",
    "\n",
    "        self.model = Model([left_input, right_input], [out])\n",
    "        \n",
    "        self.model.compile(optimizer = RMSprop(lr=5e-5),\n",
    "                           loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        self.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0528 17:31:35.703430 139747452421952 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0528 17:31:36.802050 139747452421952 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_11 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_12 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 512)          0           input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (None, 512)          0           input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 512)          262656      lambda_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 512)          262656      lambda_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 1024)         0           dense_21[0][0]                   \n",
      "                                                                 dense_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 256)          262400      concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 1)            257         dense_23[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 787,969\n",
      "Trainable params: 787,969\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "universal = UniversalModel(originals(clean_train_data), candidates(clean_train_data), train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11530 samples, validate on 4142 samples\n",
      "Epoch 1/6\n",
      "11530/11530 [==============================] - 75s 7ms/step - loss: 0.6307 - acc: 0.6546 - val_loss: 0.6388 - val_acc: 0.6456\n",
      "Epoch 2/6\n",
      "11530/11530 [==============================] - 66s 6ms/step - loss: 0.5680 - acc: 0.7144 - val_loss: 0.6299 - val_acc: 0.6552\n",
      "Epoch 3/6\n",
      "11530/11530 [==============================] - 68s 6ms/step - loss: 0.5275 - acc: 0.7599 - val_loss: 0.6267 - val_acc: 0.6579\n",
      "Epoch 4/6\n",
      "11530/11530 [==============================] - 67s 6ms/step - loss: 0.5037 - acc: 0.7722 - val_loss: 0.6325 - val_acc: 0.6637\n",
      "Epoch 5/6\n",
      "11530/11530 [==============================] - 66s 6ms/step - loss: 0.4875 - acc: 0.7825 - val_loss: 0.6209 - val_acc: 0.6779\n",
      "Epoch 6/6\n",
      "11530/11530 [==============================] - 64s 6ms/step - loss: 0.4741 - acc: 0.7892 - val_loss: 0.6230 - val_acc: 0.6782\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    K.set_session(session)\n",
    "    session.run(tf.global_variables_initializer())  \n",
    "    session.run(tf.tables_initializer())\n",
    "    universal.train(originals(clean_dev_data), candidates(clean_dev_data), dev_labels,\n",
    "                      batch_size = 64, epochs=6)\n",
    "    \n",
    "    universal_result = universal.test(originals(clean_dev_data), candidates(clean_dev_data), dev_labels)\n",
    "    \n",
    "    test_universal_result = universal.test(originals(clean_test_data), candidates(clean_test_data), test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'False': {'precision': 0.6884323107233324,\n",
       "  'recall': 0.9154191616766467,\n",
       "  'f1-score': 0.785863453815261,\n",
       "  'support': 2672},\n",
       " 'True': {'precision': 0.6162988115449916,\n",
       "  'recall': 0.24693877551020407,\n",
       "  'f1-score': 0.3525983487129674,\n",
       "  'support': 1470},\n",
       " 'micro avg': {'precision': 0.678174794785128,\n",
       "  'recall': 0.678174794785128,\n",
       "  'f1-score': 0.678174794785128,\n",
       "  'support': 4142},\n",
       " 'macro avg': {'precision': 0.652365561134162,\n",
       "  'recall': 0.5811789685934254,\n",
       "  'f1-score': 0.5692309012641142,\n",
       "  'support': 4142},\n",
       " 'weighted avg': {'precision': 0.6628320587213622,\n",
       "  'recall': 0.678174794785128,\n",
       "  'f1-score': 0.6320972286823852,\n",
       "  'support': 4142},\n",
       " 'accuracy': 0.678174794785128}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "universal_result[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'False': {'precision': 0.8144192256341789,\n",
       "  'recall': 0.9200603318250377,\n",
       "  'f1-score': 0.8640226628895185,\n",
       "  'support': 663},\n",
       " 'True': {'precision': 0.4044943820224719,\n",
       "  'recall': 0.2057142857142857,\n",
       "  'f1-score': 0.2727272727272727,\n",
       "  'support': 175},\n",
       " 'micro avg': {'precision': 0.7708830548926014,\n",
       "  'recall': 0.7708830548926014,\n",
       "  'f1-score': 0.7708830548926014,\n",
       "  'support': 838},\n",
       " 'macro avg': {'precision': 0.6094568038283255,\n",
       "  'recall': 0.5628873087696616,\n",
       "  'f1-score': 0.5683749678083956,\n",
       "  'support': 838},\n",
       " 'weighted avg': {'precision': 0.7288143955243355,\n",
       "  'recall': 0.7708830548926014,\n",
       "  'f1-score': 0.7405421219845149,\n",
       "  'support': 838},\n",
       " 'accuracy': 0.7708830548926014}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_universal_result[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Бачимо що покращення не відбулось, рузультати гірші ніж у двох попередніх моделей. Думаю модель просто нічого не знає про Twitter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проженемо тестовий скрипт і підсумуємо результати."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_scores(filename, predicted_similarity):\n",
    "    with open(filename, 'w+') as f:\n",
    "        for estimate in predicted_similarity:                    \n",
    "            f.write(\"{}\\t{:.4f}\\n\".format(str(estimate.item() > 0.5).lower(), estimate.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оскільки ми не брали до уваги debatable клас то його треба відфільтрувати з еталонного файлу інакше скрипт не спрацює."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat SemEval-PIT2015-py3/data/test.label | grep -E \"true|false\" > test_bin.label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline\n",
    "\n",
    "Виведемо для порівняння бейзлайн."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "838\tBASELINE\t02_LG\t\tF: 0.589\tPrec: 0.679\tRec: 0.520\t\tP-corr: 0.511\tF1: 0.601\tPrec: 0.674\tRec: 0.543\r\n"
     ]
    }
   ],
   "source": [
    "!python SemEval-PIT2015-py3/scripts/pit2015_eval_single.py SemEval-PIT2015-py3/data/test.label SemEval-PIT2015-py3/systemoutputs/PIT2015_BASELINE_02_LG.output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_scores('PIT2015_zubovych_autoencoder.output', seq2seq_test_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "838\tzubovych\tautoencoder\t\tF: 0.331\tPrec: 0.350\tRec: 0.314\t\tP-corr: 0.227\tF1: 0.383\tPrec: 0.278\tRec: 0.617\r\n"
     ]
    }
   ],
   "source": [
    "!python SemEval-PIT2015-py3/scripts/pit2015_eval_single.py test_bin.label PIT2015_zubovych_autoencoder.output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manhattan LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_scores('PIT2015_zubovych_malstm.output', malstm_test_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "838\tzubovych\tmalstm\t\tF: 0.315\tPrec: 0.277\tRec: 0.366\t\tP-corr: 0.170\tF1: 0.375\tPrec: 0.240\tRec: 0.857\r\n"
     ]
    }
   ],
   "source": [
    "!python SemEval-PIT2015-py3/scripts/pit2015_eval_single.py test_bin.label PIT2015_zubovych_malstm.output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Universal Sentence Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_scores('PIT2015_zubovych_universal.output',  test_universal_result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "838\tzubovych\tuniversal\t\tF: 0.273\tPrec: 0.404\tRec: 0.206\t\tP-corr: 0.255\tF1: 0.394\tPrec: 0.356\tRec: 0.440\r\n"
     ]
    }
   ],
   "source": [
    "!python SemEval-PIT2015-py3/scripts/pit2015_eval_single.py test_bin.label PIT2015_zubovych_universal.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Бейзлайн не побили. Autoencoder та MaLSTM, яка на quora датасеті дає гарну якість, виглядають приблизно однаково.\n",
    "Слід зауважити що датасет від quora в разів 30 більший і це не твітер, де в тексті дуже багато опечаток і скороченнь.\n",
    "Хочу додати що ConceptNet Numberbatch дав кращі результати порівняно зі звичайним word2vec, glove і fasttext \n",
    "(не всі експерименти були включені в фінальний notebook)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
