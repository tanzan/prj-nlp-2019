{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "Спочатку завантажуємо word embeddings для української мови."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl http://lang.org.ua/static/downloads/models/news.lowercased.tokenized.word2vec.300d.bz2 --output news.lowercased.tokenized.word2vec.300d.bz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bunzip2 news.lowercased.tokenized.word2vec.300d.bz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 59.1 s, sys: 702 ms, total: 59.8 s\n",
      "Wall time: 59.7 s\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "%time wv = KeyedVectors.load_word2vec_format('news.lowercased.tokenized.word2vec.300d', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('дієслово', 0.6502863764762878),\n",
       " ('слівце', 0.6484909653663635),\n",
       " ('словосполучення', 0.6456568241119385),\n",
       " ('гасло', 0.5913079977035522),\n",
       " ('слово**', 0.555127739906311),\n",
       " (\"прислів'я\", 0.5407627820968628),\n",
       " ('письмо', 0.5235773324966431),\n",
       " ('прізвище', 0.52119380235672),\n",
       " ('пророцтво', 0.5125285983085632),\n",
       " ('ремесло', 0.5058826804161072)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar('слово')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Потім розпаковуємо та завантажуємо дані."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replace 1551/Інші-Подяки.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
     ]
    }
   ],
   "source": [
    "!unzip -q ../../../tasks/1551.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Аварійний--травмонебезпечний-стан-утримання-об-єктів-благоустрою.txt\r\n",
      "Бажаючі-отримати--Картки-киянина--КК--.txt\r\n",
      "Будівництво-АЗС.txt\r\n",
      "Будівництво-в-нічний-час.txt\r\n",
      "Будівництво-дооблаштування-дитячого-майданчику.txt\r\n",
      "Будівництво--дооблаштування-спортивних-майданчиків.txt\r\n",
      "Будівництво-та-реконструкція-об-єктів-освіти.txt\r\n",
      "Взаємовідносини-з-сусідами.txt\r\n",
      "Вивезення--утилізація-твердих-та-негабаритних-відходів.txt\r\n",
      "Видалення-аварійних--пошкоджених-хворобами-дерев.txt\r\n",
      "Видача-розрахункових-книжок--квитанцій--довідок.txt\r\n",
      "Вилов-безпритульних-тварин.txt\r\n",
      "Вирізування--кронування--гілля-дерев.txt\r\n",
      "Виток-холодної-води-на-поверхню.txt\r\n",
      "Відновлення-благоустрою-після-вик--планових-аварійних-робіт-на-об-єктах-благоуст.txt\r\n",
      "ls: write error: Broken pipe\r\n"
     ]
    }
   ],
   "source": [
    "!ls 1551 | head -n 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1551/Незадовільна-температура-ГВП.txt',\n",
       " '1551/Незадовільне-обслуговування-в-амбулаторно-поліклінічних-установах.txt',\n",
       " '1551/Відсутнє-електропостачання.txt',\n",
       " '1551/Порушення-правил-тиші--після-------.txt',\n",
       " '1551/Неякісне-ХВП.txt',\n",
       " '1551/Нанесення-дорожньої-розмітки.txt',\n",
       " '1551/Робота-циркуляційної-системи.txt',\n",
       " '1551/Встановлення-світлофора.txt',\n",
       " '1551/Завезення-піску-на-дитячий-майданчик.txt',\n",
       " '1551/Скошування-трави.txt']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "files = glob.glob(\"1551/*\")\n",
    "\n",
    "files[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import namedtuple\n",
    "\n",
    "Document = namedtuple('Document', 'id topic_id tags content')\n",
    "\n",
    "def parse_tags(file):\n",
    "    return [tag for tag in os.path.basename(file.name)[:-4].split('-') if tag]\n",
    "\n",
    "def parse_topic_file(topic_id, filename):\n",
    "    documents = []    \n",
    "    with open(filename) as f:\n",
    "        tags = parse_tags(f)        \n",
    "        _id = None\n",
    "        idx = -1        \n",
    "        for line in f:            \n",
    "            if line.strip().isnumeric():\n",
    "                _id = int(line.strip())\n",
    "                documents.append(Document(_id, topic_id, tags, []))\n",
    "                idx +=1\n",
    "                continue\n",
    "            if not (_id is None) and line.strip():                \n",
    "                documents[idx].content.append(line.strip())                \n",
    "    \n",
    "    return [doc._replace(content = ''.join(doc.content)) for doc in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114348"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_documents = [doc for topic_id, file in enumerate(files) \\\n",
    "                 for doc in parse_topic_file(topic_id, file) if len(doc.content) > 0]\n",
    "\n",
    "len(all_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id=2697865, topic_id=0, tags=['Незадовільна', 'температура', 'ГВП'], content='Недогрев горячей воды (вода нормальной температуры подавалась неделю с15 по 23, до этого была частичная подача горячей воды (пару часов вечером и ночью горячая), остальное время теплой), сейчас опять температура порядка 40 градусов. Эта ситуация продолжается на фоне постоянного недогрева батарей в квартире, ДУ 12 ККЕУ  МОУкраины  не реагирует на ситуацию.'),\n",
       " Document(id=3170827, topic_id=0, tags=['Незадовільна', 'температура', 'ГВП'], content='Из горячего крана течет холодная вода, в вечернее и утреннее время купаться нет возможности. Необходимо или пересчитывать тарифы или включать горячую воду.'),\n",
       " Document(id=3165270, topic_id=0, tags=['Незадовільна', 'температура', 'ГВП'], content='Я поживаю на 6 этаже 9и - этажного дома на протяжении долгого промежутка времени у нас в квартире из крана горячей воды, особенно утром и в первой половине дня течёт если не холодная вода, то вода чуть тёплая. По утрам для того чтобы совершить утренний туалет приходится долго спускать воду (и эта проблема у большей части жильцов нашего дома). В свете того, что с мая месяца у нас очень выросли тарифы на горячую воду, меня интересует вопрос - почему я должна платить деньги за некачественную услугу. Огромная просьба посодействовать в решении данной проблемы. Местные сантехники подтверждают, что проблемы с горячей водой не только в нашей квартире, но решить эту проблему они не могут, так как это от них не зависит.')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_documents[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тепер фільтруємо документи з українською мовою."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect\n",
    "from langdetect.detector import LangDetectException\n",
    "from tqdm import tqdm_notebook\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "def memoize(filename, compute):  \n",
    "    \n",
    "    fullname = filename + '.can'\n",
    "    \n",
    "    if os.path.isfile(fullname):\n",
    "        with open(fullname, 'rb') as f:                        \n",
    "            return pickle.load(f)\n",
    "    \n",
    "    result = compute()\n",
    "    with open(fullname, 'wb') as f:\n",
    "        pickle.dump(result, f)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def is_uk(text):\n",
    "    \n",
    "    if len(text):\n",
    "        try:\n",
    "            return detect(text[:1024]) == 'uk'\n",
    "        except LangDetectException as e:\n",
    "            return False\n",
    "    \n",
    "    return False\n",
    "\n",
    "uk_documents = memoize('uk_documents', \n",
    "                       lambda: [doc for doc in tqdm_notebook(all_documents) if is_uk(doc.content)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дивимся на дані."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "uk_doc_df = pandas.DataFrame([doc._replace(tags = \"-\".join(doc.tags)) for doc in uk_documents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>topic_id</th>\n",
       "      <th>tags</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3152784</td>\n",
       "      <td>0</td>\n",
       "      <td>Незадовільна-температура-ГВП</td>\n",
       "      <td>Відсутнітність горячого водопостачання належно...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3143050</td>\n",
       "      <td>0</td>\n",
       "      <td>Незадовільна-температура-ГВП</td>\n",
       "      <td>Добрий вечір.Прошу розібратися з проблемою нев...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3142427</td>\n",
       "      <td>0</td>\n",
       "      <td>Незадовільна-температура-ГВП</td>\n",
       "      <td>На моє звернення № Г-6623 відповідь написав ди...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3130991</td>\n",
       "      <td>0</td>\n",
       "      <td>Незадовільна-температура-ГВП</td>\n",
       "      <td>Доброго дня! Вже більше двох тижнів гаряче вод...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2405990</td>\n",
       "      <td>0</td>\n",
       "      <td>Незадовільна-температура-ГВП</td>\n",
       "      <td>На звернення:Номер звернення:\\tГ-6478Зареєстро...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3115494</td>\n",
       "      <td>0</td>\n",
       "      <td>Незадовільна-температура-ГВП</td>\n",
       "      <td>Звертаюсь до Вас стосовно вирішення питання, щ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3104107</td>\n",
       "      <td>0</td>\n",
       "      <td>Незадовільна-температура-ГВП</td>\n",
       "      <td>Доброго дня!!! Моє звернення від 02.12.14 #Г-1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3091571</td>\n",
       "      <td>0</td>\n",
       "      <td>Незадовільна-температура-ГВП</td>\n",
       "      <td>Протягом останнього тижня гаряча вода недостат...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2690156</td>\n",
       "      <td>0</td>\n",
       "      <td>Незадовільна-температура-ГВП</td>\n",
       "      <td>Прошу прийняти необхідні заходи по покращенню ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2748419</td>\n",
       "      <td>0</td>\n",
       "      <td>Незадовільна-температура-ГВП</td>\n",
       "      <td>немає  температури гарячої води</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  topic_id                          tags  \\\n",
       "0  3152784         0  Незадовільна-температура-ГВП   \n",
       "1  3143050         0  Незадовільна-температура-ГВП   \n",
       "2  3142427         0  Незадовільна-температура-ГВП   \n",
       "3  3130991         0  Незадовільна-температура-ГВП   \n",
       "4  2405990         0  Незадовільна-температура-ГВП   \n",
       "5  3115494         0  Незадовільна-температура-ГВП   \n",
       "6  3104107         0  Незадовільна-температура-ГВП   \n",
       "7  3091571         0  Незадовільна-температура-ГВП   \n",
       "8  2690156         0  Незадовільна-температура-ГВП   \n",
       "9  2748419         0  Незадовільна-температура-ГВП   \n",
       "\n",
       "                                             content  \n",
       "0  Відсутнітність горячого водопостачання належно...  \n",
       "1  Добрий вечір.Прошу розібратися з проблемою нев...  \n",
       "2  На моє звернення № Г-6623 відповідь написав ди...  \n",
       "3  Доброго дня! Вже більше двох тижнів гаряче вод...  \n",
       "4  На звернення:Номер звернення:\\tГ-6478Зареєстро...  \n",
       "5  Звертаюсь до Вас стосовно вирішення питання, щ...  \n",
       "6  Доброго дня!!! Моє звернення від 02.12.14 #Г-1...  \n",
       "7  Протягом останнього тижня гаряча вода недостат...  \n",
       "8  Прошу прийняти необхідні заходи по покращенню ...  \n",
       "9                    немає  температури гарячої води  "
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uk_doc_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>topic_id</th>\n",
       "      <th>tags</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.182900e+04</td>\n",
       "      <td>61829.000000</td>\n",
       "      <td>61829</td>\n",
       "      <td>61829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>188</td>\n",
       "      <td>56061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Відсутність-ГВП</td>\n",
       "      <td>Відсутнє гаряче водопостачання</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6564</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.159625e+06</td>\n",
       "      <td>105.551731</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.084360e+07</td>\n",
       "      <td>55.922291</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.841555e+06</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.083712e+06</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.245460e+06</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.013102e+09</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id      topic_id             tags  \\\n",
       "count   6.182900e+04  61829.000000            61829   \n",
       "unique           NaN           NaN              188   \n",
       "top              NaN           NaN  Відсутність-ГВП   \n",
       "freq             NaN           NaN             6564   \n",
       "mean    3.159625e+06    105.551731              NaN   \n",
       "std     1.084360e+07     55.922291              NaN   \n",
       "min     1.000000e+01      0.000000              NaN   \n",
       "25%     2.841555e+06     58.000000              NaN   \n",
       "50%     3.083712e+06    121.000000              NaN   \n",
       "75%     3.245460e+06    150.000000              NaN   \n",
       "max     2.013102e+09    187.000000              NaN   \n",
       "\n",
       "                               content  \n",
       "count                            61829  \n",
       "unique                           56061  \n",
       "top     Відсутнє гаряче водопостачання  \n",
       "freq                                46  \n",
       "mean                               NaN  \n",
       "std                                NaN  \n",
       "min                                NaN  \n",
       "25%                                NaN  \n",
       "50%                                NaN  \n",
       "75%                                NaN  \n",
       "max                                NaN  "
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uk_doc_df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_id</th>\n",
       "      <th>tags</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <th>Відсутність-ГВП</th>\n",
       "      <td>6564</td>\n",
       "      <td>6564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <th>Укладання-та-ремонт-асфальтного-покриття</th>\n",
       "      <td>3628</td>\n",
       "      <td>3628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <th>Відсутність-опалення</th>\n",
       "      <td>3142</td>\n",
       "      <td>3142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <th>Перевірка-дозвільної-документації-демонтаж-кіосків-ларків</th>\n",
       "      <td>2199</td>\n",
       "      <td>2199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <th>Прибирання-та-санітарний-стан-територій</th>\n",
       "      <td>2005</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <th>Технічний-стан-проїжджих-частин-вулиць-та-тротуарів</th>\n",
       "      <td>1303</td>\n",
       "      <td>1303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <th>Відновлення-благоустрою-після-вик-планових-аварійних-робіт-на-об-єктах-благоуст</th>\n",
       "      <td>1289</td>\n",
       "      <td>1289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <th>Відсутність-освітлення-у-під-їзді-за-відсутності-несправності-лампочок</th>\n",
       "      <td>1256</td>\n",
       "      <td>1256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <th>Не-працює-пасажирський-ліфт</th>\n",
       "      <td>1220</td>\n",
       "      <td>1220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <th>Ремонт-під-їзду</th>\n",
       "      <td>1198</td>\n",
       "      <td>1198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th>Незадовільна-температура-ГВП</th>\n",
       "      <td>1116</td>\n",
       "      <td>1116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <th>Перерахунок-та-нарахування-плати-за-інші-види-житлово-комунальних-послуг</th>\n",
       "      <td>1097</td>\n",
       "      <td>1097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <th>Про-розгляд-звернень-громадян</th>\n",
       "      <td>993</td>\n",
       "      <td>993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <th>Відсутність-опалення-по-стояку</th>\n",
       "      <td>989</td>\n",
       "      <td>989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <th>ГЛ-Несанкціонована-торгівля</th>\n",
       "      <td>826</td>\n",
       "      <td>826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <th>Прибирання-приміщень</th>\n",
       "      <td>800</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <th>Відсутнє-ХВП</th>\n",
       "      <td>785</td>\n",
       "      <td>785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <th>Освітлення-в-приміщенні-й-при-вході-в-нього</th>\n",
       "      <td>743</td>\n",
       "      <td>743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <th>Інші-технічні-недоліки-стану-ліфту</th>\n",
       "      <td>695</td>\n",
       "      <td>695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <th>Ремонт-дахів</th>\n",
       "      <td>671</td>\n",
       "      <td>671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <th>Перевірка-наявності-дозволів-на-виконання-будівельних-робіт</th>\n",
       "      <td>646</td>\n",
       "      <td>646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <th>Незадовільна-температура-опалення</th>\n",
       "      <td>635</td>\n",
       "      <td>635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <th>Будівництво-дооблаштування-дитячого-майданчику</th>\n",
       "      <td>633</td>\n",
       "      <td>633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <th>Утримання-підвалів-колясочних-технічних-поверхів</th>\n",
       "      <td>617</td>\n",
       "      <td>617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <th>Відсутність-освітлення-на-опорних-стовпах-за-відсутності-несправності-лампочок</th>\n",
       "      <td>538</td>\n",
       "      <td>538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <th>Питання-освітлення-на-опорних-стовпах</th>\n",
       "      <td>516</td>\n",
       "      <td>516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <th>Встановлення-та-експлуатація-лічильників-на-водопостачання</th>\n",
       "      <td>481</td>\n",
       "      <td>481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <th>Робота-світлофора</th>\n",
       "      <td>480</td>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <th>Стихійне-сміттєзвалище</th>\n",
       "      <td>477</td>\n",
       "      <td>477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <th>Робота-циркуляційної-системи</th>\n",
       "      <td>473</td>\n",
       "      <td>473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <th>Технічне-обслуговування-систем-тепло-водопостачання-та-водовідведення-і-зливов</th>\n",
       "      <td>458</td>\n",
       "      <td>458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <th>Демонтаж-рекламних-конструкцій-і-вивісок</th>\n",
       "      <td>458</td>\n",
       "      <td>458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <th>Скління-та-ремонт-вікон-на-сходових-клітинах</th>\n",
       "      <td>431</td>\n",
       "      <td>431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <th>Встановлення-лічильників-на-опалення</th>\n",
       "      <td>430</td>\n",
       "      <td>430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <th>Вологе-прибирання-приміщень</th>\n",
       "      <td>407</td>\n",
       "      <td>407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <th>Незадовільний-вивіз-сміття-з-контейнерів-та-урн-для-сміття</th>\n",
       "      <td>383</td>\n",
       "      <td>383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <th>Встановлення-та-експлуатація-дорожніх-знаків</th>\n",
       "      <td>359</td>\n",
       "      <td>359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <th>Нанесення-дорожньої-розмітки</th>\n",
       "      <td>353</td>\n",
       "      <td>353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <th>Паркування-авто-у-місцях-загального-користування</th>\n",
       "      <td>351</td>\n",
       "      <td>351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <th>Встановлення-сміттєвих-контейнерів-та-урн-для-сміття</th>\n",
       "      <td>348</td>\n",
       "      <td>348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <th>Видалення-аварійних-пошкоджених-хворобами-дерев</th>\n",
       "      <td>321</td>\n",
       "      <td>321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <th>Контроль-за-станом-рекламних-засобів</th>\n",
       "      <td>318</td>\n",
       "      <td>318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <th>Перевірка-дозвільної-документації-демонтаж-літніх-майданчиків-кафе-ресторанів</th>\n",
       "      <td>316</td>\n",
       "      <td>316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <th>Інші-Подяки</th>\n",
       "      <td>307</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <th>Встановлення-огородження-зеленої-зони</th>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <th>Знищення-омели-амброзії-та-рослин-паразитів</th>\n",
       "      <td>283</td>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <th>Аварійний-травмонебезпечний-стан-утримання-об-єктів-благоустрою</th>\n",
       "      <td>280</td>\n",
       "      <td>280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <th>Не-працює-вантажний-ліфт</th>\n",
       "      <td>275</td>\n",
       "      <td>275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <th>Встановлення-сигнальних-стовпчиків-бар-єрних-огороджень-бордюрів</th>\n",
       "      <td>273</td>\n",
       "      <td>273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <th>Ремонт-і-обслуговування-сміттєпроводів-та-сміттєзбірників-в-приміщенні</th>\n",
       "      <td>265</td>\n",
       "      <td>265</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                               id  content\n",
       "topic_id tags                                                             \n",
       "138      Відсутність-ГВП                                     6564     6564\n",
       "180      Укладання-та-ремонт-асфальтного-покриття            3628     3628\n",
       "27       Відсутність-опалення                                3142     3142\n",
       "127      Перевірка-дозвільної-документації-демонтаж-кіос...  2199     2199\n",
       "67       Прибирання-та-санітарний-стан-територій             2005     2005\n",
       "79       Технічний-стан-проїжджих-частин-вулиць-та-троту...  1303     1303\n",
       "155      Відновлення-благоустрою-після-вик-планових-авар...  1289     1289\n",
       "121      Відсутність-освітлення-у-під-їзді-за-відсутност...  1256     1256\n",
       "58       Не-працює-пасажирський-ліфт                         1220     1220\n",
       "183      Ремонт-під-їзду                                     1198     1198\n",
       "0        Незадовільна-температура-ГВП                        1116     1116\n",
       "101      Перерахунок-та-нарахування-плати-за-інші-види-ж...  1097     1097\n",
       "143      Про-розгляд-звернень-громадян                        993      993\n",
       "88       Відсутність-опалення-по-стояку                       989      989\n",
       "173      ГЛ-Несанкціонована-торгівля                          826      826\n",
       "161      Прибирання-приміщень                                 800      800\n",
       "176      Відсутнє-ХВП                                         785      785\n",
       "171      Освітлення-в-приміщенні-й-при-вході-в-нього          743      743\n",
       "148      Інші-технічні-недоліки-стану-ліфту                   695      695\n",
       "178      Ремонт-дахів                                         671      671\n",
       "22       Перевірка-наявності-дозволів-на-виконання-будів...   646      646\n",
       "174      Незадовільна-температура-опалення                    635      635\n",
       "68       Будівництво-дооблаштування-дитячого-майданчику       633      633\n",
       "181      Утримання-підвалів-колясочних-технічних-поверхів     617      617\n",
       "164      Відсутність-освітлення-на-опорних-стовпах-за-ві...   538      538\n",
       "109      Питання-освітлення-на-опорних-стовпах                516      516\n",
       "154      Встановлення-та-експлуатація-лічильників-на-вод...   481      481\n",
       "10       Робота-світлофора                                    480      480\n",
       "41       Стихійне-сміттєзвалище                               477      477\n",
       "6        Робота-циркуляційної-системи                         473      473\n",
       "131      Технічне-обслуговування-систем-тепло-водопостач...   458      458\n",
       "114      Демонтаж-рекламних-конструкцій-і-вивісок             458      458\n",
       "116      Скління-та-ремонт-вікон-на-сходових-клітинах         431      431\n",
       "33       Встановлення-лічильників-на-опалення                 430      430\n",
       "16       Вологе-прибирання-приміщень                          407      407\n",
       "40       Незадовільний-вивіз-сміття-з-контейнерів-та-урн...   383      383\n",
       "57       Встановлення-та-експлуатація-дорожніх-знаків         359      359\n",
       "5        Нанесення-дорожньої-розмітки                         353      353\n",
       "69       Паркування-авто-у-місцях-загального-користування     351      351\n",
       "78       Встановлення-сміттєвих-контейнерів-та-урн-для-с...   348      348\n",
       "136      Видалення-аварійних-пошкоджених-хворобами-дерев      321      321\n",
       "62       Контроль-за-станом-рекламних-засобів                 318      318\n",
       "32       Перевірка-дозвільної-документації-демонтаж-літн...   316      316\n",
       "168      Інші-Подяки                                          307      307\n",
       "105      Встановлення-огородження-зеленої-зони                289      289\n",
       "74       Знищення-омели-амброзії-та-рослин-паразитів          283      283\n",
       "14       Аварійний-травмонебезпечний-стан-утримання-об-є...   280      280\n",
       "145      Не-працює-вантажний-ліфт                             275      275\n",
       "128      Встановлення-сигнальних-стовпчиків-бар-єрних-ог...   273      273\n",
       "112      Ремонт-і-обслуговування-сміттєпроводів-та-смітт...   265      265"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uk_doc_df.groupby(['topic_id', 'tags']).count().sort_values(['id'], ascending = False).head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Виділяємо лейбли."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61829"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "topic_labels = np.array([doc.topic_id for doc in uk_documents])\n",
    "len(topic_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "І розбиваємо дані на тренувальні і тестові."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_documents, test_documents, train_topic_labels, test_topic_labels = \\\n",
    "    train_test_split(uk_documents, topic_labels, random_state = 26, test_size = 0.3, stratify = topic_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43280\n",
      "43280\n"
     ]
    }
   ],
   "source": [
    "print(len(train_documents))\n",
    "print(len(train_topic_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18549\n",
      "18549\n"
     ]
    }
   ],
   "source": [
    "print(len(test_documents))\n",
    "print(len(test_topic_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline\n",
    "\n",
    "Будуємо бейзлайн, знаходимо суму векторів слів по кожному документу і використовуємо kNN на знайденних векторах. Для порівняння векторів застосовуємо cosine similarity. Перед знаходженням суми векторів, документ токенізується та видаляються stop words. Знайдені вектори нормалізуються, в такому випадку eclidean distance для kNN має той самий ефект що й cosine distance, при цьому алгоритм дозволяє використовувати більш ефективні структури данних, такі як, наприклад, k-d tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tokenize_uk\n",
    "import string\n",
    "import html\n",
    "import re\n",
    "\n",
    "with open('uk_stop_words.txt') as f:\n",
    "    STOP_WORDS = f.read().split()\n",
    "    \n",
    "EXT_PUNCTUATION = \"”...«»№\"\n",
    "\n",
    "def contain_numbers(s):\n",
    "    return bool(re.search(r'\\d', s))\n",
    "\n",
    "def non_stop_word(word):\n",
    "    return not (word in string.punctuation or word in EXT_PUNCTUATION \\\n",
    "                or word in STOP_WORDS or contain_numbers(word) or len(word) < 2)\n",
    "\n",
    "def remove_stop_words(tokens):\n",
    "    return [token for token in tokens if non_stop_word(token.lower())]\n",
    "\n",
    "def tokenize_doc(doc):\n",
    "    return [word.lower() for word in \\\n",
    "            remove_stop_words(tokenize_uk.tokenize_words(html.unescape(doc.content)))]\n",
    "\n",
    "def normalize_vec(x):\n",
    "    m = np.max(x)\n",
    "    if m > 0.0:\n",
    "        return x/np.sqrt(np.dot(x,x))\n",
    "    return x\n",
    "    \n",
    "def doc_to_sum_vec(doc):\n",
    "    words = tokenize_doc(doc)    \n",
    "    vec = np.zeros(300)\n",
    "    for word in words:\n",
    "        try:\n",
    "            vec += wv[word]\n",
    "        except KeyError as e:            \n",
    "            pass\n",
    "        \n",
    "    return vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рахуємо вектори для тренувальних і тестових документів."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a2112e4fe4d4b51927a2873f5396e79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=43280), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_doc_sum_vecs = np.array([doc_to_sum_vec(doc) for doc in tqdm_notebook(train_documents)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0f60c8645c94273a442c2fbd85633f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=18549), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_doc_sum_vecs = np.array([doc_to_sum_vec(doc) for doc in tqdm_notebook(test_documents)]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kNN+sum vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тренуємо модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "class Model:\n",
    "    def __init__(self, train_vectors, train_labels, test_vectors, test_labels):\n",
    "        self.train_vectors = train_vectors\n",
    "        self.train_labels = train_labels\n",
    "        self.test_vectors = test_vectors\n",
    "        self.test_labels = test_labels\n",
    "        \n",
    "    def train(self):\n",
    "        self.model.fit(self.train_vectors, self.train_labels)\n",
    "        self.topics_predicted = self.model.predict(self.test_vectors)\n",
    "        \n",
    "    def test(self):\n",
    "        self.test_report = classification_report(self.test_labels, self.topics_predicted)\n",
    "        print(classification_report(self.test_labels, self.topics_predicted))  \n",
    "\n",
    "class KnnModel(Model):\n",
    "    def __init__(self, train_vectors, train_labels, test_vectors, test_labels, n = 1):\n",
    "        super().__init__(np.array([normalize_vec(doc) for doc in train_vectors]),\\\n",
    "                       train_labels,\\\n",
    "                       np.array([normalize_vec(doc) for doc in test_vectors]),\\\n",
    "                       test_labels)                \n",
    "        self.model = KNeighborsClassifier(n_neighbors = n, algorithm='kd_tree', metric = 'euclidean', n_jobs = 6)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KnnModel(train_doc_sum_vecs, train_topic_labels, test_doc_sum_vecs, test_topic_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11min 14s, sys: 282 ms, total: 11min 15s\n",
      "Wall time: 1min 57s\n"
     ]
    }
   ],
   "source": [
    "%time knn.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.55      0.50       335\n",
      "           1       0.77      0.80      0.79        41\n",
      "           2       0.55      0.30      0.39        79\n",
      "           3       0.38      0.28      0.32        39\n",
      "           4       0.88      0.32      0.47        22\n",
      "           5       0.42      0.30      0.35       106\n",
      "           6       0.22      0.32      0.26       142\n",
      "           7       0.25      0.32      0.28        62\n",
      "           8       0.81      0.43      0.57        30\n",
      "           9       0.40      0.36      0.38        22\n",
      "          10       0.57      0.53      0.55       144\n",
      "          11       0.21      0.17      0.19        29\n",
      "          12       0.44      0.36      0.40        22\n",
      "          13       0.33      0.31      0.32        45\n",
      "          14       0.23      0.18      0.20        84\n",
      "          15       0.40      0.25      0.31        16\n",
      "          16       0.51      0.48      0.49       122\n",
      "          17       0.25      0.19      0.21        16\n",
      "          18       0.29      0.28      0.29        53\n",
      "          19       0.36      0.26      0.30        19\n",
      "          20       0.83      0.31      0.45        16\n",
      "          21       0.21      0.25      0.23        24\n",
      "          22       0.46      0.43      0.45       194\n",
      "          23       0.81      0.49      0.61        51\n",
      "          24       0.46      0.40      0.43        47\n",
      "          25       0.29      0.32      0.31        28\n",
      "          26       0.50      0.24      0.32        25\n",
      "          27       0.55      0.63      0.59       943\n",
      "          28       0.31      0.30      0.31        56\n",
      "          29       0.25      0.33      0.29        63\n",
      "          30       0.23      0.16      0.19        44\n",
      "          31       0.25      0.04      0.07        25\n",
      "          32       0.53      0.55      0.54        95\n",
      "          33       0.54      0.59      0.56       129\n",
      "          34       0.40      0.47      0.43        45\n",
      "          35       0.21      0.20      0.21        35\n",
      "          36       0.24      0.22      0.23        50\n",
      "          37       0.33      0.23      0.27        40\n",
      "          38       0.53      0.41      0.46        39\n",
      "          39       0.41      0.34      0.37        44\n",
      "          40       0.55      0.57      0.56       115\n",
      "          41       0.41      0.36      0.38       143\n",
      "          42       0.57      0.65      0.61        62\n",
      "          43       0.30      0.15      0.20        41\n",
      "          44       0.19      0.21      0.20        29\n",
      "          45       0.32      0.25      0.28        71\n",
      "          46       0.51      0.43      0.47        56\n",
      "          47       0.22      0.19      0.21        21\n",
      "          48       0.11      0.12      0.12        16\n",
      "          49       0.42      0.26      0.32        19\n",
      "          50       0.36      0.20      0.26        44\n",
      "          51       0.44      0.20      0.28        20\n",
      "          52       0.13      0.22      0.16        27\n",
      "          53       0.44      0.47      0.45        53\n",
      "          54       0.34      0.56      0.43        18\n",
      "          55       0.17      0.23      0.20        26\n",
      "          56       0.56      0.32      0.41        28\n",
      "          57       0.32      0.38      0.35       108\n",
      "          58       0.55      0.52      0.54       366\n",
      "          59       0.23      0.15      0.18        74\n",
      "          60       0.30      0.29      0.30        34\n",
      "          61       0.23      0.29      0.25        24\n",
      "          62       0.45      0.39      0.42        95\n",
      "          63       0.17      0.11      0.13        18\n",
      "          64       0.67      0.54      0.60        37\n",
      "          65       0.62      0.33      0.43        15\n",
      "          66       0.28      0.30      0.29        33\n",
      "          67       0.51      0.58      0.54       602\n",
      "          68       0.49      0.61      0.54       190\n",
      "          69       0.27      0.31      0.29       105\n",
      "          70       0.55      0.44      0.49        36\n",
      "          71       0.43      0.27      0.33        48\n",
      "          72       0.27      0.18      0.22        22\n",
      "          73       0.23      0.27      0.25        33\n",
      "          74       0.79      0.76      0.78        85\n",
      "          75       0.52      0.53      0.52        30\n",
      "          76       0.61      0.46      0.52        50\n",
      "          77       0.32      0.21      0.25        43\n",
      "          78       0.41      0.37      0.39       104\n",
      "          79       0.39      0.42      0.40       391\n",
      "          80       0.20      0.06      0.09        17\n",
      "          81       0.67      0.64      0.65        28\n",
      "          82       0.24      0.30      0.27        20\n",
      "          83       0.23      0.12      0.16        24\n",
      "          84       0.37      0.42      0.39        53\n",
      "          85       0.57      0.35      0.43        23\n",
      "          86       0.40      0.23      0.29        74\n",
      "          87       0.24      0.35      0.29        34\n",
      "          88       0.40      0.38      0.39       297\n",
      "          89       0.55      0.45      0.49        40\n",
      "          90       0.30      0.19      0.23        16\n",
      "          91       0.33      0.26      0.29        39\n",
      "          92       0.32      0.35      0.33        26\n",
      "          93       0.81      0.59      0.68        22\n",
      "          94       0.29      0.30      0.29        20\n",
      "          95       0.25      0.07      0.11        42\n",
      "          96       0.27      0.14      0.19        21\n",
      "          97       0.65      0.46      0.54        24\n",
      "          98       0.35      0.36      0.35        25\n",
      "          99       0.50      0.41      0.45        34\n",
      "         100       0.22      0.40      0.29        55\n",
      "         101       0.50      0.57      0.53       329\n",
      "         102       0.67      0.43      0.52        75\n",
      "         103       0.46      0.32      0.37        19\n",
      "         104       0.81      0.58      0.68        38\n",
      "         105       0.20      0.15      0.17        87\n",
      "         106       0.16      0.30      0.21        47\n",
      "         107       0.69      0.28      0.40        32\n",
      "         108       0.78      0.67      0.72        21\n",
      "         109       0.38      0.37      0.37       155\n",
      "         110       0.28      0.30      0.29        66\n",
      "         111       0.50      0.65      0.57        20\n",
      "         112       0.19      0.19      0.19        80\n",
      "         113       0.38      0.45      0.41        56\n",
      "         114       0.43      0.42      0.43       137\n",
      "         115       0.25      0.18      0.21        17\n",
      "         116       0.46      0.49      0.47       129\n",
      "         117       0.20      0.15      0.17        78\n",
      "         118       0.30      0.28      0.29        39\n",
      "         119       0.33      0.30      0.31        47\n",
      "         120       0.26      0.43      0.32        14\n",
      "         121       0.48      0.47      0.48       377\n",
      "         122       0.56      0.61      0.58        38\n",
      "         123       0.24      0.33      0.28        78\n",
      "         124       0.19      0.16      0.17        25\n",
      "         125       0.34      0.40      0.37        73\n",
      "         126       0.79      0.75      0.77        20\n",
      "         127       0.53      0.52      0.53       660\n",
      "         128       0.20      0.29      0.24        82\n",
      "         129       0.53      0.50      0.51        20\n",
      "         130       0.12      0.06      0.08        18\n",
      "         131       0.23      0.25      0.24       137\n",
      "         132       0.26      0.23      0.24        43\n",
      "         133       0.35      0.24      0.28        55\n",
      "         134       0.52      0.44      0.47        64\n",
      "         135       0.34      0.28      0.31        57\n",
      "         136       0.44      0.36      0.40        96\n",
      "         137       0.31      0.21      0.25        61\n",
      "         138       0.69      0.73      0.71      1969\n",
      "         139       0.44      0.35      0.39        54\n",
      "         140       0.25      0.19      0.21        16\n",
      "         141       0.38      0.40      0.39        25\n",
      "         142       0.18      0.24      0.21        17\n",
      "         143       0.37      0.35      0.36       298\n",
      "         144       0.14      0.10      0.11        41\n",
      "         145       0.46      0.52      0.49        83\n",
      "         146       0.56      0.40      0.47        25\n",
      "         147       0.30      0.12      0.17        25\n",
      "         148       0.34      0.39      0.36       209\n",
      "         149       0.46      0.40      0.43        15\n",
      "         150       0.30      0.36      0.33        61\n",
      "         151       0.27      0.30      0.29        20\n",
      "         152       0.42      0.25      0.31        20\n",
      "         153       0.47      0.24      0.31        34\n",
      "         154       0.52      0.52      0.52       144\n",
      "         155       0.42      0.43      0.42       387\n",
      "         156       0.24      0.21      0.23        56\n",
      "         157       0.18      0.12      0.15        24\n",
      "         158       0.40      0.37      0.39        51\n",
      "         159       0.57      0.35      0.43        23\n",
      "         160       0.27      0.27      0.27        44\n",
      "         161       0.48      0.43      0.45       240\n",
      "         162       0.44      0.26      0.33        27\n",
      "         163       0.29      0.26      0.28        19\n",
      "         164       0.33      0.34      0.34       161\n",
      "         165       0.56      0.30      0.39        66\n",
      "         166       0.40      0.33      0.36        70\n",
      "         167       0.55      0.43      0.48        61\n",
      "         168       0.46      0.17      0.25        92\n",
      "         169       0.39      0.53      0.45        34\n",
      "         170       0.19      0.16      0.18        37\n",
      "         171       0.36      0.39      0.37       223\n",
      "         172       0.20      0.08      0.12        24\n",
      "         173       0.62      0.58      0.60       248\n",
      "         174       0.45      0.46      0.45       191\n",
      "         175       0.20      0.21      0.20        53\n",
      "         176       0.42      0.32      0.36       236\n",
      "         177       0.32      0.28      0.30        39\n",
      "         178       0.37      0.48      0.42       201\n",
      "         179       0.12      0.16      0.14        31\n",
      "         180       0.51      0.57      0.54      1088\n",
      "         181       0.37      0.36      0.37       185\n",
      "         182       0.30      0.25      0.27        28\n",
      "         183       0.41      0.45      0.43       359\n",
      "         184       0.52      0.68      0.59        19\n",
      "         185       0.16      0.14      0.15        35\n",
      "         186       0.47      0.23      0.31        39\n",
      "         187       0.42      0.40      0.41        25\n",
      "\n",
      "   micro avg       0.46      0.46      0.46     18549\n",
      "   macro avg       0.40      0.35      0.36     18549\n",
      "weighted avg       0.46      0.46      0.46     18549\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imrovements\n",
    "\n",
    "Намагаємося покращити результат. Спочатку будемо використовувати логістичну регресію, потім проробимо все те саме але з векторами Doc2Vec."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logreg+sum vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "class LogregModel(Model):\n",
    "    def __init__(self, train_vectors, train_labels, test_vectors, test_labels, iters = 3000):\n",
    "        super().__init__(train_vectors, train_labels, test_vectors, test_labels)\n",
    "        self.model = LogisticRegression(random_state=26, n_jobs = 6, solver=\"lbfgs\", \\\n",
    "                                        multi_class=\"multinomial\", max_iter = iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogregModel(train_doc_sum_vecs, train_topic_labels, test_doc_sum_vecs, test_topic_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 303 ms, sys: 440 ms, total: 743 ms\n",
      "Wall time: 39min 38s\n"
     ]
    }
   ],
   "source": [
    "%time logreg.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.53      0.59       335\n",
      "           1       0.81      0.83      0.82        41\n",
      "           2       0.46      0.52      0.49        79\n",
      "           3       0.41      0.36      0.38        39\n",
      "           4       0.37      0.32      0.34        22\n",
      "           5       0.62      0.47      0.53       106\n",
      "           6       0.31      0.19      0.24       142\n",
      "           7       0.35      0.58      0.43        62\n",
      "           8       0.75      0.50      0.60        30\n",
      "           9       0.48      0.55      0.51        22\n",
      "          10       0.62      0.69      0.65       144\n",
      "          11       0.20      0.31      0.24        29\n",
      "          12       0.83      0.45      0.59        22\n",
      "          13       0.28      0.33      0.31        45\n",
      "          14       0.14      0.12      0.13        84\n",
      "          15       0.38      0.50      0.43        16\n",
      "          16       0.56      0.55      0.56       122\n",
      "          17       0.80      0.25      0.38        16\n",
      "          18       0.26      0.23      0.24        53\n",
      "          19       0.35      0.32      0.33        19\n",
      "          20       0.31      0.25      0.28        16\n",
      "          21       0.13      0.25      0.17        24\n",
      "          22       0.53      0.49      0.51       194\n",
      "          23       0.90      0.71      0.79        51\n",
      "          24       0.54      0.53      0.54        47\n",
      "          25       0.35      0.39      0.37        28\n",
      "          26       0.48      0.52      0.50        25\n",
      "          27       0.71      0.71      0.71       943\n",
      "          28       0.31      0.39      0.34        56\n",
      "          29       0.35      0.51      0.42        63\n",
      "          30       0.24      0.36      0.29        44\n",
      "          31       0.06      0.08      0.07        25\n",
      "          32       0.54      0.72      0.62        95\n",
      "          33       0.63      0.67      0.65       129\n",
      "          34       0.34      0.42      0.38        45\n",
      "          35       0.22      0.29      0.25        35\n",
      "          36       0.25      0.30      0.28        50\n",
      "          37       0.09      0.12      0.10        40\n",
      "          38       0.69      0.64      0.67        39\n",
      "          39       0.18      0.27      0.22        44\n",
      "          40       0.55      0.59      0.57       115\n",
      "          41       0.53      0.43      0.48       143\n",
      "          42       0.54      0.69      0.61        62\n",
      "          43       0.33      0.44      0.37        41\n",
      "          44       0.17      0.28      0.21        29\n",
      "          45       0.41      0.48      0.44        71\n",
      "          46       0.59      0.61      0.60        56\n",
      "          47       0.14      0.29      0.18        21\n",
      "          48       0.00      0.00      0.00        16\n",
      "          49       0.38      0.42      0.40        19\n",
      "          50       0.31      0.34      0.33        44\n",
      "          51       0.56      0.50      0.53        20\n",
      "          52       0.17      0.19      0.18        27\n",
      "          53       0.43      0.57      0.49        53\n",
      "          54       0.17      0.33      0.23        18\n",
      "          55       0.17      0.31      0.22        26\n",
      "          56       0.79      0.68      0.73        28\n",
      "          57       0.56      0.60      0.58       108\n",
      "          58       0.66      0.64      0.65       366\n",
      "          59       0.23      0.22      0.22        74\n",
      "          60       0.43      0.53      0.47        34\n",
      "          61       0.20      0.38      0.26        24\n",
      "          62       0.38      0.41      0.39        95\n",
      "          63       0.17      0.28      0.21        18\n",
      "          64       0.68      0.68      0.68        37\n",
      "          65       0.38      0.40      0.39        15\n",
      "          66       0.26      0.30      0.28        33\n",
      "          67       0.60      0.61      0.60       602\n",
      "          68       0.60      0.65      0.62       190\n",
      "          69       0.33      0.30      0.31       105\n",
      "          70       0.68      0.75      0.71        36\n",
      "          71       0.33      0.40      0.36        48\n",
      "          72       0.20      0.18      0.19        22\n",
      "          73       0.40      0.52      0.45        33\n",
      "          74       0.73      0.71      0.72        85\n",
      "          75       0.54      0.67      0.60        30\n",
      "          76       0.69      0.54      0.61        50\n",
      "          77       0.34      0.37      0.36        43\n",
      "          78       0.46      0.58      0.51       104\n",
      "          79       0.57      0.38      0.46       391\n",
      "          80       0.25      0.29      0.27        17\n",
      "          81       0.85      0.79      0.81        28\n",
      "          82       0.20      0.30      0.24        20\n",
      "          83       0.18      0.21      0.19        24\n",
      "          84       0.38      0.40      0.39        53\n",
      "          85       0.40      0.52      0.45        23\n",
      "          86       0.24      0.32      0.28        74\n",
      "          87       0.19      0.32      0.24        34\n",
      "          88       0.55      0.43      0.48       297\n",
      "          89       0.67      0.55      0.60        40\n",
      "          90       0.17      0.12      0.14        16\n",
      "          91       0.24      0.31      0.27        39\n",
      "          92       0.43      0.38      0.41        26\n",
      "          93       0.86      0.82      0.84        22\n",
      "          94       0.14      0.30      0.19        20\n",
      "          95       0.33      0.38      0.35        42\n",
      "          96       0.56      0.48      0.51        21\n",
      "          97       0.73      0.67      0.70        24\n",
      "          98       0.16      0.20      0.18        25\n",
      "          99       0.24      0.26      0.25        34\n",
      "         100       0.28      0.33      0.30        55\n",
      "         101       0.57      0.43      0.49       329\n",
      "         102       0.59      0.63      0.61        75\n",
      "         103       0.26      0.32      0.29        19\n",
      "         104       0.90      0.68      0.78        38\n",
      "         105       0.27      0.30      0.28        87\n",
      "         106       0.07      0.09      0.08        47\n",
      "         107       0.40      0.31      0.35        32\n",
      "         108       0.71      0.48      0.57        21\n",
      "         109       0.41      0.39      0.40       155\n",
      "         110       0.33      0.32      0.32        66\n",
      "         111       0.57      0.65      0.60        20\n",
      "         112       0.34      0.31      0.32        80\n",
      "         113       0.39      0.43      0.41        56\n",
      "         114       0.51      0.45      0.48       137\n",
      "         115       0.08      0.06      0.07        17\n",
      "         116       0.59      0.62      0.61       129\n",
      "         117       0.14      0.10      0.12        78\n",
      "         118       0.15      0.28      0.19        39\n",
      "         119       0.40      0.49      0.44        47\n",
      "         120       0.50      0.50      0.50        14\n",
      "         121       0.53      0.51      0.52       377\n",
      "         122       0.62      0.55      0.58        38\n",
      "         123       0.24      0.26      0.25        78\n",
      "         124       0.29      0.40      0.33        25\n",
      "         125       0.32      0.40      0.36        73\n",
      "         126       0.87      0.65      0.74        20\n",
      "         127       0.69      0.62      0.66       660\n",
      "         128       0.22      0.22      0.22        82\n",
      "         129       0.33      0.40      0.36        20\n",
      "         130       0.56      0.28      0.37        18\n",
      "         131       0.26      0.21      0.23       137\n",
      "         132       0.21      0.33      0.25        43\n",
      "         133       0.22      0.29      0.25        55\n",
      "         134       0.42      0.47      0.44        64\n",
      "         135       0.29      0.28      0.28        57\n",
      "         136       0.49      0.48      0.49        96\n",
      "         137       0.57      0.64      0.60        61\n",
      "         138       0.77      0.80      0.79      1969\n",
      "         139       0.48      0.54      0.50        54\n",
      "         140       0.14      0.25      0.18        16\n",
      "         141       0.20      0.32      0.25        25\n",
      "         142       0.44      0.41      0.42        17\n",
      "         143       0.28      0.20      0.23       298\n",
      "         144       0.14      0.17      0.16        41\n",
      "         145       0.42      0.53      0.47        83\n",
      "         146       0.50      0.60      0.55        25\n",
      "         147       0.13      0.16      0.14        25\n",
      "         148       0.44      0.38      0.41       209\n",
      "         149       0.25      0.07      0.11        15\n",
      "         150       0.36      0.43      0.39        61\n",
      "         151       0.41      0.35      0.38        20\n",
      "         152       0.38      0.45      0.41        20\n",
      "         153       0.31      0.32      0.31        34\n",
      "         154       0.65      0.62      0.64       144\n",
      "         155       0.58      0.48      0.53       387\n",
      "         156       0.20      0.25      0.22        56\n",
      "         157       0.47      0.29      0.36        24\n",
      "         158       0.30      0.41      0.35        51\n",
      "         159       0.53      0.43      0.48        23\n",
      "         160       0.19      0.20      0.20        44\n",
      "         161       0.61      0.55      0.58       240\n",
      "         162       0.46      0.48      0.47        27\n",
      "         163       0.58      0.37      0.45        19\n",
      "         164       0.47      0.38      0.42       161\n",
      "         165       0.47      0.48      0.48        66\n",
      "         166       0.33      0.37      0.35        70\n",
      "         167       0.80      0.70      0.75        61\n",
      "         168       0.28      0.26      0.27        92\n",
      "         169       0.57      0.76      0.65        34\n",
      "         170       0.29      0.38      0.33        37\n",
      "         171       0.38      0.32      0.35       223\n",
      "         172       0.06      0.12      0.08        24\n",
      "         173       0.71      0.67      0.69       248\n",
      "         174       0.56      0.43      0.49       191\n",
      "         175       0.20      0.30      0.24        53\n",
      "         176       0.58      0.49      0.53       236\n",
      "         177       0.26      0.33      0.29        39\n",
      "         178       0.70      0.58      0.64       201\n",
      "         179       0.15      0.26      0.19        31\n",
      "         180       0.64      0.66      0.65      1088\n",
      "         181       0.45      0.37      0.40       185\n",
      "         182       0.28      0.39      0.32        28\n",
      "         183       0.56      0.51      0.53       359\n",
      "         184       0.71      0.63      0.67        19\n",
      "         185       0.13      0.20      0.16        35\n",
      "         186       0.22      0.38      0.28        39\n",
      "         187       0.65      0.52      0.58        25\n",
      "\n",
      "   micro avg       0.52      0.52      0.52     18549\n",
      "   macro avg       0.42      0.42      0.41     18549\n",
      "weighted avg       0.54      0.52      0.52     18549\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Є невелике покращення в якості."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kNN+Doc2Vec\n",
    "\n",
    "Переходимо до Doc2Vec. Для цього використовуємо gensim. Спочатку конвертуємо наші документи в модель gensim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import TaggedDocument\n",
    "\n",
    "def to_tagged_doc(doc):\n",
    "    words = tokenize_doc(doc)\n",
    "    return TaggedDocument(words, [doc.topic_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=['заявляю', 'чергове', 'втручання', 'діяльність', 'інформаційної', 'системи', 'колцентру', 'метою', 'викривлення', 'відомостей', 'стосовно', 'результатів', 'вирішення', 'поданих', 'звернень', 'даний', 'відмітку', 'виконано', 'наводжу', 'витяг', 'березня', 'перегляд', 'інтерактивній', 'картівідсутність', 'гвп', 'відповідальний', 'кп', 'печерська', 'брама', 'мазурчак', 'олександр', 'володимирович', 'дата', 'контролю', 'березня', 'статус', 'виконано', 'відповідаю', 'дійсності', 'оскільки', 'годин', 'офіційно', 'отриманий', 'електронний', 'запит', 'виклав', 'текст', 'протилежного', 'змісту', 'наводжу', 'заявника', 'квітня', 'статус', 'виконано', 'квартира', 'розташована', 'му', 'під’їзді', 'відношення', 'перекриття', 'стояка', 'го', 'заміна', 'вентиля', 'сусідів', 'потребує', 'перекриття', 'водопостачання', 'будинку', 'викличе', 'появу', 'трубах', 'будинку', 'стільки', 'бруду', 'зливався', 'понад', 'хвилини', 'хвилину', 'вигаданих', 'нормативів', 'кму', 'скарги', 'взагалі', 'подавались', 'заради', 'отримання', 'пустих', 'роз’яснень', 'усунення', 'проблеми', 'рахунок', 'винуватців', 'поборами', 'див', 'договір', 'викликає', 'подив', 'подане', 'звернення', 'зареєстроване', 'оскільки', 'начебто', 'другу', 'добу', 'перевіряється', 'оператором', '???', 'наведене', 'криміналом', 'корупційними', 'діяннями', '!!!'], tags=[0])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_tagged_doc(uk_documents[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d101f49834d549f5846d72449e1360d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=43280), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_tagged_docs = [to_tagged_doc(doc) for doc in tqdm_notebook(train_documents)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8065043876c94903ad18008211334f86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=18549), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_tagged_docs = [to_tagged_doc(doc) for doc in tqdm_notebook(test_documents)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Потім тренуємо PV-DBOW модель. Розмір вектору документа 300, як і в моделі з embeddins, яку ми використовували в бейзлайні."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec\n",
    "\n",
    "dbow_model = Doc2Vec(dm=0, vector_size=300, min_count=5, window=10, workers=6, epochs=120)\n",
    "\n",
    "dbow_model.build_vocab(train_tagged_docs + test_tagged_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11min 54s, sys: 46.5 s, total: 12min 40s\n",
      "Wall time: 4min 40s\n"
     ]
    }
   ],
   "source": [
    "%time dbow_model.train(train_tagged_docs, total_examples=dbow_model.corpus_count, epochs=dbow_model.epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Збираємо вектори документів."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff796e8649de4b13a557c57f84d9f813",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=43280), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_doc_vecs = np.array([dbow_model.infer_vector(doc.words) for doc in tqdm_notebook(train_tagged_docs)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a939d4d5e01403ca92619e1fdca87f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=18549), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_doc_vecs = np.array([dbow_model.infer_vector(doc.words) for doc in tqdm_notebook(test_tagged_docs)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Знову намагаємося застосувати kNN та логістичну регресію на отриманних векторах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn2 = KnnModel(train_doc_vecs, train_topic_labels, test_doc_vecs, test_topic_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11min 38s, sys: 170 ms, total: 11min 38s\n",
      "Wall time: 2min 3s\n"
     ]
    }
   ],
   "source": [
    "%time knn2.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.59      0.60       335\n",
      "           1       0.76      0.83      0.79        41\n",
      "           2       0.55      0.53      0.54        79\n",
      "           3       0.48      0.54      0.51        39\n",
      "           4       0.60      0.55      0.57        22\n",
      "           5       0.52      0.75      0.61       106\n",
      "           6       0.42      0.32      0.37       142\n",
      "           7       0.55      0.52      0.53        62\n",
      "           8       0.45      0.97      0.61        30\n",
      "           9       0.51      0.86      0.64        22\n",
      "          10       0.77      0.89      0.82       144\n",
      "          11       0.56      0.17      0.26        29\n",
      "          12       0.81      0.59      0.68        22\n",
      "          13       0.67      0.53      0.59        45\n",
      "          14       0.29      0.17      0.21        84\n",
      "          15       0.41      0.44      0.42        16\n",
      "          16       0.48      0.64      0.55       122\n",
      "          17       0.50      0.25      0.33        16\n",
      "          18       0.31      0.28      0.29        53\n",
      "          19       0.31      0.21      0.25        19\n",
      "          20       0.38      0.31      0.34        16\n",
      "          21       0.64      0.38      0.47        24\n",
      "          22       0.67      0.54      0.60       194\n",
      "          23       0.68      0.86      0.76        51\n",
      "          24       0.58      0.53      0.56        47\n",
      "          25       0.55      0.61      0.58        28\n",
      "          26       0.44      0.60      0.51        25\n",
      "          27       0.62      0.82      0.71       943\n",
      "          28       0.65      0.61      0.63        56\n",
      "          29       0.52      0.40      0.45        63\n",
      "          30       0.29      0.27      0.28        44\n",
      "          31       0.15      0.12      0.13        25\n",
      "          32       0.77      0.73      0.75        95\n",
      "          33       0.75      0.78      0.77       129\n",
      "          34       0.44      0.60      0.51        45\n",
      "          35       0.38      0.23      0.29        35\n",
      "          36       0.40      0.34      0.37        50\n",
      "          37       0.44      0.20      0.28        40\n",
      "          38       0.59      0.67      0.63        39\n",
      "          39       0.52      0.52      0.52        44\n",
      "          40       0.48      0.68      0.56       115\n",
      "          41       0.55      0.61      0.58       143\n",
      "          42       0.66      0.71      0.68        62\n",
      "          43       0.62      0.71      0.66        41\n",
      "          44       0.32      0.38      0.35        29\n",
      "          45       0.66      0.35      0.46        71\n",
      "          46       0.74      0.75      0.74        56\n",
      "          47       0.27      0.33      0.30        21\n",
      "          48       0.23      0.19      0.21        16\n",
      "          49       0.50      0.74      0.60        19\n",
      "          50       0.62      0.64      0.63        44\n",
      "          51       0.62      0.40      0.48        20\n",
      "          52       0.41      0.26      0.32        27\n",
      "          53       0.49      0.58      0.53        53\n",
      "          54       0.44      0.44      0.44        18\n",
      "          55       0.31      0.19      0.24        26\n",
      "          56       0.77      0.82      0.79        28\n",
      "          57       0.61      0.57      0.59       108\n",
      "          58       0.67      0.79      0.73       366\n",
      "          59       0.44      0.42      0.43        74\n",
      "          60       0.67      0.35      0.46        34\n",
      "          61       0.43      0.42      0.43        24\n",
      "          62       0.52      0.59      0.55        95\n",
      "          63       0.17      0.33      0.23        18\n",
      "          64       0.50      0.86      0.63        37\n",
      "          65       0.57      0.53      0.55        15\n",
      "          66       0.39      0.27      0.32        33\n",
      "          67       0.58      0.65      0.61       602\n",
      "          68       0.63      0.56      0.59       190\n",
      "          69       0.39      0.37      0.38       105\n",
      "          70       0.68      0.75      0.71        36\n",
      "          71       0.78      0.38      0.51        48\n",
      "          72       0.27      0.18      0.22        22\n",
      "          73       0.47      0.61      0.53        33\n",
      "          74       0.75      0.92      0.83        85\n",
      "          75       0.53      0.83      0.65        30\n",
      "          76       0.67      0.62      0.65        50\n",
      "          77       0.51      0.88      0.64        43\n",
      "          78       0.62      0.52      0.57       104\n",
      "          79       0.42      0.44      0.43       391\n",
      "          80       0.25      0.12      0.16        17\n",
      "          81       0.66      0.89      0.76        28\n",
      "          82       0.31      0.55      0.39        20\n",
      "          83       0.19      0.17      0.18        24\n",
      "          84       0.48      0.28      0.36        53\n",
      "          85       0.71      0.52      0.60        23\n",
      "          86       0.52      0.34      0.41        74\n",
      "          87       0.56      0.41      0.47        34\n",
      "          88       0.52      0.39      0.45       297\n",
      "          89       0.66      0.78      0.71        40\n",
      "          90       0.50      0.19      0.27        16\n",
      "          91       0.46      0.33      0.39        39\n",
      "          92       0.38      0.35      0.36        26\n",
      "          93       0.67      1.00      0.80        22\n",
      "          94       0.13      0.30      0.18        20\n",
      "          95       0.13      0.17      0.15        42\n",
      "          96       0.45      0.48      0.47        21\n",
      "          97       0.50      0.79      0.61        24\n",
      "          98       0.33      0.32      0.33        25\n",
      "          99       0.35      0.47      0.40        34\n",
      "         100       0.45      0.35      0.39        55\n",
      "         101       0.71      0.50      0.59       329\n",
      "         102       0.91      0.91      0.91        75\n",
      "         103       0.52      0.63      0.57        19\n",
      "         104       0.76      0.89      0.82        38\n",
      "         105       0.33      0.25      0.29        87\n",
      "         106       0.37      0.32      0.34        47\n",
      "         107       0.60      0.47      0.53        32\n",
      "         108       0.70      0.67      0.68        21\n",
      "         109       0.49      0.52      0.51       155\n",
      "         110       0.38      0.23      0.29        66\n",
      "         111       0.64      0.80      0.71        20\n",
      "         112       0.65      0.66      0.66        80\n",
      "         113       0.76      0.50      0.60        56\n",
      "         114       0.53      0.59      0.56       137\n",
      "         115       0.24      0.24      0.24        17\n",
      "         116       0.63      0.67      0.65       129\n",
      "         117       0.28      0.22      0.25        78\n",
      "         118       0.63      0.31      0.41        39\n",
      "         119       0.37      0.40      0.39        47\n",
      "         120       0.36      0.64      0.46        14\n",
      "         121       0.56      0.61      0.58       377\n",
      "         122       0.57      0.68      0.62        38\n",
      "         123       0.38      0.47      0.42        78\n",
      "         124       0.42      0.20      0.27        25\n",
      "         125       0.36      0.23      0.28        73\n",
      "         126       0.60      0.75      0.67        20\n",
      "         127       0.75      0.74      0.74       660\n",
      "         128       0.41      0.35      0.38        82\n",
      "         129       0.62      0.40      0.48        20\n",
      "         130       0.88      0.39      0.54        18\n",
      "         131       0.43      0.30      0.35       137\n",
      "         132       0.28      0.42      0.34        43\n",
      "         133       0.54      0.38      0.45        55\n",
      "         134       0.56      0.56      0.56        64\n",
      "         135       0.45      0.30      0.36        57\n",
      "         136       0.65      0.64      0.64        96\n",
      "         137       0.60      0.69      0.64        61\n",
      "         138       0.80      0.86      0.83      1969\n",
      "         139       0.49      0.63      0.55        54\n",
      "         140       0.43      0.19      0.26        16\n",
      "         141       0.38      0.60      0.46        25\n",
      "         142       0.39      0.41      0.40        17\n",
      "         143       0.57      0.37      0.45       298\n",
      "         144       0.19      0.22      0.20        41\n",
      "         145       0.41      0.73      0.52        83\n",
      "         146       0.56      0.56      0.56        25\n",
      "         147       0.35      0.28      0.31        25\n",
      "         148       0.47      0.36      0.41       209\n",
      "         149       0.40      0.27      0.32        15\n",
      "         150       0.77      0.33      0.46        61\n",
      "         151       0.64      0.70      0.67        20\n",
      "         152       0.65      0.55      0.59        20\n",
      "         153       0.38      0.41      0.39        34\n",
      "         154       0.72      0.73      0.73       144\n",
      "         155       0.67      0.48      0.56       387\n",
      "         156       0.29      0.30      0.30        56\n",
      "         157       0.33      0.29      0.31        24\n",
      "         158       0.53      0.55      0.54        51\n",
      "         159       0.56      0.43      0.49        23\n",
      "         160       0.50      0.25      0.33        44\n",
      "         161       0.56      0.53      0.54       240\n",
      "         162       0.89      0.30      0.44        27\n",
      "         163       0.71      0.53      0.61        19\n",
      "         164       0.53      0.43      0.47       161\n",
      "         165       0.58      0.53      0.56        66\n",
      "         166       0.44      0.40      0.42        70\n",
      "         167       0.70      0.79      0.74        61\n",
      "         168       0.32      0.27      0.30        92\n",
      "         169       0.44      0.85      0.58        34\n",
      "         170       0.50      0.57      0.53        37\n",
      "         171       0.43      0.49      0.46       223\n",
      "         172       0.12      0.08      0.10        24\n",
      "         173       0.63      0.76      0.69       248\n",
      "         174       0.61      0.52      0.56       191\n",
      "         175       0.42      0.19      0.26        53\n",
      "         176       0.56      0.59      0.57       236\n",
      "         177       0.29      0.31      0.30        39\n",
      "         178       0.79      0.67      0.73       201\n",
      "         179       0.44      0.26      0.33        31\n",
      "         180       0.64      0.69      0.67      1088\n",
      "         181       0.49      0.40      0.44       185\n",
      "         182       0.46      0.46      0.46        28\n",
      "         183       0.68      0.52      0.59       359\n",
      "         184       0.52      0.68      0.59        19\n",
      "         185       0.31      0.14      0.20        35\n",
      "         186       0.50      0.46      0.48        39\n",
      "         187       0.50      0.36      0.42        25\n",
      "\n",
      "   micro avg       0.59      0.59      0.59     18549\n",
      "   macro avg       0.51      0.50      0.49     18549\n",
      "weighted avg       0.59      0.59      0.58     18549\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn2.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logreg+Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg2 = LogregModel(train_doc_vecs, train_topic_labels, test_doc_vecs, test_topic_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 245 ms, sys: 627 ms, total: 872 ms\n",
      "Wall time: 7min 18s\n"
     ]
    }
   ],
   "source": [
    "%time logreg2.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.51      0.56       335\n",
      "           1       0.93      0.63      0.75        41\n",
      "           2       0.52      0.46      0.49        79\n",
      "           3       0.56      0.46      0.51        39\n",
      "           4       0.82      0.41      0.55        22\n",
      "           5       0.68      0.66      0.67       106\n",
      "           6       0.36      0.37      0.36       142\n",
      "           7       0.62      0.45      0.52        62\n",
      "           8       0.59      0.63      0.61        30\n",
      "           9       0.61      0.50      0.55        22\n",
      "          10       0.77      0.87      0.81       144\n",
      "          11       0.71      0.17      0.28        29\n",
      "          12       1.00      0.41      0.58        22\n",
      "          13       0.60      0.40      0.48        45\n",
      "          14       0.28      0.24      0.26        84\n",
      "          15       0.56      0.56      0.56        16\n",
      "          16       0.52      0.57      0.54       122\n",
      "          17       0.83      0.31      0.45        16\n",
      "          18       0.34      0.36      0.35        53\n",
      "          19       0.57      0.21      0.31        19\n",
      "          20       0.80      0.25      0.38        16\n",
      "          21       0.67      0.25      0.36        24\n",
      "          22       0.59      0.56      0.58       194\n",
      "          23       0.86      0.86      0.86        51\n",
      "          24       0.66      0.45      0.53        47\n",
      "          25       0.73      0.57      0.64        28\n",
      "          26       0.56      0.36      0.44        25\n",
      "          27       0.69      0.73      0.71       943\n",
      "          28       0.66      0.70      0.68        56\n",
      "          29       0.45      0.49      0.47        63\n",
      "          30       0.22      0.23      0.22        44\n",
      "          31       0.15      0.08      0.11        25\n",
      "          32       0.80      0.75      0.77        95\n",
      "          33       0.79      0.76      0.77       129\n",
      "          34       0.46      0.58      0.51        45\n",
      "          35       0.40      0.17      0.24        35\n",
      "          36       0.32      0.30      0.31        50\n",
      "          37       0.53      0.20      0.29        40\n",
      "          38       0.74      0.79      0.77        39\n",
      "          39       0.58      0.48      0.53        44\n",
      "          40       0.57      0.67      0.62       115\n",
      "          41       0.54      0.58      0.56       143\n",
      "          42       0.61      0.69      0.65        62\n",
      "          43       0.57      0.76      0.65        41\n",
      "          44       0.38      0.28      0.32        29\n",
      "          45       0.55      0.42      0.48        71\n",
      "          46       0.78      0.71      0.75        56\n",
      "          47       0.40      0.38      0.39        21\n",
      "          48       0.09      0.06      0.07        16\n",
      "          49       0.90      0.47      0.62        19\n",
      "          50       0.72      0.59      0.65        44\n",
      "          51       0.82      0.45      0.58        20\n",
      "          52       0.46      0.22      0.30        27\n",
      "          53       0.58      0.64      0.61        53\n",
      "          54       0.31      0.28      0.29        18\n",
      "          55       0.58      0.27      0.37        26\n",
      "          56       0.94      0.57      0.71        28\n",
      "          57       0.62      0.58      0.60       108\n",
      "          58       0.72      0.77      0.75       366\n",
      "          59       0.52      0.39      0.45        74\n",
      "          60       0.60      0.26      0.37        34\n",
      "          61       0.47      0.33      0.39        24\n",
      "          62       0.48      0.53      0.50        95\n",
      "          63       0.33      0.22      0.27        18\n",
      "          64       0.75      0.81      0.78        37\n",
      "          65       1.00      0.27      0.42        15\n",
      "          66       0.69      0.27      0.39        33\n",
      "          67       0.66      0.71      0.68       602\n",
      "          68       0.65      0.66      0.65       190\n",
      "          69       0.41      0.39      0.40       105\n",
      "          70       0.85      0.81      0.83        36\n",
      "          71       0.62      0.38      0.47        48\n",
      "          72       0.45      0.23      0.30        22\n",
      "          73       0.59      0.52      0.55        33\n",
      "          74       0.84      0.92      0.88        85\n",
      "          75       0.71      0.73      0.72        30\n",
      "          76       0.61      0.76      0.68        50\n",
      "          77       0.81      0.67      0.73        43\n",
      "          78       0.67      0.66      0.67       104\n",
      "          79       0.43      0.42      0.42       391\n",
      "          80       0.22      0.12      0.15        17\n",
      "          81       0.83      0.54      0.65        28\n",
      "          82       0.29      0.35      0.32        20\n",
      "          83       0.35      0.25      0.29        24\n",
      "          84       0.52      0.30      0.38        53\n",
      "          85       0.80      0.35      0.48        23\n",
      "          86       0.53      0.45      0.49        74\n",
      "          87       0.71      0.35      0.47        34\n",
      "          88       0.50      0.51      0.51       297\n",
      "          89       0.70      0.70      0.70        40\n",
      "          90       1.00      0.19      0.32        16\n",
      "          91       0.39      0.31      0.34        39\n",
      "          92       0.44      0.27      0.33        26\n",
      "          93       1.00      0.77      0.87        22\n",
      "          94       0.26      0.25      0.26        20\n",
      "          95       0.18      0.21      0.20        42\n",
      "          96       0.88      0.33      0.48        21\n",
      "          97       0.53      0.71      0.61        24\n",
      "          98       0.77      0.40      0.53        25\n",
      "          99       0.50      0.50      0.50        34\n",
      "         100       0.46      0.44      0.45        55\n",
      "         101       0.50      0.64      0.56       329\n",
      "         102       0.87      0.88      0.87        75\n",
      "         103       0.69      0.58      0.63        19\n",
      "         104       0.94      0.76      0.84        38\n",
      "         105       0.37      0.30      0.33        87\n",
      "         106       0.28      0.23      0.25        47\n",
      "         107       0.64      0.44      0.52        32\n",
      "         108       0.83      0.48      0.61        21\n",
      "         109       0.52      0.55      0.53       155\n",
      "         110       0.41      0.26      0.32        66\n",
      "         111       0.92      0.60      0.73        20\n",
      "         112       0.63      0.74      0.68        80\n",
      "         113       0.71      0.52      0.60        56\n",
      "         114       0.53      0.54      0.54       137\n",
      "         115       0.20      0.12      0.15        17\n",
      "         116       0.71      0.76      0.73       129\n",
      "         117       0.39      0.22      0.28        78\n",
      "         118       0.45      0.26      0.33        39\n",
      "         119       0.47      0.40      0.44        47\n",
      "         120       0.71      0.36      0.48        14\n",
      "         121       0.58      0.65      0.61       377\n",
      "         122       0.73      0.58      0.65        38\n",
      "         123       0.40      0.44      0.41        78\n",
      "         124       0.50      0.24      0.32        25\n",
      "         125       0.45      0.30      0.36        73\n",
      "         126       0.88      0.75      0.81        20\n",
      "         127       0.66      0.80      0.73       660\n",
      "         128       0.38      0.27      0.31        82\n",
      "         129       0.78      0.35      0.48        20\n",
      "         130       0.80      0.22      0.35        18\n",
      "         131       0.27      0.32      0.29       137\n",
      "         132       0.24      0.28      0.26        43\n",
      "         133       0.46      0.33      0.38        55\n",
      "         134       0.59      0.62      0.61        64\n",
      "         135       0.42      0.35      0.38        57\n",
      "         136       0.74      0.65      0.69        96\n",
      "         137       0.67      0.77      0.72        61\n",
      "         138       0.77      0.86      0.81      1969\n",
      "         139       0.58      0.57      0.58        54\n",
      "         140       1.00      0.25      0.40        16\n",
      "         141       0.63      0.48      0.55        25\n",
      "         142       0.57      0.24      0.33        17\n",
      "         143       0.36      0.40      0.38       298\n",
      "         144       0.22      0.22      0.22        41\n",
      "         145       0.60      0.71      0.65        83\n",
      "         146       0.56      0.56      0.56        25\n",
      "         147       0.37      0.28      0.32        25\n",
      "         148       0.45      0.51      0.48       209\n",
      "         149       0.71      0.33      0.45        15\n",
      "         150       0.56      0.33      0.41        61\n",
      "         151       0.64      0.35      0.45        20\n",
      "         152       0.57      0.40      0.47        20\n",
      "         153       0.28      0.32      0.30        34\n",
      "         154       0.76      0.74      0.75       144\n",
      "         155       0.54      0.56      0.55       387\n",
      "         156       0.38      0.43      0.40        56\n",
      "         157       0.32      0.33      0.33        24\n",
      "         158       0.59      0.51      0.55        51\n",
      "         159       0.62      0.43      0.51        23\n",
      "         160       0.68      0.34      0.45        44\n",
      "         161       0.55      0.58      0.56       240\n",
      "         162       1.00      0.30      0.46        27\n",
      "         163       1.00      0.37      0.54        19\n",
      "         164       0.53      0.49      0.51       161\n",
      "         165       0.59      0.55      0.57        66\n",
      "         166       0.47      0.41      0.44        70\n",
      "         167       0.87      0.66      0.75        61\n",
      "         168       0.30      0.36      0.33        92\n",
      "         169       0.49      0.68      0.57        34\n",
      "         170       0.61      0.51      0.56        37\n",
      "         171       0.41      0.41      0.41       223\n",
      "         172       0.13      0.12      0.13        24\n",
      "         173       0.70      0.74      0.72       248\n",
      "         174       0.53      0.51      0.52       191\n",
      "         175       0.44      0.28      0.34        53\n",
      "         176       0.59      0.56      0.58       236\n",
      "         177       0.41      0.36      0.38        39\n",
      "         178       0.73      0.70      0.71       201\n",
      "         179       0.37      0.32      0.34        31\n",
      "         180       0.60      0.75      0.67      1088\n",
      "         181       0.53      0.45      0.49       185\n",
      "         182       0.36      0.46      0.41        28\n",
      "         183       0.55      0.63      0.59       359\n",
      "         184       0.83      0.53      0.65        19\n",
      "         185       0.42      0.14      0.21        35\n",
      "         186       0.52      0.44      0.47        39\n",
      "         187       0.77      0.40      0.53        25\n",
      "\n",
      "   micro avg       0.60      0.60      0.60     18549\n",
      "   macro avg       0.58      0.47      0.50     18549\n",
      "weighted avg       0.60      0.60      0.59     18549\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg2.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks Approach\n",
    "\n",
    "Спробуємо використати нейронні мережі для покращення якості."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FFN+Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1' #CNN doesn't work on my PC on GPU due to libraries incompatibility, comment to use GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Input, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "\n",
    "class NnModel(Model):\n",
    "    def __init__(self, train_vectors, train_labels, test_vectors, test_labels):\n",
    "        super().__init__(train_vectors, \n",
    "                         to_categorical(train_labels), \n",
    "                         test_vectors, \n",
    "                         test_labels)\n",
    "    \n",
    "    def train(self, epochs = 10):\n",
    "        self.history = self.model.fit(self.train_vectors, self.train_labels,\n",
    "                                      epochs = epochs, batch_size=128, \n",
    "                                      verbose=0, callbacks=[TQDMNotebookCallback()])\n",
    "        self.topics_predicted = np.argmax(self.model.predict(self.test_vectors), axis=-1)\n",
    "    \n",
    "\n",
    "class FeedForwardNN(NnModel):\n",
    "    def __init__(self, train_vectors, train_labels, test_vectors, test_labels,\n",
    "                 input_size, hidden_size):\n",
    "        super().__init__(train_vectors, \n",
    "                         train_labels, \n",
    "                         test_vectors, \n",
    "                         test_labels)               \n",
    "        self.model = Sequential()\n",
    "        self.model.add(Dense(hidden_size, activation='relu', input_shape=(input_size,)))        \n",
    "        self.model.add(Dense(188, activation='softmax'))\n",
    "        self.model.summary()\n",
    "        self.model.compile(optimizer=RMSprop(lr=1e-4),\n",
    "                           loss='categorical_crossentropy',\n",
    "                           metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/szubovych/.virtualenvs/nlp/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1024)              308224    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 188)               192700    \n",
      "=================================================================\n",
      "Total params: 500,924\n",
      "Trainable params: 500,924\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ff_model = FeedForwardNN(train_doc_vecs, train_topic_labels, test_doc_vecs, test_topic_labels, 300, 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b2ef963bbd047dd82b2df62905c1391",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training', max=10, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 0', max=43280, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 1', max=43280, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 2', max=43280, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 3', max=43280, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 4', max=43280, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 5', max=43280, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 6', max=43280, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 7', max=43280, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 8', max=43280, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 9', max=43280, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ff_model.train(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.53      0.58       335\n",
      "           1       0.97      0.73      0.83        41\n",
      "           2       0.54      0.47      0.50        79\n",
      "           3       0.47      0.59      0.52        39\n",
      "           4       0.91      0.45      0.61        22\n",
      "           5       0.63      0.77      0.69       106\n",
      "           6       0.39      0.32      0.36       142\n",
      "           7       0.65      0.69      0.67        62\n",
      "           8       0.67      0.60      0.63        30\n",
      "           9       0.93      0.59      0.72        22\n",
      "          10       0.80      0.88      0.84       144\n",
      "          11       0.78      0.24      0.37        29\n",
      "          12       1.00      0.55      0.71        22\n",
      "          13       0.64      0.47      0.54        45\n",
      "          14       0.37      0.23      0.28        84\n",
      "          15       0.80      0.50      0.62        16\n",
      "          16       0.50      0.68      0.58       122\n",
      "          17       0.83      0.31      0.45        16\n",
      "          18       0.34      0.38      0.36        53\n",
      "          19       0.71      0.26      0.38        19\n",
      "          20       0.80      0.25      0.38        16\n",
      "          21       0.75      0.38      0.50        24\n",
      "          22       0.71      0.62      0.66       194\n",
      "          23       0.91      0.82      0.87        51\n",
      "          24       0.71      0.53      0.61        47\n",
      "          25       0.80      0.57      0.67        28\n",
      "          26       0.48      0.40      0.43        25\n",
      "          27       0.69      0.78      0.73       943\n",
      "          28       0.66      0.73      0.69        56\n",
      "          29       0.40      0.52      0.46        63\n",
      "          30       0.38      0.25      0.30        44\n",
      "          31       0.21      0.12      0.15        25\n",
      "          32       0.84      0.74      0.79        95\n",
      "          33       0.80      0.78      0.79       129\n",
      "          34       0.55      0.60      0.57        45\n",
      "          35       0.52      0.31      0.39        35\n",
      "          36       0.43      0.40      0.41        50\n",
      "          37       0.47      0.23      0.31        40\n",
      "          38       0.81      0.67      0.73        39\n",
      "          39       0.62      0.55      0.58        44\n",
      "          40       0.65      0.71      0.68       115\n",
      "          41       0.59      0.58      0.59       143\n",
      "          42       0.60      0.61      0.61        62\n",
      "          43       0.65      0.76      0.70        41\n",
      "          44       0.67      0.21      0.32        29\n",
      "          45       0.51      0.49      0.50        71\n",
      "          46       0.79      0.73      0.76        56\n",
      "          47       0.53      0.43      0.47        21\n",
      "          48       0.09      0.06      0.07        16\n",
      "          49       0.72      0.68      0.70        19\n",
      "          50       0.83      0.55      0.66        44\n",
      "          51       0.82      0.45      0.58        20\n",
      "          52       0.71      0.19      0.29        27\n",
      "          53       0.65      0.58      0.61        53\n",
      "          54       0.50      0.17      0.25        18\n",
      "          55       0.75      0.23      0.35        26\n",
      "          56       0.94      0.61      0.74        28\n",
      "          57       0.61      0.61      0.61       108\n",
      "          58       0.72      0.78      0.75       366\n",
      "          59       0.46      0.45      0.45        74\n",
      "          60       0.70      0.41      0.52        34\n",
      "          61       0.56      0.42      0.48        24\n",
      "          62       0.48      0.57      0.52        95\n",
      "          63       0.50      0.22      0.31        18\n",
      "          64       0.81      0.81      0.81        37\n",
      "          65       0.62      0.33      0.43        15\n",
      "          66       0.77      0.30      0.43        33\n",
      "          67       0.66      0.71      0.69       602\n",
      "          68       0.61      0.78      0.69       190\n",
      "          69       0.39      0.37      0.38       105\n",
      "          70       0.81      0.81      0.81        36\n",
      "          71       0.66      0.48      0.55        48\n",
      "          72       0.41      0.32      0.36        22\n",
      "          73       0.65      0.45      0.54        33\n",
      "          74       0.88      0.95      0.92        85\n",
      "          75       0.75      0.70      0.72        30\n",
      "          76       0.77      0.60      0.67        50\n",
      "          77       0.70      0.65      0.67        43\n",
      "          78       0.71      0.63      0.67       104\n",
      "          79       0.45      0.40      0.42       391\n",
      "          80       0.50      0.06      0.11        17\n",
      "          81       0.83      0.54      0.65        28\n",
      "          82       0.38      0.30      0.33        20\n",
      "          83       0.50      0.25      0.33        24\n",
      "          84       0.53      0.30      0.39        53\n",
      "          85       0.70      0.30      0.42        23\n",
      "          86       0.52      0.46      0.49        74\n",
      "          87       0.65      0.32      0.43        34\n",
      "          88       0.55      0.53      0.54       297\n",
      "          89       0.72      0.78      0.75        40\n",
      "          90       0.75      0.19      0.30        16\n",
      "          91       0.42      0.33      0.37        39\n",
      "          92       0.33      0.50      0.40        26\n",
      "          93       1.00      0.59      0.74        22\n",
      "          94       0.20      0.10      0.13        20\n",
      "          95       0.30      0.26      0.28        42\n",
      "          96       0.71      0.48      0.57        21\n",
      "          97       0.53      0.67      0.59        24\n",
      "          98       0.50      0.36      0.42        25\n",
      "          99       0.55      0.50      0.52        34\n",
      "         100       0.66      0.35      0.45        55\n",
      "         101       0.56      0.66      0.61       329\n",
      "         102       0.93      0.91      0.92        75\n",
      "         103       0.82      0.47      0.60        19\n",
      "         104       0.97      0.76      0.85        38\n",
      "         105       0.37      0.38      0.37        87\n",
      "         106       0.32      0.23      0.27        47\n",
      "         107       0.65      0.47      0.55        32\n",
      "         108       0.73      0.52      0.61        21\n",
      "         109       0.56      0.52      0.54       155\n",
      "         110       0.37      0.23      0.28        66\n",
      "         111       1.00      0.80      0.89        20\n",
      "         112       0.65      0.78      0.71        80\n",
      "         113       0.76      0.46      0.58        56\n",
      "         114       0.54      0.49      0.51       137\n",
      "         115       0.33      0.18      0.23        17\n",
      "         116       0.72      0.81      0.76       129\n",
      "         117       0.47      0.23      0.31        78\n",
      "         118       0.59      0.26      0.36        39\n",
      "         119       0.65      0.43      0.51        47\n",
      "         120       0.78      0.50      0.61        14\n",
      "         121       0.58      0.69      0.63       377\n",
      "         122       0.76      0.68      0.72        38\n",
      "         123       0.42      0.45      0.43        78\n",
      "         124       0.64      0.28      0.39        25\n",
      "         125       0.45      0.30      0.36        73\n",
      "         126       0.83      0.75      0.79        20\n",
      "         127       0.67      0.84      0.74       660\n",
      "         128       0.44      0.32      0.37        82\n",
      "         129       0.86      0.30      0.44        20\n",
      "         130       1.00      0.06      0.11        18\n",
      "         131       0.35      0.36      0.35       137\n",
      "         132       0.30      0.28      0.29        43\n",
      "         133       0.51      0.35      0.41        55\n",
      "         134       0.66      0.66      0.66        64\n",
      "         135       0.57      0.47      0.52        57\n",
      "         136       0.70      0.74      0.72        96\n",
      "         137       0.75      0.72      0.73        61\n",
      "         138       0.77      0.86      0.81      1969\n",
      "         139       0.66      0.50      0.57        54\n",
      "         140       1.00      0.19      0.32        16\n",
      "         141       0.65      0.44      0.52        25\n",
      "         142       0.50      0.24      0.32        17\n",
      "         143       0.31      0.50      0.38       298\n",
      "         144       0.31      0.12      0.18        41\n",
      "         145       0.66      0.71      0.68        83\n",
      "         146       0.68      0.52      0.59        25\n",
      "         147       0.55      0.24      0.33        25\n",
      "         148       0.50      0.54      0.52       209\n",
      "         149       0.62      0.33      0.43        15\n",
      "         150       0.66      0.44      0.53        61\n",
      "         151       0.75      0.45      0.56        20\n",
      "         152       0.69      0.45      0.55        20\n",
      "         153       0.47      0.26      0.34        34\n",
      "         154       0.84      0.74      0.79       144\n",
      "         155       0.59      0.56      0.58       387\n",
      "         156       0.70      0.38      0.49        56\n",
      "         157       0.44      0.29      0.35        24\n",
      "         158       0.56      0.39      0.46        51\n",
      "         159       0.77      0.43      0.56        23\n",
      "         160       0.70      0.32      0.44        44\n",
      "         161       0.62      0.57      0.59       240\n",
      "         162       0.78      0.26      0.39        27\n",
      "         163       0.88      0.37      0.52        19\n",
      "         164       0.54      0.55      0.54       161\n",
      "         165       0.73      0.55      0.63        66\n",
      "         166       0.46      0.46      0.46        70\n",
      "         167       0.80      0.70      0.75        61\n",
      "         168       0.31      0.39      0.35        92\n",
      "         169       0.53      0.62      0.57        34\n",
      "         170       0.71      0.54      0.62        37\n",
      "         171       0.43      0.41      0.42       223\n",
      "         172       0.12      0.08      0.10        24\n",
      "         173       0.70      0.70      0.70       248\n",
      "         174       0.58      0.60      0.59       191\n",
      "         175       0.41      0.28      0.33        53\n",
      "         176       0.63      0.61      0.62       236\n",
      "         177       0.47      0.38      0.42        39\n",
      "         178       0.76      0.75      0.76       201\n",
      "         179       0.43      0.29      0.35        31\n",
      "         180       0.59      0.79      0.68      1088\n",
      "         181       0.59      0.40      0.48       185\n",
      "         182       0.41      0.46      0.43        28\n",
      "         183       0.56      0.69      0.62       359\n",
      "         184       0.76      0.68      0.72        19\n",
      "         185       0.36      0.14      0.20        35\n",
      "         186       0.54      0.51      0.53        39\n",
      "         187       0.65      0.52      0.58        25\n",
      "\n",
      "   micro avg       0.62      0.62      0.62     18549\n",
      "   macro avg       0.62      0.48      0.53     18549\n",
      "weighted avg       0.62      0.62      0.61     18549\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ff_model.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FFN+sum vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 1024)              308224    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 188)               192700    \n",
      "=================================================================\n",
      "Total params: 500,924\n",
      "Trainable params: 500,924\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ff_sum_model = FeedForwardNN(train_doc_sum_vecs, train_topic_labels, \n",
    "                             test_doc_sum_vecs, test_topic_labels, 300, 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d832747a2f884321ab26a2baf2715ef8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training', max=5, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 0', max=43280, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 1', max=43280, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 2', max=43280, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 3', max=43280, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 4', max=43280, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ff_sum_model.train(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.59      0.60       335\n",
      "           1       0.84      0.78      0.81        41\n",
      "           2       0.65      0.59      0.62        79\n",
      "           3       0.35      0.51      0.42        39\n",
      "           4       0.82      0.41      0.55        22\n",
      "           5       0.48      0.51      0.49       106\n",
      "           6       0.31      0.26      0.28       142\n",
      "           7       0.54      0.55      0.54        62\n",
      "           8       0.67      0.53      0.59        30\n",
      "           9       0.80      0.55      0.65        22\n",
      "          10       0.70      0.76      0.73       144\n",
      "          11       0.00      0.00      0.00        29\n",
      "          12       0.86      0.55      0.67        22\n",
      "          13       0.47      0.42      0.45        45\n",
      "          14       0.23      0.20      0.22        84\n",
      "          15       0.64      0.44      0.52        16\n",
      "          16       0.68      0.54      0.60       122\n",
      "          17       0.44      0.44      0.44        16\n",
      "          18       0.32      0.30      0.31        53\n",
      "          19       0.50      0.32      0.39        19\n",
      "          20       0.00      0.00      0.00        16\n",
      "          21       0.35      0.25      0.29        24\n",
      "          22       0.63      0.62      0.62       194\n",
      "          23       0.86      0.73      0.79        51\n",
      "          24       0.59      0.55      0.57        47\n",
      "          25       0.43      0.36      0.39        28\n",
      "          26       0.59      0.40      0.48        25\n",
      "          27       0.69      0.78      0.73       943\n",
      "          28       0.50      0.43      0.46        56\n",
      "          29       0.37      0.49      0.42        63\n",
      "          30       0.29      0.18      0.22        44\n",
      "          31       0.17      0.04      0.06        25\n",
      "          32       0.71      0.63      0.67        95\n",
      "          33       0.79      0.74      0.76       129\n",
      "          34       0.63      0.53      0.58        45\n",
      "          35       0.25      0.20      0.22        35\n",
      "          36       0.47      0.30      0.37        50\n",
      "          37       0.13      0.17      0.15        40\n",
      "          38       0.84      0.67      0.74        39\n",
      "          39       0.45      0.39      0.41        44\n",
      "          40       0.62      0.68      0.65       115\n",
      "          41       0.51      0.52      0.51       143\n",
      "          42       0.61      0.55      0.58        62\n",
      "          43       0.64      0.56      0.60        41\n",
      "          44       0.54      0.24      0.33        29\n",
      "          45       0.54      0.54      0.54        71\n",
      "          46       0.70      0.68      0.69        56\n",
      "          47       0.24      0.19      0.21        21\n",
      "          48       0.00      0.00      0.00        16\n",
      "          49       0.75      0.32      0.44        19\n",
      "          50       0.56      0.20      0.30        44\n",
      "          51       0.52      0.55      0.54        20\n",
      "          52       0.25      0.26      0.25        27\n",
      "          53       0.60      0.55      0.57        53\n",
      "          54       0.75      0.17      0.27        18\n",
      "          55       0.50      0.08      0.13        26\n",
      "          56       0.00      0.00      0.00        28\n",
      "          57       0.64      0.62      0.63       108\n",
      "          58       0.74      0.66      0.70       366\n",
      "          59       0.29      0.34      0.31        74\n",
      "          60       0.00      0.00      0.00        34\n",
      "          61       0.00      0.00      0.00        24\n",
      "          62       0.48      0.47      0.48        95\n",
      "          63       0.55      0.33      0.41        18\n",
      "          64       0.83      0.78      0.81        37\n",
      "          65       0.00      0.00      0.00        15\n",
      "          66       0.42      0.33      0.37        33\n",
      "          67       0.58      0.69      0.63       602\n",
      "          68       0.62      0.73      0.67       190\n",
      "          69       0.43      0.43      0.43       105\n",
      "          70       0.00      0.00      0.00        36\n",
      "          71       0.34      0.25      0.29        48\n",
      "          72       0.36      0.18      0.24        22\n",
      "          73       0.56      0.45      0.50        33\n",
      "          74       0.82      0.73      0.77        85\n",
      "          75       0.76      0.53      0.63        30\n",
      "          76       0.76      0.62      0.68        50\n",
      "          77       0.43      0.42      0.42        43\n",
      "          78       0.57      0.56      0.56       104\n",
      "          79       0.51      0.53      0.52       391\n",
      "          80       0.30      0.18      0.22        17\n",
      "          81       0.00      0.00      0.00        28\n",
      "          82       0.19      0.25      0.21        20\n",
      "          83       0.38      0.12      0.19        24\n",
      "          84       0.00      0.00      0.00        53\n",
      "          85       0.40      0.26      0.32        23\n",
      "          86       0.33      0.30      0.31        74\n",
      "          87       0.00      0.00      0.00        34\n",
      "          88       0.58      0.52      0.55       297\n",
      "          89       0.76      0.55      0.64        40\n",
      "          90       0.00      0.00      0.00        16\n",
      "          91       0.55      0.31      0.39        39\n",
      "          92       0.26      0.35      0.30        26\n",
      "          93       0.00      0.00      0.00        22\n",
      "          94       0.46      0.30      0.36        20\n",
      "          95       0.31      0.26      0.28        42\n",
      "          96       0.71      0.24      0.36        21\n",
      "          97       0.64      0.58      0.61        24\n",
      "          98       0.36      0.32      0.34        25\n",
      "          99       0.43      0.35      0.39        34\n",
      "         100       0.45      0.45      0.45        55\n",
      "         101       0.52      0.67      0.58       329\n",
      "         102       0.69      0.61      0.65        75\n",
      "         103       0.45      0.47      0.46        19\n",
      "         104       0.85      0.76      0.81        38\n",
      "         105       0.33      0.30      0.32        87\n",
      "         106       0.29      0.23      0.26        47\n",
      "         107       0.50      0.44      0.47        32\n",
      "         108       0.00      0.00      0.00        21\n",
      "         109       0.41      0.39      0.40       155\n",
      "         110       0.49      0.38      0.43        66\n",
      "         111       0.82      0.70      0.76        20\n",
      "         112       0.39      0.36      0.38        80\n",
      "         113       0.60      0.43      0.50        56\n",
      "         114       0.45      0.51      0.48       137\n",
      "         115       0.22      0.12      0.15        17\n",
      "         116       0.71      0.75      0.73       129\n",
      "         117       0.22      0.22      0.22        78\n",
      "         118       0.34      0.28      0.31        39\n",
      "         119       0.60      0.51      0.55        47\n",
      "         120       0.00      0.00      0.00        14\n",
      "         121       0.56      0.59      0.57       377\n",
      "         122       0.61      0.58      0.59        38\n",
      "         123       0.43      0.40      0.41        78\n",
      "         124       0.47      0.28      0.35        25\n",
      "         125       0.43      0.40      0.41        73\n",
      "         126       0.88      0.70      0.78        20\n",
      "         127       0.61      0.76      0.68       660\n",
      "         128       0.25      0.28      0.27        82\n",
      "         129       0.00      0.00      0.00        20\n",
      "         130       0.00      0.00      0.00        18\n",
      "         131       0.30      0.36      0.33       137\n",
      "         132       0.27      0.35      0.31        43\n",
      "         133       0.39      0.27      0.32        55\n",
      "         134       0.52      0.50      0.51        64\n",
      "         135       0.37      0.30      0.33        57\n",
      "         136       0.58      0.56      0.57        96\n",
      "         137       0.62      0.51      0.56        61\n",
      "         138       0.77      0.86      0.81      1969\n",
      "         139       0.63      0.44      0.52        54\n",
      "         140       0.00      0.00      0.00        16\n",
      "         141       0.47      0.32      0.38        25\n",
      "         142       0.86      0.35      0.50        17\n",
      "         143       0.32      0.44      0.37       298\n",
      "         144       0.17      0.15      0.16        41\n",
      "         145       0.70      0.58      0.63        83\n",
      "         146       0.00      0.00      0.00        25\n",
      "         147       0.21      0.20      0.20        25\n",
      "         148       0.38      0.59      0.46       209\n",
      "         149       0.88      0.47      0.61        15\n",
      "         150       0.67      0.48      0.56        61\n",
      "         151       0.45      0.50      0.48        20\n",
      "         152       0.50      0.25      0.33        20\n",
      "         153       0.52      0.47      0.49        34\n",
      "         154       0.66      0.71      0.68       144\n",
      "         155       0.49      0.71      0.58       387\n",
      "         156       0.35      0.32      0.33        56\n",
      "         157       0.42      0.21      0.28        24\n",
      "         158       0.65      0.43      0.52        51\n",
      "         159       0.62      0.43      0.51        23\n",
      "         160       0.39      0.27      0.32        44\n",
      "         161       0.52      0.56      0.54       240\n",
      "         162       0.00      0.00      0.00        27\n",
      "         163       0.82      0.47      0.60        19\n",
      "         164       0.40      0.45      0.42       161\n",
      "         165       0.54      0.44      0.48        66\n",
      "         166       0.53      0.44      0.48        70\n",
      "         167       0.82      0.67      0.74        61\n",
      "         168       0.36      0.38      0.37        92\n",
      "         169       0.70      0.76      0.73        34\n",
      "         170       0.42      0.41      0.41        37\n",
      "         171       0.37      0.41      0.39       223\n",
      "         172       0.15      0.08      0.11        24\n",
      "         173       0.64      0.79      0.71       248\n",
      "         174       0.58      0.51      0.54       191\n",
      "         175       0.39      0.28      0.33        53\n",
      "         176       0.60      0.57      0.59       236\n",
      "         177       0.45      0.36      0.40        39\n",
      "         178       0.68      0.65      0.66       201\n",
      "         179       0.33      0.23      0.27        31\n",
      "         180       0.68      0.66      0.67      1088\n",
      "         181       0.45      0.57      0.50       185\n",
      "         182       0.64      0.32      0.43        28\n",
      "         183       0.55      0.66      0.60       359\n",
      "         184       0.73      0.58      0.65        19\n",
      "         185       0.50      0.26      0.34        35\n",
      "         186       0.46      0.31      0.37        39\n",
      "         187       0.55      0.48      0.51        25\n",
      "\n",
      "   micro avg       0.57      0.57      0.57     18549\n",
      "   macro avg       0.47      0.40      0.42     18549\n",
      "weighted avg       0.56      0.57      0.56     18549\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ff_sum_model.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134451"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "\n",
    "vocab = Dictionary([doc.words for doc in (train_tagged_docs + test_tagged_docs)])\n",
    "\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48553\n"
     ]
    }
   ],
   "source": [
    "vocab.filter_extremes(no_below = 3, no_above = 0.9, keep_n = 50000)\n",
    "\n",
    "MAX_WORDS_NUM = len(vocab) + 1\n",
    "\n",
    "print(MAX_WORDS_NUM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2token = dict([(i, token)for token, i in vocab.token2id.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_sequence(words):\n",
    "    return [i + 1 for i in vocab.doc2idx(words)]\n",
    "\n",
    "def sequence_to_text(seq):\n",
    "    return [id2token[i - 1] for i in seq if i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43280"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sequences = [text_to_sequence(doc.words) for doc in train_tagged_docs]\n",
    "\n",
    "len(train_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 11, 20, 15, 2, 5, 16, 13, 10, 25, 22, 8, 1, 7, 14, 9, 3, 18, 24, 4, 12, 21, 17, 25, 19, 23]\n"
     ]
    }
   ],
   "source": [
    "print(train_sequences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['повідомляємо', 'протязі', 'тижня', 'прохання', 'мешканців', 'квартир', 'будинку', 'вул', 'жолудєва', 'поверх', 'замініти', 'лампочку', 'можливо', 'причина', 'світильники', 'загальному', 'коридорі', 'сотрудники', 'рєо', 'відмовляють', 'відсутністью', 'лампочек', 'просимо', 'допомогти', 'вирішенні', 'питання', 'освітлення', 'загального', 'коридору']\n"
     ]
    }
   ],
   "source": [
    "print(sequence_to_text(train_sequences[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18549"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sequences = [text_to_sequence(doc.words) for doc in test_tagged_docs]\n",
    "\n",
    "len(test_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = train_sequences + test_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Length: 39.9\n",
      "Max Length: 235\n"
     ]
    }
   ],
   "source": [
    "seq_lens = [len(s) for s in sequences]\n",
    "print(\"Average Length: %0.1f\" % np.mean(seq_lens))\n",
    "print(\"Max Length: %d\" % max(seq_lens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(seq_lens, bins=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43280, 235)\n",
      "(18549, 235)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "MAX_SEQ_LEN = 235\n",
    "\n",
    "train_padded_seqs = pad_sequences(train_sequences, maxlen = MAX_SEQ_LEN)\n",
    "test_padded_seqs = pad_sequences(test_sequences, maxlen = MAX_SEQ_LEN)\n",
    "\n",
    "print(train_padded_seqs.shape)\n",
    "print(test_padded_seqs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import LSTM, Embedding, Dense, Input, SpatialDropout1D, Dropout\n",
    "\n",
    "class LstmModel(NnModel):\n",
    "    def __init__(self, train_vectors, train_labels, test_vectors, test_labels,\n",
    "                 embedding_dim, memory_units):\n",
    "        super().__init__(train_vectors, \n",
    "                         train_labels, \n",
    "                         test_vectors, \n",
    "                         test_labels)\n",
    "        self.model = Sequential()\n",
    "        self.model.add(Embedding(MAX_WORDS_NUM, embedding_dim, input_length = MAX_SEQ_LEN))\n",
    "        self.model.add(Dropout(0.2))        \n",
    "        self.model.add(LSTM(memory_units, dropout=0.2, recurrent_dropout=0.2))        \n",
    "        self.model.add(Dense(188, activation='softmax'))\n",
    "        self.model.summary()\n",
    "        self.model.compile(optimizer=RMSprop(lr=1e-3),\n",
    "                           loss='categorical_crossentropy',\n",
    "                           metrics=['acc'])        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/szubovych/.virtualenvs/nlp/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 235, 100)          4855300   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 235, 100)          0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 188)               18988     \n",
      "=================================================================\n",
      "Total params: 4,954,688\n",
      "Trainable params: 4,954,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm_model = LstmModel(train_padded_seqs, train_topic_labels, test_padded_seqs, test_topic_labels, 100, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fcfc91ef6e74264a937e73647afdaa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training', max=25, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 0', max=43280, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 1', max=43280, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 2', max=43280, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 3', max=43280, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 4', max=43280, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 5', max=43280, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 6', max=43280, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 7', max=43280, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 8', max=43280, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 9', max=43280, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 10', max=43280, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 11', max=43280, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 12', max=43280, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 13', max=43280, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 14', max=43280, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 15', max=43280, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 16', max=43280, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 17', max=43280, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 18', max=43280, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 19', max=43280, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 20', max=43280, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 21', max=43280, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 22', max=43280, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 23', max=43280, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 24', max=43280, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lstm_model.train(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.57      0.63       335\n",
      "           1       0.74      0.71      0.72        41\n",
      "           2       0.64      0.46      0.53        79\n",
      "           3       0.38      0.38      0.38        39\n",
      "           4       0.73      0.50      0.59        22\n",
      "           5       0.80      0.77      0.78       106\n",
      "           6       0.35      0.28      0.31       142\n",
      "           7       0.61      0.71      0.66        62\n",
      "           8       0.67      0.60      0.63        30\n",
      "           9       0.92      0.50      0.65        22\n",
      "          10       0.88      0.84      0.86       144\n",
      "          11       0.21      0.10      0.14        29\n",
      "          12       0.82      0.41      0.55        22\n",
      "          13       0.42      0.60      0.49        45\n",
      "          14       0.30      0.30      0.30        84\n",
      "          15       0.77      0.62      0.69        16\n",
      "          16       0.70      0.66      0.68       122\n",
      "          17       0.50      0.25      0.33        16\n",
      "          18       0.34      0.40      0.37        53\n",
      "          19       0.62      0.26      0.37        19\n",
      "          20       0.60      0.19      0.29        16\n",
      "          21       0.50      0.17      0.25        24\n",
      "          22       0.63      0.68      0.65       194\n",
      "          23       0.91      0.84      0.88        51\n",
      "          24       0.65      0.43      0.51        47\n",
      "          25       0.81      0.46      0.59        28\n",
      "          26       0.33      0.24      0.28        25\n",
      "          27       0.73      0.86      0.79       943\n",
      "          28       0.78      0.82      0.80        56\n",
      "          29       0.23      0.43      0.30        63\n",
      "          30       0.30      0.34      0.32        44\n",
      "          31       0.08      0.04      0.05        25\n",
      "          32       0.70      0.81      0.75        95\n",
      "          33       0.81      0.81      0.81       129\n",
      "          34       0.64      0.51      0.57        45\n",
      "          35       0.18      0.11      0.14        35\n",
      "          36       0.45      0.38      0.41        50\n",
      "          37       0.27      0.17      0.21        40\n",
      "          38       0.90      0.72      0.80        39\n",
      "          39       0.64      0.52      0.57        44\n",
      "          40       0.61      0.67      0.64       115\n",
      "          41       0.59      0.64      0.61       143\n",
      "          42       0.72      0.61      0.66        62\n",
      "          43       0.64      0.56      0.60        41\n",
      "          44       0.43      0.34      0.38        29\n",
      "          45       0.49      0.58      0.53        71\n",
      "          46       0.86      0.64      0.73        56\n",
      "          47       0.26      0.29      0.27        21\n",
      "          48       0.10      0.06      0.08        16\n",
      "          49       0.62      0.26      0.37        19\n",
      "          50       0.67      0.59      0.63        44\n",
      "          51       0.78      0.35      0.48        20\n",
      "          52       0.14      0.04      0.06        27\n",
      "          53       0.66      0.70      0.68        53\n",
      "          54       0.33      0.06      0.10        18\n",
      "          55       0.15      0.12      0.13        26\n",
      "          56       0.70      0.57      0.63        28\n",
      "          57       0.71      0.69      0.70       108\n",
      "          58       0.74      0.84      0.79       366\n",
      "          59       0.42      0.31      0.36        74\n",
      "          60       0.31      0.24      0.27        34\n",
      "          61       0.36      0.33      0.35        24\n",
      "          62       0.50      0.46      0.48        95\n",
      "          63       0.33      0.11      0.17        18\n",
      "          64       0.78      0.68      0.72        37\n",
      "          65       0.57      0.27      0.36        15\n",
      "          66       0.50      0.55      0.52        33\n",
      "          67       0.69      0.73      0.71       602\n",
      "          68       0.66      0.75      0.70       190\n",
      "          69       0.33      0.38      0.35       105\n",
      "          70       0.79      0.64      0.71        36\n",
      "          71       0.61      0.48      0.53        48\n",
      "          72       0.36      0.36      0.36        22\n",
      "          73       0.67      0.42      0.52        33\n",
      "          74       0.90      0.87      0.89        85\n",
      "          75       0.71      0.67      0.69        30\n",
      "          76       0.78      0.64      0.70        50\n",
      "          77       0.73      0.63      0.68        43\n",
      "          78       0.56      0.72      0.63       104\n",
      "          79       0.50      0.54      0.52       391\n",
      "          80       0.60      0.18      0.27        17\n",
      "          81       0.68      0.68      0.68        28\n",
      "          82       0.57      0.20      0.30        20\n",
      "          83       0.38      0.12      0.19        24\n",
      "          84       0.35      0.26      0.30        53\n",
      "          85       0.50      0.26      0.34        23\n",
      "          86       0.55      0.39      0.46        74\n",
      "          87       0.33      0.29      0.31        34\n",
      "          88       0.72      0.55      0.62       297\n",
      "          89       0.68      0.70      0.69        40\n",
      "          90       0.00      0.00      0.00        16\n",
      "          91       0.34      0.41      0.37        39\n",
      "          92       0.29      0.23      0.26        26\n",
      "          93       0.89      0.77      0.83        22\n",
      "          94       0.08      0.15      0.10        20\n",
      "          95       0.53      0.24      0.33        42\n",
      "          96       0.62      0.76      0.68        21\n",
      "          97       0.64      0.58      0.61        24\n",
      "          98       0.27      0.12      0.17        25\n",
      "          99       0.52      0.35      0.42        34\n",
      "         100       0.52      0.44      0.48        55\n",
      "         101       0.67      0.69      0.68       329\n",
      "         102       0.89      0.87      0.88        75\n",
      "         103       0.43      0.32      0.36        19\n",
      "         104       1.00      0.71      0.83        38\n",
      "         105       0.36      0.33      0.35        87\n",
      "         106       0.21      0.15      0.17        47\n",
      "         107       0.62      0.47      0.54        32\n",
      "         108       0.64      0.43      0.51        21\n",
      "         109       0.45      0.60      0.51       155\n",
      "         110       0.32      0.36      0.34        66\n",
      "         111       0.57      0.65      0.60        20\n",
      "         112       0.62      0.69      0.65        80\n",
      "         113       0.74      0.66      0.70        56\n",
      "         114       0.56      0.58      0.57       137\n",
      "         115       0.11      0.06      0.08        17\n",
      "         116       0.67      0.81      0.74       129\n",
      "         117       0.18      0.23      0.20        78\n",
      "         118       0.28      0.28      0.28        39\n",
      "         119       0.52      0.47      0.49        47\n",
      "         120       0.25      0.21      0.23        14\n",
      "         121       0.61      0.65      0.63       377\n",
      "         122       0.62      0.66      0.64        38\n",
      "         123       0.44      0.54      0.49        78\n",
      "         124       0.33      0.28      0.30        25\n",
      "         125       0.42      0.37      0.39        73\n",
      "         126       0.57      0.65      0.60        20\n",
      "         127       0.81      0.86      0.84       660\n",
      "         128       0.31      0.20      0.24        82\n",
      "         129       0.54      0.35      0.42        20\n",
      "         130       0.71      0.28      0.40        18\n",
      "         131       0.46      0.26      0.33       137\n",
      "         132       0.43      0.28      0.34        43\n",
      "         133       0.40      0.40      0.40        55\n",
      "         134       0.65      0.44      0.52        64\n",
      "         135       0.41      0.40      0.41        57\n",
      "         136       0.65      0.69      0.67        96\n",
      "         137       0.81      0.79      0.80        61\n",
      "         138       0.86      0.90      0.88      1969\n",
      "         139       0.62      0.65      0.64        54\n",
      "         140       0.56      0.31      0.40        16\n",
      "         141       0.60      0.36      0.45        25\n",
      "         142       0.18      0.24      0.21        17\n",
      "         143       0.32      0.47      0.38       298\n",
      "         144       0.19      0.20      0.19        41\n",
      "         145       0.80      0.73      0.77        83\n",
      "         146       0.58      0.56      0.57        25\n",
      "         147       0.30      0.12      0.17        25\n",
      "         148       0.48      0.54      0.51       209\n",
      "         149       0.50      0.20      0.29        15\n",
      "         150       0.60      0.49      0.54        61\n",
      "         151       0.67      0.40      0.50        20\n",
      "         152       0.21      0.15      0.18        20\n",
      "         153       0.39      0.32      0.35        34\n",
      "         154       0.78      0.82      0.80       144\n",
      "         155       0.60      0.64      0.62       387\n",
      "         156       0.31      0.36      0.33        56\n",
      "         157       0.31      0.21      0.25        24\n",
      "         158       0.44      0.33      0.38        51\n",
      "         159       0.91      0.43      0.59        23\n",
      "         160       0.26      0.23      0.24        44\n",
      "         161       0.66      0.70      0.68       240\n",
      "         162       0.67      0.30      0.41        27\n",
      "         163       0.89      0.42      0.57        19\n",
      "         164       0.45      0.43      0.44       161\n",
      "         165       0.62      0.65      0.64        66\n",
      "         166       0.45      0.61      0.52        70\n",
      "         167       0.91      0.84      0.87        61\n",
      "         168       0.41      0.32      0.36        92\n",
      "         169       0.73      0.71      0.72        34\n",
      "         170       0.65      0.46      0.54        37\n",
      "         171       0.47      0.45      0.46       223\n",
      "         172       0.11      0.04      0.06        24\n",
      "         173       0.73      0.83      0.78       248\n",
      "         174       0.63      0.63      0.63       191\n",
      "         175       0.31      0.17      0.22        53\n",
      "         176       0.70      0.83      0.76       236\n",
      "         177       0.50      0.28      0.36        39\n",
      "         178       0.79      0.82      0.80       201\n",
      "         179       0.58      0.35      0.44        31\n",
      "         180       0.71      0.74      0.72      1088\n",
      "         181       0.49      0.54      0.51       185\n",
      "         182       0.57      0.57      0.57        28\n",
      "         183       0.65      0.73      0.69       359\n",
      "         184       0.70      0.74      0.72        19\n",
      "         185       0.19      0.14      0.16        35\n",
      "         186       0.57      0.41      0.48        39\n",
      "         187       0.48      0.40      0.43        25\n",
      "\n",
      "   micro avg       0.64      0.64      0.64     18549\n",
      "   macro avg       0.54      0.47      0.49     18549\n",
      "weighted avg       0.63      0.64      0.63     18549\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lstm_model.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv1D, MaxPooling1D, Flatten\n",
    "\n",
    "class CnnModel(NnModel):\n",
    "     def __init__(self, train_vectors, train_labels, test_vectors, test_labels, \n",
    "                  embedding_dim, channels_num, conv_window):\n",
    "        super().__init__(train_vectors, \n",
    "                         train_labels, \n",
    "                         test_vectors, \n",
    "                         test_labels)\n",
    "        self.model = Sequential()\n",
    "        self.model.add(Embedding(MAX_WORDS_NUM, embedding_dim, input_length = MAX_SEQ_LEN))\n",
    "        self.model.add(Dropout(0.2))\n",
    "        self.model.add(Conv1D(channels_num, conv_window, activation='relu'))\n",
    "        self.model.add(MaxPooling1D(conv_window))\n",
    "        self.model.add(Flatten())\n",
    "        self.model.add(Dense(1024, activation='relu'))\n",
    "        self.model.add(Dropout(0.2))\n",
    "        self.model.add(Dense(188, activation='softmax'))\n",
    "        self.model.summary()\n",
    "        self.model.compile(optimizer=RMSprop(lr=1e-3),\n",
    "                           loss='categorical_crossentropy',\n",
    "                           metrics=['acc'])        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 235, 100)          4855300   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 235, 100)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 231, 128)          64128     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 46, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 5888)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1024)              6030336   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 188)               192700    \n",
      "=================================================================\n",
      "Total params: 11,142,464\n",
      "Trainable params: 11,142,464\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_model = CnnModel(train_padded_seqs, train_topic_labels, test_padded_seqs, test_topic_labels, 100, 128, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad00d431549841fbb64958654335a3d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training', max=25, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 0', max=43280, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 1', max=43280, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 2', max=43280, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 3', max=43280, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 4', max=43280, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 5', max=43280, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 6', max=43280, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 7', max=43280, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 8', max=43280, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 9', max=43280, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 10', max=43280, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 11', max=43280, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 12', max=43280, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 13', max=43280, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 14', max=43280, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 15', max=43280, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 16', max=43280, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 17', max=43280, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 18', max=43280, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 19', max=43280, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 20', max=43280, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 21', max=43280, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 22', max=43280, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 23', max=43280, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 24', max=43280, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cnn_model.train(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.49      0.57       335\n",
      "           1       0.48      0.56      0.52        41\n",
      "           2       0.45      0.43      0.44        79\n",
      "           3       0.39      0.44      0.41        39\n",
      "           4       0.35      0.27      0.31        22\n",
      "           5       0.50      0.68      0.58       106\n",
      "           6       0.21      0.38      0.27       142\n",
      "           7       0.39      0.60      0.47        62\n",
      "           8       0.71      0.50      0.59        30\n",
      "           9       0.55      0.55      0.55        22\n",
      "          10       0.81      0.69      0.75       144\n",
      "          11       0.33      0.14      0.20        29\n",
      "          12       0.46      0.55      0.50        22\n",
      "          13       0.26      0.51      0.35        45\n",
      "          14       0.20      0.18      0.19        84\n",
      "          15       0.38      0.56      0.45        16\n",
      "          16       0.66      0.68      0.67       122\n",
      "          17       0.29      0.12      0.17        16\n",
      "          18       0.32      0.49      0.39        53\n",
      "          19       0.31      0.21      0.25        19\n",
      "          20       0.31      0.25      0.28        16\n",
      "          21       0.27      0.33      0.30        24\n",
      "          22       0.63      0.48      0.54       194\n",
      "          23       0.73      0.71      0.72        51\n",
      "          24       0.29      0.36      0.32        47\n",
      "          25       0.20      0.39      0.26        28\n",
      "          26       0.50      0.28      0.36        25\n",
      "          27       0.74      0.67      0.71       943\n",
      "          28       0.55      0.50      0.52        56\n",
      "          29       0.31      0.33      0.32        63\n",
      "          30       0.20      0.32      0.24        44\n",
      "          31       0.03      0.04      0.03        25\n",
      "          32       0.61      0.68      0.64        95\n",
      "          33       0.74      0.77      0.76       129\n",
      "          34       0.35      0.38      0.37        45\n",
      "          35       0.23      0.40      0.29        35\n",
      "          36       0.46      0.54      0.50        50\n",
      "          37       0.19      0.20      0.20        40\n",
      "          38       0.87      0.51      0.65        39\n",
      "          39       0.37      0.39      0.38        44\n",
      "          40       0.60      0.63      0.62       115\n",
      "          41       0.52      0.50      0.51       143\n",
      "          42       0.30      0.68      0.42        62\n",
      "          43       0.29      0.46      0.36        41\n",
      "          44       0.18      0.28      0.22        29\n",
      "          45       0.44      0.52      0.47        71\n",
      "          46       0.41      0.45      0.43        56\n",
      "          47       0.29      0.10      0.14        21\n",
      "          48       0.00      0.00      0.00        16\n",
      "          49       0.41      0.37      0.39        19\n",
      "          50       0.69      0.41      0.51        44\n",
      "          51       0.09      0.25      0.14        20\n",
      "          52       0.15      0.26      0.19        27\n",
      "          53       0.53      0.47      0.50        53\n",
      "          54       0.26      0.33      0.29        18\n",
      "          55       0.07      0.19      0.10        26\n",
      "          56       0.52      0.50      0.51        28\n",
      "          57       0.57      0.66      0.61       108\n",
      "          58       0.79      0.69      0.74       366\n",
      "          59       0.32      0.32      0.32        74\n",
      "          60       0.19      0.26      0.22        34\n",
      "          61       0.15      0.33      0.21        24\n",
      "          62       0.30      0.41      0.35        95\n",
      "          63       0.23      0.17      0.19        18\n",
      "          64       0.61      0.62      0.61        37\n",
      "          65       0.26      0.47      0.33        15\n",
      "          66       0.31      0.33      0.32        33\n",
      "          67       0.74      0.56      0.64       602\n",
      "          68       0.64      0.61      0.62       190\n",
      "          69       0.29      0.29      0.29       105\n",
      "          70       0.42      0.61      0.49        36\n",
      "          71       0.45      0.35      0.40        48\n",
      "          72       0.15      0.32      0.20        22\n",
      "          73       0.38      0.45      0.42        33\n",
      "          74       0.87      0.84      0.85        85\n",
      "          75       0.64      0.60      0.62        30\n",
      "          76       0.73      0.60      0.66        50\n",
      "          77       0.78      0.49      0.60        43\n",
      "          78       0.41      0.58      0.48       104\n",
      "          79       0.48      0.43      0.46       391\n",
      "          80       0.08      0.06      0.07        17\n",
      "          81       0.64      0.64      0.64        28\n",
      "          82       0.26      0.30      0.28        20\n",
      "          83       0.13      0.17      0.15        24\n",
      "          84       0.24      0.30      0.26        53\n",
      "          85       0.18      0.22      0.20        23\n",
      "          86       0.30      0.34      0.32        74\n",
      "          87       0.18      0.44      0.26        34\n",
      "          88       0.51      0.64      0.57       297\n",
      "          89       0.46      0.47      0.47        40\n",
      "          90       0.08      0.12      0.10        16\n",
      "          91       0.65      0.28      0.39        39\n",
      "          92       0.28      0.27      0.27        26\n",
      "          93       0.95      0.86      0.90        22\n",
      "          94       0.17      0.20      0.18        20\n",
      "          95       0.44      0.26      0.33        42\n",
      "          96       0.59      0.48      0.53        21\n",
      "          97       0.59      0.67      0.63        24\n",
      "          98       0.21      0.36      0.26        25\n",
      "          99       0.45      0.53      0.49        34\n",
      "         100       0.36      0.38      0.37        55\n",
      "         101       0.69      0.45      0.54       329\n",
      "         102       0.87      0.79      0.83        75\n",
      "         103       0.32      0.32      0.32        19\n",
      "         104       0.77      0.61      0.68        38\n",
      "         105       0.19      0.21      0.20        87\n",
      "         106       0.13      0.34      0.19        47\n",
      "         107       0.16      0.19      0.17        32\n",
      "         108       0.43      0.43      0.43        21\n",
      "         109       0.46      0.58      0.51       155\n",
      "         110       0.17      0.27      0.21        66\n",
      "         111       0.42      0.65      0.51        20\n",
      "         112       0.43      0.66      0.52        80\n",
      "         113       0.67      0.54      0.59        56\n",
      "         114       0.54      0.64      0.58       137\n",
      "         115       0.21      0.24      0.22        17\n",
      "         116       0.66      0.66      0.66       129\n",
      "         117       0.14      0.21      0.17        78\n",
      "         118       0.29      0.26      0.27        39\n",
      "         119       0.52      0.57      0.55        47\n",
      "         120       0.38      0.36      0.37        14\n",
      "         121       0.65      0.54      0.59       377\n",
      "         122       0.34      0.55      0.42        38\n",
      "         123       0.33      0.33      0.33        78\n",
      "         124       0.18      0.16      0.17        25\n",
      "         125       0.36      0.32      0.34        73\n",
      "         126       0.52      0.70      0.60        20\n",
      "         127       0.87      0.73      0.80       660\n",
      "         128       0.22      0.41      0.29        82\n",
      "         129       0.27      0.20      0.23        20\n",
      "         130       0.11      0.11      0.11        18\n",
      "         131       0.30      0.26      0.28       137\n",
      "         132       0.31      0.37      0.34        43\n",
      "         133       0.40      0.25      0.31        55\n",
      "         134       0.44      0.59      0.50        64\n",
      "         135       0.12      0.26      0.16        57\n",
      "         136       0.61      0.60      0.61        96\n",
      "         137       0.48      0.75      0.59        61\n",
      "         138       0.88      0.80      0.84      1969\n",
      "         139       0.41      0.56      0.47        54\n",
      "         140       0.33      0.31      0.32        16\n",
      "         141       0.24      0.44      0.31        25\n",
      "         142       0.20      0.18      0.19        17\n",
      "         143       0.36      0.24      0.29       298\n",
      "         144       0.14      0.29      0.19        41\n",
      "         145       0.63      0.67      0.65        83\n",
      "         146       0.21      0.52      0.30        25\n",
      "         147       0.09      0.08      0.08        25\n",
      "         148       0.44      0.55      0.49       209\n",
      "         149       0.12      0.33      0.18        15\n",
      "         150       0.34      0.41      0.37        61\n",
      "         151       0.32      0.50      0.39        20\n",
      "         152       0.22      0.25      0.23        20\n",
      "         153       0.41      0.26      0.32        34\n",
      "         154       0.79      0.72      0.76       144\n",
      "         155       0.65      0.49      0.56       387\n",
      "         156       0.39      0.23      0.29        56\n",
      "         157       0.29      0.08      0.13        24\n",
      "         158       0.46      0.51      0.49        51\n",
      "         159       0.56      0.39      0.46        23\n",
      "         160       0.30      0.30      0.30        44\n",
      "         161       0.70      0.51      0.59       240\n",
      "         162       0.12      0.22      0.16        27\n",
      "         163       0.71      0.26      0.38        19\n",
      "         164       0.58      0.34      0.43       161\n",
      "         165       0.38      0.50      0.43        66\n",
      "         166       0.46      0.59      0.52        70\n",
      "         167       0.85      0.74      0.79        61\n",
      "         168       0.33      0.27      0.30        92\n",
      "         169       0.55      0.62      0.58        34\n",
      "         170       0.41      0.41      0.41        37\n",
      "         171       0.44      0.54      0.49       223\n",
      "         172       0.06      0.17      0.09        24\n",
      "         173       0.80      0.67      0.73       248\n",
      "         174       0.73      0.50      0.59       191\n",
      "         175       0.19      0.21      0.20        53\n",
      "         176       0.68      0.69      0.69       236\n",
      "         177       0.55      0.31      0.39        39\n",
      "         178       0.84      0.58      0.69       201\n",
      "         179       0.26      0.39      0.31        31\n",
      "         180       0.73      0.63      0.68      1088\n",
      "         181       0.36      0.48      0.41       185\n",
      "         182       0.46      0.46      0.46        28\n",
      "         183       0.67      0.58      0.62       359\n",
      "         184       0.37      0.53      0.43        19\n",
      "         185       0.19      0.20      0.19        35\n",
      "         186       0.50      0.36      0.42        39\n",
      "         187       0.30      0.36      0.33        25\n",
      "\n",
      "   micro avg       0.55      0.55      0.55     18549\n",
      "   macro avg       0.42      0.43      0.41     18549\n",
      "weighted avg       0.59      0.55      0.56     18549\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cnn_model.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>precision (macro avg)</th>\n",
       "      <th>recall (macro avg)</th>\n",
       "      <th>f1 (macro avg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kNN+vectors sum</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>logreg+vectors sum</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kNN+doc2vec</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>logreg+doc2vec</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FNN+vectors sum</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FNN+doc2vec</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CNN</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                model precision (macro avg) recall (macro avg) f1 (macro avg)\n",
       "0     kNN+vectors sum                  0.40               0.35           0.36\n",
       "1  logreg+vectors sum                  0.42               0.42           0.41\n",
       "2         kNN+doc2vec                  0.51               0.50           0.49\n",
       "3      logreg+doc2vec                  0.58               0.47           0.50\n",
       "4     FNN+vectors sum                  0.62               0.48           0.53\n",
       "5         FNN+doc2vec                  0.47               0.40           0.42\n",
       "6                LSTM                  0.54               0.47           0.49\n",
       "7                 CNN                  0.42               0.43           0.41"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_metrics(model, group = 'macro avg'): \n",
    "    metrics = [line.strip() for line in  model.test_report.split('\\n') if group in line][0]\n",
    "    return [metric.strip() for metric in metrics[len(group)-1:].split()][1:-1]\n",
    "\n",
    "pandas.DataFrame({\n",
    "    'model': ['kNN+vectors sum',\n",
    "              'logreg+vectors sum',\n",
    "              'kNN+doc2vec',\n",
    "              'logreg+doc2vec',\n",
    "              'FNN+vectors sum',\n",
    "              'FNN+doc2vec',\n",
    "              'LSTM',\n",
    "              'CNN'],\n",
    "    'precision (macro avg)': [extract_metrics(knn)[0],\n",
    "                              extract_metrics(logreg)[0],\n",
    "                              extract_metrics(knn2)[0],\n",
    "                              extract_metrics(logreg2)[0],\n",
    "                              extract_metrics(ff_model)[0],\n",
    "                              extract_metrics(ff_sum_model)[0],\n",
    "                              extract_metrics(lstm_model)[0],\n",
    "                              extract_metrics(cnn_model)[0]],\n",
    "    'recall (macro avg)': [extract_metrics(knn)[1],\n",
    "                              extract_metrics(logreg)[1],\n",
    "                              extract_metrics(knn2)[1],\n",
    "                              extract_metrics(logreg2)[1],\n",
    "                              extract_metrics(ff_model)[1],\n",
    "                              extract_metrics(ff_sum_model)[1],\n",
    "                              extract_metrics(lstm_model)[1],\n",
    "                              extract_metrics(cnn_model)[1]],\n",
    "    'f1 (macro avg)': [extract_metrics(knn)[2],\n",
    "                              extract_metrics(logreg)[2],\n",
    "                              extract_metrics(knn2)[2],\n",
    "                              extract_metrics(logreg2)[2],\n",
    "                              extract_metrics(ff_model)[2],\n",
    "                              extract_metrics(ff_sum_model)[2],\n",
    "                              extract_metrics(lstm_model)[2],\n",
    "                              extract_metrics(cnn_model)[2]]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Бачимо що вдалося покращити якість у порівнянні з бейзланойм більш ніж на 10% згідно F1. Логістична регресія в порівнянні з kNN у всіх випадках працювала краще. Вектори документів також дали покращення у всіх випадках."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
