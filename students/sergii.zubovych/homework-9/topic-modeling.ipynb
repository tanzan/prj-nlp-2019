{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "Спочатку завантажуємо word embeddings для української мови."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl http://lang.org.ua/static/downloads/models/news.lowercased.tokenized.word2vec.300d.bz2 --output news.lowercased.tokenized.word2vec.300d.bz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bunzip2 news.lowercased.tokenized.word2vec.300d.bz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 11s, sys: 560 ms, total: 1min 12s\n",
      "Wall time: 1min 11s\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "%time wv = KeyedVectors.load_word2vec_format('news.lowercased.tokenized.word2vec.300d', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('дієслово', 0.6502863764762878),\n",
       " ('слівце', 0.6484909653663635),\n",
       " ('словосполучення', 0.6456568241119385),\n",
       " ('гасло', 0.5913079977035522),\n",
       " ('слово**', 0.555127739906311),\n",
       " (\"прислів'я\", 0.5407627820968628),\n",
       " ('письмо', 0.5235773324966431),\n",
       " ('прізвище', 0.52119380235672),\n",
       " ('пророцтво', 0.5125285983085632),\n",
       " ('ремесло', 0.5058826804161072)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar('слово')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Потім розпаковуємо та завантажуємо дані."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replace 1551/Інші-Подяки.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
     ]
    }
   ],
   "source": [
    "!unzip -q ../../../tasks/1551.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Аварійний--травмонебезпечний-стан-утримання-об-єктів-благоустрою.txt\r\n",
      "Бажаючі-отримати--Картки-киянина--КК--.txt\r\n",
      "Будівництво-АЗС.txt\r\n",
      "Будівництво-в-нічний-час.txt\r\n",
      "Будівництво-дооблаштування-дитячого-майданчику.txt\r\n",
      "Будівництво--дооблаштування-спортивних-майданчиків.txt\r\n",
      "Будівництво-та-реконструкція-об-єктів-освіти.txt\r\n",
      "Взаємовідносини-з-сусідами.txt\r\n",
      "Вивезення--утилізація-твердих-та-негабаритних-відходів.txt\r\n",
      "Видалення-аварійних--пошкоджених-хворобами-дерев.txt\r\n",
      "Видача-розрахункових-книжок--квитанцій--довідок.txt\r\n",
      "Вилов-безпритульних-тварин.txt\r\n",
      "Вирізування--кронування--гілля-дерев.txt\r\n",
      "Виток-холодної-води-на-поверхню.txt\r\n",
      "Відновлення-благоустрою-після-вик--планових-аварійних-робіт-на-об-єктах-благоуст.txt\r\n",
      "ls: write error: Broken pipe\r\n"
     ]
    }
   ],
   "source": [
    "!ls 1551 | head -n 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1551/Незадовільна-температура-ГВП.txt',\n",
       " '1551/Незадовільне-обслуговування-в-амбулаторно-поліклінічних-установах.txt',\n",
       " '1551/Відсутнє-електропостачання.txt',\n",
       " '1551/Порушення-правил-тиші--після-------.txt',\n",
       " '1551/Неякісне-ХВП.txt',\n",
       " '1551/Нанесення-дорожньої-розмітки.txt',\n",
       " '1551/Робота-циркуляційної-системи.txt',\n",
       " '1551/Встановлення-світлофора.txt',\n",
       " '1551/Завезення-піску-на-дитячий-майданчик.txt',\n",
       " '1551/Скошування-трави.txt']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "files = glob.glob(\"1551/*\")\n",
    "\n",
    "files[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import namedtuple\n",
    "\n",
    "Document = namedtuple('Document', 'id topic_id tags content')\n",
    "\n",
    "def parse_tags(file):\n",
    "    return [tag for tag in os.path.basename(file.name)[:-4].split('-') if tag]\n",
    "\n",
    "def parse_topic_file(topic_id, filename):\n",
    "    documents = []    \n",
    "    with open(filename) as f:\n",
    "        tags = parse_tags(f)        \n",
    "        _id = None\n",
    "        content = []\n",
    "        for line in f:            \n",
    "            if _id is None and line.strip().isnumeric():\n",
    "                _id = int(line.strip())                \n",
    "                continue\n",
    "            if not (_id is None) and line.strip():                \n",
    "                content.append(line.strip())\n",
    "                continue\n",
    "            if not (_id is None) and not line.strip():\n",
    "                documents.append(Document(_id, topic_id, tags, ''.join(content)))\n",
    "                _id = None\n",
    "                content = []                \n",
    "    \n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114338"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_documents = [doc for topic_id, file in enumerate(files) \\\n",
    "                 for doc in parse_topic_file(topic_id, file) if len(doc.content) > 0]\n",
    "\n",
    "len(all_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id=2697865, topic_id=0, tags=['Незадовільна', 'температура', 'ГВП'], content='Недогрев горячей воды (вода нормальной температуры подавалась неделю с15 по 23, до этого была частичная подача горячей воды (пару часов вечером и ночью горячая), остальное время теплой), сейчас опять температура порядка 40 градусов. Эта ситуация продолжается на фоне постоянного недогрева батарей в квартире, ДУ 12 ККЕУ  МОУкраины  не реагирует на ситуацию.'),\n",
       " Document(id=3170827, topic_id=0, tags=['Незадовільна', 'температура', 'ГВП'], content='Из горячего крана течет холодная вода, в вечернее и утреннее время купаться нет возможности. Необходимо или пересчитывать тарифы или включать горячую воду.'),\n",
       " Document(id=3165270, topic_id=0, tags=['Незадовільна', 'температура', 'ГВП'], content='Я поживаю на 6 этаже 9и - этажного дома на протяжении долгого промежутка времени у нас в квартире из крана горячей воды, особенно утром и в первой половине дня течёт если не холодная вода, то вода чуть тёплая. По утрам для того чтобы совершить утренний туалет приходится долго спускать воду (и эта проблема у большей части жильцов нашего дома). В свете того, что с мая месяца у нас очень выросли тарифы на горячую воду, меня интересует вопрос - почему я должна платить деньги за некачественную услугу. Огромная просьба посодействовать в решении данной проблемы. Местные сантехники подтверждают, что проблемы с горячей водой не только в нашей квартире, но решить эту проблему они не могут, так как это от них не зависит.')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_documents[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тепер фільтруємо документи з українською мовою."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect\n",
    "from langdetect.detector import LangDetectException\n",
    "from tqdm import tqdm_notebook\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "def memoize(filename, compute):  \n",
    "    \n",
    "    fullname = filename + '.can'\n",
    "    \n",
    "    if os.path.isfile(fullname):\n",
    "        with open(fullname, 'rb') as f:                        \n",
    "            return pickle.load(f)\n",
    "    \n",
    "    result = compute()\n",
    "    with open(fullname, 'wb') as f:\n",
    "        pickle.dump(result, f)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def is_uk(text):\n",
    "    \n",
    "    if len(text):\n",
    "        try:\n",
    "            return detect(text[:1024]) == 'uk'\n",
    "        except LangDetectException as e:\n",
    "            return False\n",
    "    \n",
    "    return False\n",
    "\n",
    "uk_documents = memoize('uk_documents', \n",
    "                       lambda: [doc for doc in tqdm_notebook(all_documents) if is_uk(doc.content)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id=3152784, topic_id=0, tags=['Незадовільна', 'температура', 'ГВП'], content='Відсутнітність горячого водопостачання належної температури в ванній кімнаті та на кухні. Було звернення в ЖКХ та  на горячу лінію 1551. Досі питання не вирішено'),\n",
       " Document(id=3143050, topic_id=0, tags=['Незадовільна', 'температура', 'ГВП'], content='Добрий вечір.Прошу розібратися з проблемою невідповідної температури гарячої води, прийняти міри та відновити гаряче водопостачання.Вже 3 дні гаряча вода має температру не більше 38 градусів.При неможливості відновити постачання гарчоїї води, прошу Вас перерахувати її вартість згідно з законодавством.Дякую за допомогу та розуміння.'),\n",
       " Document(id=3142427, topic_id=0, tags=['Незадовільна', 'температура', 'ГВП'], content='На моє звернення № Г-6623 відповідь написав директор КП РЕО-1 Кононець В. В. Під час зустрічі активу нашого будинку із начальником управління ЖКГ Святошинського району Мужиченком Є. О. пан Мужиченко сказав, що згідно Закону України № 1998 ні районна влада, ні тим паче КП РЕО-1 не є суб’єктами договірних відносин і не можуть втручатись у стосунки між споживачем і виконавцем - ПАТ ”Київенерго”. Тому прошу КБ «Контактний центр міста Києва 1551» як координатора звернень від громадян мої скарги про відсутність послуги ГВП, про неналежну якість послуг ГВП передавати саме ПАТ «Київенерго». Відповіді на мої скарги повинно надавати ПАТ «Київенерго».Вкотре повідомляю: протягом року за адресою проспект Корольова, 14 температура ГВП не перевищує 35 °С.Вимагаємо від ПАТ «Київенерго» виконати всі необхідні роботи.')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uk_documents[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дивимся на дані."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "uk_doc_df = pandas.DataFrame([doc._replace(tags = \"-\".join(doc.tags)) for doc in uk_documents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>topic_id</th>\n",
       "      <th>tags</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3152784</td>\n",
       "      <td>0</td>\n",
       "      <td>Незадовільна-температура-ГВП</td>\n",
       "      <td>Відсутнітність горячого водопостачання належно...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3143050</td>\n",
       "      <td>0</td>\n",
       "      <td>Незадовільна-температура-ГВП</td>\n",
       "      <td>Добрий вечір.Прошу розібратися з проблемою нев...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3142427</td>\n",
       "      <td>0</td>\n",
       "      <td>Незадовільна-температура-ГВП</td>\n",
       "      <td>На моє звернення № Г-6623 відповідь написав ди...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3130991</td>\n",
       "      <td>0</td>\n",
       "      <td>Незадовільна-температура-ГВП</td>\n",
       "      <td>Доброго дня! Вже більше двох тижнів гаряче вод...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2405990</td>\n",
       "      <td>0</td>\n",
       "      <td>Незадовільна-температура-ГВП</td>\n",
       "      <td>На звернення:Номер звернення:\\tГ-6478Зареєстро...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3115494</td>\n",
       "      <td>0</td>\n",
       "      <td>Незадовільна-температура-ГВП</td>\n",
       "      <td>Звертаюсь до Вас стосовно вирішення питання, щ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3104107</td>\n",
       "      <td>0</td>\n",
       "      <td>Незадовільна-температура-ГВП</td>\n",
       "      <td>Доброго дня!!! Моє звернення від 02.12.14 #Г-1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3091571</td>\n",
       "      <td>0</td>\n",
       "      <td>Незадовільна-температура-ГВП</td>\n",
       "      <td>Протягом останнього тижня гаряча вода недостат...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2690156</td>\n",
       "      <td>0</td>\n",
       "      <td>Незадовільна-температура-ГВП</td>\n",
       "      <td>Прошу прийняти необхідні заходи по покращенню ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2748419</td>\n",
       "      <td>0</td>\n",
       "      <td>Незадовільна-температура-ГВП</td>\n",
       "      <td>немає  температури гарячої води</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  topic_id                          tags  \\\n",
       "0  3152784         0  Незадовільна-температура-ГВП   \n",
       "1  3143050         0  Незадовільна-температура-ГВП   \n",
       "2  3142427         0  Незадовільна-температура-ГВП   \n",
       "3  3130991         0  Незадовільна-температура-ГВП   \n",
       "4  2405990         0  Незадовільна-температура-ГВП   \n",
       "5  3115494         0  Незадовільна-температура-ГВП   \n",
       "6  3104107         0  Незадовільна-температура-ГВП   \n",
       "7  3091571         0  Незадовільна-температура-ГВП   \n",
       "8  2690156         0  Незадовільна-температура-ГВП   \n",
       "9  2748419         0  Незадовільна-температура-ГВП   \n",
       "\n",
       "                                             content  \n",
       "0  Відсутнітність горячого водопостачання належно...  \n",
       "1  Добрий вечір.Прошу розібратися з проблемою нев...  \n",
       "2  На моє звернення № Г-6623 відповідь написав ди...  \n",
       "3  Доброго дня! Вже більше двох тижнів гаряче вод...  \n",
       "4  На звернення:Номер звернення:\\tГ-6478Зареєстро...  \n",
       "5  Звертаюсь до Вас стосовно вирішення питання, щ...  \n",
       "6  Доброго дня!!! Моє звернення від 02.12.14 #Г-1...  \n",
       "7  Протягом останнього тижня гаряча вода недостат...  \n",
       "8  Прошу прийняти необхідні заходи по покращенню ...  \n",
       "9                    немає  температури гарячої води  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uk_doc_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>topic_id</th>\n",
       "      <th>tags</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.148600e+04</td>\n",
       "      <td>61486.000000</td>\n",
       "      <td>61486</td>\n",
       "      <td>61486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>188</td>\n",
       "      <td>53743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Відсутність-ГВП</td>\n",
       "      <td>Доброго дня!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6531</td>\n",
       "      <td>707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.038086e+06</td>\n",
       "      <td>105.549361</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.625866e+05</td>\n",
       "      <td>55.921234</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.840977e+06</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.083505e+06</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.245302e+06</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.440811e+06</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id      topic_id             tags       content\n",
       "count   6.148600e+04  61486.000000            61486         61486\n",
       "unique           NaN           NaN              188         53743\n",
       "top              NaN           NaN  Відсутність-ГВП  Доброго дня!\n",
       "freq             NaN           NaN             6531           707\n",
       "mean    3.038086e+06    105.549361              NaN           NaN\n",
       "std     2.625866e+05     55.921234              NaN           NaN\n",
       "min     1.000000e+01      0.000000              NaN           NaN\n",
       "25%     2.840977e+06     58.000000              NaN           NaN\n",
       "50%     3.083505e+06    121.000000              NaN           NaN\n",
       "75%     3.245302e+06    150.000000              NaN           NaN\n",
       "max     3.440811e+06    187.000000              NaN           NaN"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uk_doc_df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_id</th>\n",
       "      <th>tags</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <th>Відсутність-ГВП</th>\n",
       "      <td>6531</td>\n",
       "      <td>6531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <th>Укладання-та-ремонт-асфальтного-покриття</th>\n",
       "      <td>3618</td>\n",
       "      <td>3618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <th>Відсутність-опалення</th>\n",
       "      <td>3128</td>\n",
       "      <td>3128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <th>Перевірка-дозвільної-документації-демонтаж-кіосків-ларків</th>\n",
       "      <td>2196</td>\n",
       "      <td>2196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <th>Прибирання-та-санітарний-стан-територій</th>\n",
       "      <td>2004</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <th>Технічний-стан-проїжджих-частин-вулиць-та-тротуарів</th>\n",
       "      <td>1292</td>\n",
       "      <td>1292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <th>Відновлення-благоустрою-після-вик-планових-аварійних-робіт-на-об-єктах-благоуст</th>\n",
       "      <td>1276</td>\n",
       "      <td>1276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <th>Відсутність-освітлення-у-під-їзді-за-відсутності-несправності-лампочок</th>\n",
       "      <td>1260</td>\n",
       "      <td>1260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <th>Не-працює-пасажирський-ліфт</th>\n",
       "      <td>1216</td>\n",
       "      <td>1216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <th>Ремонт-під-їзду</th>\n",
       "      <td>1188</td>\n",
       "      <td>1188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th>Незадовільна-температура-ГВП</th>\n",
       "      <td>1105</td>\n",
       "      <td>1105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <th>Перерахунок-та-нарахування-плати-за-інші-види-житлово-комунальних-послуг</th>\n",
       "      <td>1090</td>\n",
       "      <td>1090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <th>Відсутність-опалення-по-стояку</th>\n",
       "      <td>984</td>\n",
       "      <td>984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <th>Про-розгляд-звернень-громадян</th>\n",
       "      <td>984</td>\n",
       "      <td>984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <th>ГЛ-Несанкціонована-торгівля</th>\n",
       "      <td>823</td>\n",
       "      <td>823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <th>Прибирання-приміщень</th>\n",
       "      <td>793</td>\n",
       "      <td>793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <th>Відсутнє-ХВП</th>\n",
       "      <td>778</td>\n",
       "      <td>778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <th>Освітлення-в-приміщенні-й-при-вході-в-нього</th>\n",
       "      <td>745</td>\n",
       "      <td>745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <th>Інші-технічні-недоліки-стану-ліфту</th>\n",
       "      <td>692</td>\n",
       "      <td>692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <th>Ремонт-дахів</th>\n",
       "      <td>659</td>\n",
       "      <td>659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <th>Перевірка-наявності-дозволів-на-виконання-будівельних-робіт</th>\n",
       "      <td>640</td>\n",
       "      <td>640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <th>Незадовільна-температура-опалення</th>\n",
       "      <td>634</td>\n",
       "      <td>634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <th>Будівництво-дооблаштування-дитячого-майданчику</th>\n",
       "      <td>632</td>\n",
       "      <td>632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <th>Утримання-підвалів-колясочних-технічних-поверхів</th>\n",
       "      <td>607</td>\n",
       "      <td>607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <th>Відсутність-освітлення-на-опорних-стовпах-за-відсутності-несправності-лампочок</th>\n",
       "      <td>537</td>\n",
       "      <td>537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <th>Питання-освітлення-на-опорних-стовпах</th>\n",
       "      <td>515</td>\n",
       "      <td>515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <th>Робота-світлофора</th>\n",
       "      <td>482</td>\n",
       "      <td>482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <th>Стихійне-сміттєзвалище</th>\n",
       "      <td>474</td>\n",
       "      <td>474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <th>Робота-циркуляційної-системи</th>\n",
       "      <td>468</td>\n",
       "      <td>468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <th>Встановлення-та-експлуатація-лічильників-на-водопостачання</th>\n",
       "      <td>467</td>\n",
       "      <td>467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <th>Демонтаж-рекламних-конструкцій-і-вивісок</th>\n",
       "      <td>459</td>\n",
       "      <td>459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <th>Технічне-обслуговування-систем-тепло-водопостачання-та-водовідведення-і-зливов</th>\n",
       "      <td>455</td>\n",
       "      <td>455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <th>Скління-та-ремонт-вікон-на-сходових-клітинах</th>\n",
       "      <td>435</td>\n",
       "      <td>435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <th>Встановлення-лічильників-на-опалення</th>\n",
       "      <td>428</td>\n",
       "      <td>428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <th>Вологе-прибирання-приміщень</th>\n",
       "      <td>406</td>\n",
       "      <td>406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <th>Незадовільний-вивіз-сміття-з-контейнерів-та-урн-для-сміття</th>\n",
       "      <td>383</td>\n",
       "      <td>383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <th>Встановлення-та-експлуатація-дорожніх-знаків</th>\n",
       "      <td>354</td>\n",
       "      <td>354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <th>Нанесення-дорожньої-розмітки</th>\n",
       "      <td>350</td>\n",
       "      <td>350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <th>Паркування-авто-у-місцях-загального-користування</th>\n",
       "      <td>348</td>\n",
       "      <td>348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <th>Встановлення-сміттєвих-контейнерів-та-урн-для-сміття</th>\n",
       "      <td>343</td>\n",
       "      <td>343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <th>Видалення-аварійних-пошкоджених-хворобами-дерев</th>\n",
       "      <td>320</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <th>Контроль-за-станом-рекламних-засобів</th>\n",
       "      <td>318</td>\n",
       "      <td>318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <th>Перевірка-дозвільної-документації-демонтаж-літніх-майданчиків-кафе-ресторанів</th>\n",
       "      <td>316</td>\n",
       "      <td>316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <th>Інші-Подяки</th>\n",
       "      <td>305</td>\n",
       "      <td>305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <th>Встановлення-огородження-зеленої-зони</th>\n",
       "      <td>288</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <th>Знищення-омели-амброзії-та-рослин-паразитів</th>\n",
       "      <td>284</td>\n",
       "      <td>284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <th>Аварійний-травмонебезпечний-стан-утримання-об-єктів-благоустрою</th>\n",
       "      <td>279</td>\n",
       "      <td>279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <th>Не-працює-вантажний-ліфт</th>\n",
       "      <td>271</td>\n",
       "      <td>271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <th>Встановлення-сигнальних-стовпчиків-бар-єрних-огороджень-бордюрів</th>\n",
       "      <td>269</td>\n",
       "      <td>269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>Відсутнє-електропостачання</th>\n",
       "      <td>262</td>\n",
       "      <td>262</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                               id  content\n",
       "topic_id tags                                                             \n",
       "138      Відсутність-ГВП                                     6531     6531\n",
       "180      Укладання-та-ремонт-асфальтного-покриття            3618     3618\n",
       "27       Відсутність-опалення                                3128     3128\n",
       "127      Перевірка-дозвільної-документації-демонтаж-кіос...  2196     2196\n",
       "67       Прибирання-та-санітарний-стан-територій             2004     2004\n",
       "79       Технічний-стан-проїжджих-частин-вулиць-та-троту...  1292     1292\n",
       "155      Відновлення-благоустрою-після-вик-планових-авар...  1276     1276\n",
       "121      Відсутність-освітлення-у-під-їзді-за-відсутност...  1260     1260\n",
       "58       Не-працює-пасажирський-ліфт                         1216     1216\n",
       "183      Ремонт-під-їзду                                     1188     1188\n",
       "0        Незадовільна-температура-ГВП                        1105     1105\n",
       "101      Перерахунок-та-нарахування-плати-за-інші-види-ж...  1090     1090\n",
       "88       Відсутність-опалення-по-стояку                       984      984\n",
       "143      Про-розгляд-звернень-громадян                        984      984\n",
       "173      ГЛ-Несанкціонована-торгівля                          823      823\n",
       "161      Прибирання-приміщень                                 793      793\n",
       "176      Відсутнє-ХВП                                         778      778\n",
       "171      Освітлення-в-приміщенні-й-при-вході-в-нього          745      745\n",
       "148      Інші-технічні-недоліки-стану-ліфту                   692      692\n",
       "178      Ремонт-дахів                                         659      659\n",
       "22       Перевірка-наявності-дозволів-на-виконання-будів...   640      640\n",
       "174      Незадовільна-температура-опалення                    634      634\n",
       "68       Будівництво-дооблаштування-дитячого-майданчику       632      632\n",
       "181      Утримання-підвалів-колясочних-технічних-поверхів     607      607\n",
       "164      Відсутність-освітлення-на-опорних-стовпах-за-ві...   537      537\n",
       "109      Питання-освітлення-на-опорних-стовпах                515      515\n",
       "10       Робота-світлофора                                    482      482\n",
       "41       Стихійне-сміттєзвалище                               474      474\n",
       "6        Робота-циркуляційної-системи                         468      468\n",
       "154      Встановлення-та-експлуатація-лічильників-на-вод...   467      467\n",
       "114      Демонтаж-рекламних-конструкцій-і-вивісок             459      459\n",
       "131      Технічне-обслуговування-систем-тепло-водопостач...   455      455\n",
       "116      Скління-та-ремонт-вікон-на-сходових-клітинах         435      435\n",
       "33       Встановлення-лічильників-на-опалення                 428      428\n",
       "16       Вологе-прибирання-приміщень                          406      406\n",
       "40       Незадовільний-вивіз-сміття-з-контейнерів-та-урн...   383      383\n",
       "57       Встановлення-та-експлуатація-дорожніх-знаків         354      354\n",
       "5        Нанесення-дорожньої-розмітки                         350      350\n",
       "69       Паркування-авто-у-місцях-загального-користування     348      348\n",
       "78       Встановлення-сміттєвих-контейнерів-та-урн-для-с...   343      343\n",
       "136      Видалення-аварійних-пошкоджених-хворобами-дерев      320      320\n",
       "62       Контроль-за-станом-рекламних-засобів                 318      318\n",
       "32       Перевірка-дозвільної-документації-демонтаж-літн...   316      316\n",
       "168      Інші-Подяки                                          305      305\n",
       "105      Встановлення-огородження-зеленої-зони                288      288\n",
       "74       Знищення-омели-амброзії-та-рослин-паразитів          284      284\n",
       "14       Аварійний-травмонебезпечний-стан-утримання-об-є...   279      279\n",
       "145      Не-працює-вантажний-ліфт                             271      271\n",
       "128      Встановлення-сигнальних-стовпчиків-бар-єрних-ог...   269      269\n",
       "2        Відсутнє-електропостачання                           262      262"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uk_doc_df.groupby(['topic_id', 'tags']).count().sort_values(['id'], ascending = False).head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Виділяємо лейбли."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61473"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "topic_labels = np.array([doc.topic_id for doc in uk_documents])\n",
    "len(topic_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "І розбиваємо дані на тренувальні і тестові."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_documents, test_documents, train_topic_labels, test_topic_labels = \\\n",
    "    train_test_split(uk_documents, topic_labels, random_state = 26, test_size = 0.3, stratify = topic_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43031\n",
      "43031\n"
     ]
    }
   ],
   "source": [
    "print(len(train_documents))\n",
    "print(len(train_topic_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18442\n",
      "18442\n"
     ]
    }
   ],
   "source": [
    "print(len(test_documents))\n",
    "print(len(test_topic_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline\n",
    "\n",
    "Будуємо бейзлайн, знаходимо суму векторів слів по кожному документу і використовуємо kNN на знайденних векторах. Для порівняння векторів застосовуємо cosine similarity. Перед знаходженням суми векторів, документ токенізується та видаляються stop words. Знайдені вектори нормалізуються, в такому випадку eclidean distance для kNN має той самий ефект що й cosine distance, при цьому алгоритм дозволяє використовувати більш ефективні структури данних, такі як, наприклад, k-d tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tokenize_uk\n",
    "import string\n",
    "\n",
    "with open('uk_stop_words.txt') as f:\n",
    "    STOP_WORDS = f.read().split()\n",
    "    \n",
    "EXT_PUNCTUATION = \"”...\"\n",
    "\n",
    "def non_stop_word(word):\n",
    "    return not (word in string.punctuation or word in EXT_PUNCTUATION \\\n",
    "                or word in STOP_WORDS or word.isnumeric()) and word.isalpha() and len(word) > 3\n",
    "\n",
    "def remove_stop_words(tokens):\n",
    "    return [token for token in tokens if non_stop_word(token.lower())]\n",
    "\n",
    "def tokenize_doc(doc):\n",
    "    return [word.lower() for word in \\\n",
    "            remove_stop_words(tokenize_uk.tokenize_words(doc.content))]\n",
    "\n",
    "def normalize_vec(x):\n",
    "    m = np.max(x)\n",
    "    if m > 0.0:\n",
    "        return x/np.sqrt(np.dot(x,x))\n",
    "    return x\n",
    "    \n",
    "def doc_to_sum_vec(doc):\n",
    "    words = tokenize_doc(doc)    \n",
    "    vec = np.zeros(300)\n",
    "    for word in words:\n",
    "        try:\n",
    "            vec += wv[word]\n",
    "        except KeyError as e:            \n",
    "            pass\n",
    "        \n",
    "    return vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рахуємо вектори для тренувальних і тестових документів."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a712439b7154294a386ce4aa4da6585",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=43031), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_doc_sum_vecs = np.array([doc_to_sum_vec(doc) for doc in tqdm_notebook(train_documents)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32910085d6ce4b9ba392159a7f1ebbb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=18442), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_doc_sum_vecs = np.array([doc_to_sum_vec(doc) for doc in tqdm_notebook(test_documents)]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тренуємо модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "class Model:\n",
    "    def __init__(self, train_vectors, train_labels, test_vectors, test_labels):\n",
    "        self.train_vectors = train_vectors\n",
    "        self.train_labels = train_labels\n",
    "        self.test_vectors = test_vectors\n",
    "        self.test_labels = test_labels\n",
    "        \n",
    "    def train(self):\n",
    "        self.model.fit(self.train_vectors, self.train_labels)\n",
    "        self.topics_predicted = self.model.predict(self.test_vectors)\n",
    "        \n",
    "    def test(self):\n",
    "        print(classification_report(self.test_labels, self.topics_predicted))  \n",
    "\n",
    "class KnnModel(Model):\n",
    "    def __init__(self, train_vectors, train_labels, test_vectors, test_labels, n = 1):\n",
    "        super().__init__(np.array([normalize_vec(doc) for doc in train_vectors]),\\\n",
    "                       train_labels,\\\n",
    "                       np.array([normalize_vec(doc) for doc in test_vectors]),\\\n",
    "                       test_labels)                \n",
    "        self.model = KNeighborsClassifier(n_neighbors = n, algorithm='kd_tree', metric = 'euclidean', n_jobs = 6)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KnnModel(train_doc_sum_vecs, train_topic_labels, test_doc_sum_vecs, test_topic_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9min 46s, sys: 514 ms, total: 9min 47s\n",
      "Wall time: 1min 44s\n"
     ]
    }
   ],
   "source": [
    "%time knn.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.52      0.47       330\n",
      "           1       0.69      0.72      0.71        40\n",
      "           2       0.46      0.29      0.36        78\n",
      "           3       0.38      0.26      0.31        39\n",
      "           4       0.43      0.14      0.21        22\n",
      "           5       0.38      0.34      0.36       106\n",
      "           6       0.18      0.21      0.19       141\n",
      "           7       0.26      0.26      0.26        62\n",
      "           8       0.48      0.50      0.49        30\n",
      "           9       0.50      0.18      0.27        22\n",
      "          10       0.52      0.50      0.51       145\n",
      "          11       0.28      0.24      0.26        29\n",
      "          12       0.62      0.38      0.47        21\n",
      "          13       0.18      0.18      0.18        44\n",
      "          14       0.26      0.19      0.22        84\n",
      "          15       0.20      0.12      0.15        16\n",
      "          16       0.46      0.50      0.48       120\n",
      "          17       0.00      0.00      0.00        15\n",
      "          18       0.25      0.21      0.23        53\n",
      "          19       0.43      0.15      0.22        20\n",
      "          20       0.27      0.19      0.22        16\n",
      "          21       0.32      0.24      0.27        25\n",
      "          22       0.44      0.41      0.42       192\n",
      "          23       0.68      0.53      0.59        51\n",
      "          24       0.53      0.37      0.44        46\n",
      "          25       0.23      0.25      0.24        28\n",
      "          26       0.62      0.32      0.42        25\n",
      "          27       0.56      0.63      0.59       938\n",
      "          28       0.31      0.38      0.34        56\n",
      "          29       0.22      0.22      0.22        63\n",
      "          30       0.29      0.21      0.24        43\n",
      "          31       0.22      0.08      0.12        25\n",
      "          32       0.44      0.54      0.49        95\n",
      "          33       0.50      0.50      0.50       128\n",
      "          34       0.46      0.43      0.45        44\n",
      "          35       0.20      0.29      0.24        35\n",
      "          36       0.14      0.14      0.14        49\n",
      "          37       0.30      0.15      0.20        39\n",
      "          38       0.63      0.58      0.60        38\n",
      "          39       0.44      0.33      0.37        43\n",
      "          40       0.56      0.54      0.55       115\n",
      "          41       0.37      0.31      0.33       143\n",
      "          42       0.53      0.65      0.58        62\n",
      "          43       0.33      0.15      0.21        40\n",
      "          44       0.12      0.17      0.14        30\n",
      "          45       0.20      0.18      0.19        71\n",
      "          46       0.44      0.44      0.44        55\n",
      "          47       0.27      0.19      0.22        21\n",
      "          48       0.12      0.12      0.12        16\n",
      "          49       0.38      0.28      0.32        18\n",
      "          50       0.38      0.34      0.36        44\n",
      "          51       0.56      0.25      0.34        20\n",
      "          52       0.11      0.15      0.13        26\n",
      "          53       0.45      0.33      0.38        52\n",
      "          54       0.11      0.17      0.13        18\n",
      "          55       0.16      0.19      0.17        26\n",
      "          56       0.50      0.26      0.34        27\n",
      "          57       0.48      0.44      0.46       106\n",
      "          58       0.57      0.58      0.57       365\n",
      "          59       0.24      0.26      0.25        74\n",
      "          60       0.30      0.29      0.29        35\n",
      "          61       0.08      0.08      0.08        24\n",
      "          62       0.43      0.31      0.36        95\n",
      "          63       0.21      0.24      0.22        17\n",
      "          64       0.71      0.54      0.62        37\n",
      "          65       0.00      0.00      0.00        14\n",
      "          66       0.43      0.48      0.46        33\n",
      "          67       0.32      0.56      0.41       601\n",
      "          68       0.49      0.58      0.53       190\n",
      "          69       0.21      0.23      0.22       104\n",
      "          70       0.32      0.31      0.32        35\n",
      "          71       0.35      0.19      0.24        48\n",
      "          72       0.25      0.24      0.24        21\n",
      "          73       0.43      0.36      0.39        33\n",
      "          74       0.70      0.79      0.74        85\n",
      "          75       0.60      0.70      0.65        30\n",
      "          76       0.39      0.18      0.25        49\n",
      "          77       0.18      0.14      0.16        43\n",
      "          78       0.47      0.45      0.46       103\n",
      "          79       0.40      0.37      0.39       388\n",
      "          80       0.22      0.11      0.15        18\n",
      "          81       0.67      0.57      0.62        28\n",
      "          82       0.23      0.25      0.24        20\n",
      "          83       0.22      0.09      0.12        23\n",
      "          84       0.22      0.29      0.25        52\n",
      "          85       0.27      0.18      0.22        22\n",
      "          86       0.47      0.28      0.35        74\n",
      "          87       0.35      0.37      0.36        35\n",
      "          88       0.39      0.35      0.37       296\n",
      "          89       0.43      0.47      0.45        40\n",
      "          90       0.25      0.12      0.17        16\n",
      "          91       0.21      0.24      0.23        38\n",
      "          92       0.62      0.31      0.41        26\n",
      "          93       0.71      0.68      0.70        22\n",
      "          94       0.33      0.21      0.26        19\n",
      "          95       0.48      0.24      0.32        42\n",
      "          96       0.45      0.25      0.32        20\n",
      "          97       0.50      0.50      0.50        24\n",
      "          98       0.47      0.35      0.40        23\n",
      "          99       0.41      0.38      0.39        34\n",
      "         100       0.16      0.19      0.17        54\n",
      "         101       0.39      0.50      0.44       328\n",
      "         102       0.58      0.39      0.47        74\n",
      "         103       0.36      0.26      0.30        19\n",
      "         104       0.66      0.68      0.67        37\n",
      "         105       0.25      0.24      0.25        87\n",
      "         106       0.09      0.13      0.10        46\n",
      "         107       0.38      0.29      0.33        31\n",
      "         108       0.45      0.24      0.31        21\n",
      "         109       0.38      0.38      0.38       154\n",
      "         110       0.28      0.33      0.30        66\n",
      "         111       0.57      0.40      0.47        20\n",
      "         112       0.28      0.27      0.27        78\n",
      "         113       0.32      0.25      0.28        56\n",
      "         114       0.47      0.43      0.45       138\n",
      "         115       0.27      0.18      0.21        17\n",
      "         116       0.55      0.47      0.51       131\n",
      "         117       0.15      0.13      0.14        78\n",
      "         118       0.22      0.18      0.20        38\n",
      "         119       0.45      0.49      0.47        47\n",
      "         120       0.33      0.33      0.33        15\n",
      "         121       0.52      0.52      0.52       378\n",
      "         122       0.70      0.50      0.58        38\n",
      "         123       0.31      0.28      0.30        78\n",
      "         124       0.31      0.16      0.21        25\n",
      "         125       0.25      0.18      0.21        73\n",
      "         126       0.88      0.70      0.78        20\n",
      "         127       0.50      0.50      0.50       658\n",
      "         128       0.22      0.29      0.25        79\n",
      "         129       0.39      0.45      0.42        20\n",
      "         130       0.12      0.06      0.08        17\n",
      "         131       0.25      0.18      0.21       136\n",
      "         132       0.24      0.14      0.18        43\n",
      "         133       0.33      0.28      0.30        54\n",
      "         134       0.45      0.44      0.45        63\n",
      "         135       0.25      0.21      0.23        57\n",
      "         136       0.44      0.36      0.40        96\n",
      "         137       0.32      0.20      0.25        60\n",
      "         138       0.67      0.70      0.68      1958\n",
      "         139       0.34      0.34      0.34        53\n",
      "         140       0.10      0.20      0.13        15\n",
      "         141       0.31      0.20      0.24        25\n",
      "         142       0.32      0.35      0.33        17\n",
      "         143       0.37      0.37      0.37       293\n",
      "         144       0.31      0.25      0.28        40\n",
      "         145       0.43      0.47      0.45        81\n",
      "         146       0.50      0.28      0.36        25\n",
      "         147       0.12      0.08      0.10        25\n",
      "         148       0.36      0.35      0.36       207\n",
      "         149       0.14      0.07      0.09        15\n",
      "         150       0.27      0.40      0.32        60\n",
      "         151       0.17      0.15      0.16        20\n",
      "         152       0.27      0.19      0.22        21\n",
      "         153       0.28      0.21      0.24        33\n",
      "         154       0.40      0.45      0.42       141\n",
      "         155       0.38      0.38      0.38       383\n",
      "         156       0.28      0.21      0.24        56\n",
      "         157       0.36      0.22      0.27        23\n",
      "         158       0.50      0.38      0.43        52\n",
      "         159       0.50      0.43      0.47        23\n",
      "         160       0.27      0.23      0.25        44\n",
      "         161       0.49      0.46      0.47       239\n",
      "         162       0.19      0.19      0.19        26\n",
      "         163       0.35      0.29      0.32        21\n",
      "         164       0.44      0.37      0.40       161\n",
      "         165       0.44      0.28      0.35        67\n",
      "         166       0.35      0.18      0.24        71\n",
      "         167       0.73      0.48      0.58        62\n",
      "         168       0.41      0.17      0.24        92\n",
      "         169       0.39      0.71      0.51        34\n",
      "         170       0.35      0.24      0.29        37\n",
      "         171       0.46      0.46      0.46       224\n",
      "         172       0.36      0.21      0.26        24\n",
      "         173       0.56      0.51      0.53       247\n",
      "         174       0.40      0.45      0.42       191\n",
      "         175       0.24      0.25      0.25        52\n",
      "         176       0.37      0.34      0.35       235\n",
      "         177       0.21      0.21      0.21        39\n",
      "         178       0.35      0.43      0.39       198\n",
      "         179       0.16      0.16      0.16        31\n",
      "         180       0.48      0.51      0.49      1085\n",
      "         181       0.31      0.27      0.29       182\n",
      "         182       0.36      0.29      0.32        28\n",
      "         183       0.37      0.42      0.40       356\n",
      "         184       0.70      0.74      0.72        19\n",
      "         185       0.23      0.26      0.25        34\n",
      "         186       0.39      0.23      0.29        40\n",
      "         187       0.36      0.16      0.22        25\n",
      "\n",
      "   micro avg       0.44      0.44      0.44     18442\n",
      "   macro avg       0.37      0.32      0.34     18442\n",
      "weighted avg       0.44      0.44      0.43     18442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imrovements\n",
    "\n",
    "Намагаємося покращити результат. Спочатку будемо використовувати логістичну регресію, потім проробимо все те саме але з векторами Doc2Vec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "class LogregModel(Model):\n",
    "    def __init__(self, train_vectors, train_labels, test_vectors, test_labels, iters = 3000):\n",
    "        super().__init__(train_vectors, train_labels, test_vectors, test_labels)\n",
    "        self.model = LogisticRegression(random_state=26, n_jobs = 6, solver=\"lbfgs\", \\\n",
    "                                        multi_class=\"multinomial\", max_iter = iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogregModel(train_doc_sum_vecs, train_topic_labels, test_doc_sum_vecs, test_topic_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 245 ms, sys: 369 ms, total: 614 ms\n",
      "Wall time: 36min 56s\n"
     ]
    }
   ],
   "source": [
    "%time logreg.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.47      0.52       330\n",
      "           1       0.87      0.65      0.74        40\n",
      "           2       0.48      0.53      0.50        78\n",
      "           3       0.26      0.18      0.21        39\n",
      "           4       0.60      0.27      0.37        22\n",
      "           5       0.43      0.46      0.45       106\n",
      "           6       0.26      0.17      0.20       141\n",
      "           7       0.41      0.42      0.41        62\n",
      "           8       0.61      0.67      0.63        30\n",
      "           9       0.35      0.27      0.31        22\n",
      "          10       0.67      0.68      0.68       145\n",
      "          11       0.18      0.28      0.22        29\n",
      "          12       0.74      0.67      0.70        21\n",
      "          13       0.19      0.30      0.23        44\n",
      "          14       0.13      0.11      0.12        84\n",
      "          15       0.33      0.25      0.29        16\n",
      "          16       0.44      0.57      0.50       120\n",
      "          17       0.33      0.27      0.30        15\n",
      "          18       0.28      0.30      0.29        53\n",
      "          19       0.50      0.40      0.44        20\n",
      "          20       0.22      0.12      0.16        16\n",
      "          21       0.26      0.44      0.33        25\n",
      "          22       0.54      0.39      0.45       192\n",
      "          23       0.71      0.73      0.72        51\n",
      "          24       0.46      0.57      0.50        46\n",
      "          25       0.18      0.32      0.23        28\n",
      "          26       0.41      0.44      0.42        25\n",
      "          27       0.75      0.72      0.74       938\n",
      "          28       0.32      0.45      0.38        56\n",
      "          29       0.27      0.33      0.30        63\n",
      "          30       0.15      0.23      0.18        43\n",
      "          31       0.11      0.16      0.13        25\n",
      "          32       0.54      0.58      0.56        95\n",
      "          33       0.64      0.64      0.64       128\n",
      "          34       0.39      0.45      0.42        44\n",
      "          35       0.25      0.34      0.29        35\n",
      "          36       0.15      0.14      0.15        49\n",
      "          37       0.10      0.13      0.11        39\n",
      "          38       0.67      0.76      0.72        38\n",
      "          39       0.24      0.37      0.29        43\n",
      "          40       0.52      0.60      0.56       115\n",
      "          41       0.50      0.36      0.42       143\n",
      "          42       0.49      0.65      0.56        62\n",
      "          43       0.35      0.42      0.38        40\n",
      "          44       0.14      0.13      0.14        30\n",
      "          45       0.44      0.45      0.44        71\n",
      "          46       0.48      0.71      0.57        55\n",
      "          47       0.25      0.33      0.29        21\n",
      "          48       0.08      0.06      0.07        16\n",
      "          49       0.40      0.33      0.36        18\n",
      "          50       0.31      0.45      0.37        44\n",
      "          51       0.46      0.30      0.36        20\n",
      "          52       0.14      0.19      0.16        26\n",
      "          53       0.41      0.42      0.42        52\n",
      "          54       0.10      0.17      0.13        18\n",
      "          55       0.08      0.12      0.09        26\n",
      "          56       0.55      0.67      0.60        27\n",
      "          57       0.52      0.56      0.54       106\n",
      "          58       0.68      0.60      0.63       365\n",
      "          59       0.30      0.30      0.30        74\n",
      "          60       0.21      0.37      0.27        35\n",
      "          61       0.13      0.25      0.17        24\n",
      "          62       0.30      0.27      0.29        95\n",
      "          63       0.26      0.29      0.28        17\n",
      "          64       0.49      0.62      0.55        37\n",
      "          65       0.11      0.07      0.09        14\n",
      "          66       0.38      0.45      0.42        33\n",
      "          67       0.59      0.56      0.58       601\n",
      "          68       0.61      0.61      0.61       190\n",
      "          69       0.28      0.17      0.21       104\n",
      "          70       0.53      0.51      0.52        35\n",
      "          71       0.24      0.25      0.24        48\n",
      "          72       0.17      0.14      0.15        21\n",
      "          73       0.30      0.48      0.37        33\n",
      "          74       0.64      0.74      0.68        85\n",
      "          75       0.46      0.63      0.54        30\n",
      "          76       0.47      0.55      0.50        49\n",
      "          77       0.28      0.33      0.30        43\n",
      "          78       0.41      0.38      0.39       103\n",
      "          79       0.56      0.35      0.43       388\n",
      "          80       0.27      0.22      0.24        18\n",
      "          81       0.83      0.71      0.77        28\n",
      "          82       0.24      0.30      0.27        20\n",
      "          83       0.15      0.09      0.11        23\n",
      "          84       0.29      0.40      0.34        52\n",
      "          85       0.31      0.41      0.35        22\n",
      "          86       0.34      0.36      0.35        74\n",
      "          87       0.19      0.29      0.23        35\n",
      "          88       0.62      0.44      0.52       296\n",
      "          89       0.54      0.47      0.51        40\n",
      "          90       0.13      0.12      0.13        16\n",
      "          91       0.22      0.37      0.27        38\n",
      "          92       0.47      0.31      0.37        26\n",
      "          93       0.89      0.73      0.80        22\n",
      "          94       0.06      0.11      0.08        19\n",
      "          95       0.25      0.40      0.31        42\n",
      "          96       0.53      0.50      0.51        20\n",
      "          97       0.42      0.58      0.49        24\n",
      "          98       0.17      0.39      0.24        23\n",
      "          99       0.26      0.41      0.32        34\n",
      "         100       0.20      0.17      0.18        54\n",
      "         101       0.55      0.40      0.46       328\n",
      "         102       0.53      0.57      0.55        74\n",
      "         103       0.25      0.32      0.28        19\n",
      "         104       0.75      0.65      0.70        37\n",
      "         105       0.25      0.22      0.23        87\n",
      "         106       0.13      0.13      0.13        46\n",
      "         107       0.28      0.29      0.29        31\n",
      "         108       0.70      0.33      0.45        21\n",
      "         109       0.40      0.30      0.34       154\n",
      "         110       0.32      0.32      0.32        66\n",
      "         111       0.40      0.40      0.40        20\n",
      "         112       0.41      0.36      0.38        78\n",
      "         113       0.30      0.32      0.31        56\n",
      "         114       0.42      0.37      0.39       138\n",
      "         115       0.10      0.18      0.13        17\n",
      "         116       0.59      0.50      0.54       131\n",
      "         117       0.20      0.10      0.13        78\n",
      "         118       0.20      0.29      0.23        38\n",
      "         119       0.37      0.51      0.43        47\n",
      "         120       0.28      0.33      0.30        15\n",
      "         121       0.57      0.57      0.57       378\n",
      "         122       0.50      0.55      0.53        38\n",
      "         123       0.43      0.47      0.45        78\n",
      "         124       0.19      0.32      0.24        25\n",
      "         125       0.19      0.15      0.17        73\n",
      "         126       0.85      0.55      0.67        20\n",
      "         127       0.68      0.54      0.60       658\n",
      "         128       0.19      0.16      0.18        79\n",
      "         129       0.32      0.45      0.38        20\n",
      "         130       0.12      0.06      0.08        17\n",
      "         131       0.29      0.21      0.24       136\n",
      "         132       0.12      0.16      0.14        43\n",
      "         133       0.19      0.28      0.23        54\n",
      "         134       0.46      0.49      0.47        63\n",
      "         135       0.26      0.28      0.27        57\n",
      "         136       0.47      0.49      0.48        96\n",
      "         137       0.35      0.52      0.42        60\n",
      "         138       0.61      0.80      0.69      1958\n",
      "         139       0.39      0.45      0.42        53\n",
      "         140       0.18      0.27      0.22        15\n",
      "         141       0.16      0.28      0.20        25\n",
      "         142       0.26      0.29      0.28        17\n",
      "         143       0.27      0.21      0.24       293\n",
      "         144       0.18      0.28      0.22        40\n",
      "         145       0.45      0.52      0.48        81\n",
      "         146       0.44      0.32      0.37        25\n",
      "         147       0.12      0.24      0.16        25\n",
      "         148       0.40      0.29      0.34       207\n",
      "         149       0.50      0.13      0.21        15\n",
      "         150       0.34      0.42      0.38        60\n",
      "         151       0.33      0.30      0.32        20\n",
      "         152       0.58      0.33      0.42        21\n",
      "         153       0.24      0.30      0.27        33\n",
      "         154       0.58      0.55      0.56       141\n",
      "         155       0.55      0.39      0.46       383\n",
      "         156       0.25      0.29      0.27        56\n",
      "         157       0.60      0.26      0.36        23\n",
      "         158       0.30      0.37      0.33        52\n",
      "         159       0.48      0.43      0.45        23\n",
      "         160       0.14      0.18      0.16        44\n",
      "         161       0.53      0.50      0.52       239\n",
      "         162       0.24      0.27      0.25        26\n",
      "         163       0.44      0.33      0.38        21\n",
      "         164       0.40      0.36      0.38       161\n",
      "         165       0.32      0.37      0.35        67\n",
      "         166       0.32      0.28      0.30        71\n",
      "         167       0.57      0.74      0.64        62\n",
      "         168       0.32      0.34      0.33        92\n",
      "         169       0.52      0.74      0.61        34\n",
      "         170       0.32      0.51      0.39        37\n",
      "         171       0.40      0.29      0.33       224\n",
      "         172       0.09      0.21      0.13        24\n",
      "         173       0.71      0.64      0.67       247\n",
      "         174       0.53      0.44      0.48       191\n",
      "         175       0.25      0.27      0.26        52\n",
      "         176       0.57      0.46      0.50       235\n",
      "         177       0.20      0.28      0.23        39\n",
      "         178       0.64      0.53      0.58       198\n",
      "         179       0.16      0.19      0.18        31\n",
      "         180       0.57      0.59      0.58      1085\n",
      "         181       0.51      0.32      0.40       182\n",
      "         182       0.20      0.29      0.24        28\n",
      "         183       0.58      0.45      0.51       356\n",
      "         184       0.56      0.47      0.51        19\n",
      "         185       0.23      0.32      0.27        34\n",
      "         186       0.26      0.30      0.28        40\n",
      "         187       0.38      0.24      0.29        25\n",
      "\n",
      "   micro avg       0.49      0.49      0.49     18442\n",
      "   macro avg       0.38      0.38      0.37     18442\n",
      "weighted avg       0.50      0.49      0.49     18442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Є невелике покращення в якості. Переходимо до Doc2Vec. Для цього використовуємо gensim. Спочатку конвертуємо наші документи в модель gensim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import TaggedDocument\n",
    "\n",
    "def to_tagged_doc(doc):\n",
    "    words = tokenize_doc(doc)\n",
    "    return TaggedDocument(words, [doc.topic_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=['заявляю', 'чергове', 'втручання', 'діяльність', 'інформаційної', 'системи', 'колцентру', 'метою', 'викривлення', 'відомостей', 'стосовно', 'результатів', 'вирішення', 'поданих', 'звернень', 'даний', 'відмітку', 'виконано', 'наводжу', 'витяг', 'березня', 'перегляд', 'інтерактивній', 'картівідсутність', 'відповідальний', 'печерська', 'брама', 'мазурчак', 'олександр', 'володимирович', 'дата', 'контролю', 'березня', 'статус', 'виконано', 'відповідаю', 'дійсності', 'оскільки', 'годин', 'офіційно', 'отриманий', 'електронний', 'запит', 'виклав', 'текст', 'протилежного', 'змісту', 'наводжу', 'заявника', 'квітня', 'статус', 'виконано', 'квартира', 'розташована', 'відношення', 'перекриття', 'стояка', 'заміна', 'вентиля', 'сусідів', 'потребує', 'перекриття', 'водопостачання', 'будинку', 'викличе', 'появу', 'трубах', 'будинку', 'стільки', 'бруду', 'зливався', 'понад', 'хвилини', 'хвилину', 'вигаданих', 'нормативів', 'скарги', 'взагалі', 'подавались', 'заради', 'отримання', 'пустих', 'усунення', 'проблеми', 'рахунок', 'винуватців', 'поборами', 'договір'], tags=[0])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_tagged_doc(uk_documents[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58bb9613d6394753aa9bdea2bf9674a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=43031), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_tagged_docs = [to_tagged_doc(doc) for doc in tqdm_notebook(train_documents)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b17e8f8587ba44c184eb6bb05d4dd604",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=18442), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_tagged_docs = [to_tagged_doc(doc) for doc in tqdm_notebook(test_documents)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Потім тренуємо PV-DBOW модель. Розмір вектору документа 300, як і в моделі з embeddins, яку ми використовували в бейзлайні."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec\n",
    "\n",
    "dbow_model = Doc2Vec(dm=0, vector_size=300, min_count=5, window=10, workers=6, epochs=120)\n",
    "\n",
    "dbow_model.build_vocab(train_tagged_docs + test_tagged_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9min 36s, sys: 44 s, total: 10min 20s\n",
      "Wall time: 4min 8s\n"
     ]
    }
   ],
   "source": [
    "%time dbow_model.train(train_tagged_docs, total_examples=dbow_model.corpus_count, epochs=dbow_model.epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Збираємо вектори документів."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd5bdb06735344e990cb7c9ea4543f59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=43031), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_doc_vecs = np.array([dbow_model.infer_vector(doc.words) for doc in tqdm_notebook(train_tagged_docs)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fda66eb70ed64a859a631edc3f2f0586",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=18442), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_doc_vecs = np.array([dbow_model.infer_vector(doc.words) for doc in tqdm_notebook(test_tagged_docs)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Знову намагаємося застосувати kNN та логістичну регресію на отриманних векторах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn2 = KnnModel(train_doc_vecs, train_topic_labels, test_doc_vecs, test_topic_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10min 49s, sys: 19.5 ms, total: 10min 49s\n",
      "Wall time: 1min 55s\n"
     ]
    }
   ],
   "source": [
    "%time knn2.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.50      0.51       330\n",
      "           1       0.66      0.72      0.69        40\n",
      "           2       0.56      0.58      0.57        78\n",
      "           3       0.37      0.44      0.40        39\n",
      "           4       0.54      0.32      0.40        22\n",
      "           5       0.47      0.62      0.54       106\n",
      "           6       0.43      0.32      0.37       141\n",
      "           7       0.64      0.56      0.60        62\n",
      "           8       0.48      0.87      0.62        30\n",
      "           9       0.58      0.68      0.62        22\n",
      "          10       0.70      0.83      0.76       145\n",
      "          11       0.50      0.21      0.29        29\n",
      "          12       0.70      0.90      0.79        21\n",
      "          13       0.50      0.27      0.35        44\n",
      "          14       0.27      0.20      0.23        84\n",
      "          15       0.44      0.44      0.44        16\n",
      "          16       0.47      0.65      0.55       120\n",
      "          17       0.36      0.33      0.34        15\n",
      "          18       0.31      0.25      0.27        53\n",
      "          19       0.31      0.20      0.24        20\n",
      "          20       0.25      0.19      0.21        16\n",
      "          21       0.47      0.28      0.35        25\n",
      "          22       0.56      0.48      0.52       192\n",
      "          23       0.54      0.76      0.63        51\n",
      "          24       0.51      0.50      0.51        46\n",
      "          25       0.50      0.68      0.58        28\n",
      "          26       0.47      0.64      0.54        25\n",
      "          27       0.64      0.76      0.70       938\n",
      "          28       0.60      0.55      0.57        56\n",
      "          29       0.41      0.33      0.37        63\n",
      "          30       0.48      0.30      0.37        43\n",
      "          31       0.11      0.20      0.14        25\n",
      "          32       0.75      0.68      0.71        95\n",
      "          33       0.66      0.67      0.67       128\n",
      "          34       0.40      0.48      0.44        44\n",
      "          35       0.28      0.29      0.28        35\n",
      "          36       0.21      0.10      0.14        49\n",
      "          37       0.39      0.23      0.29        39\n",
      "          38       0.51      0.82      0.63        38\n",
      "          39       0.33      0.37      0.35        43\n",
      "          40       0.47      0.71      0.57       115\n",
      "          41       0.38      0.50      0.44       143\n",
      "          42       0.67      0.71      0.69        62\n",
      "          43       0.55      0.70      0.62        40\n",
      "          44       0.30      0.23      0.26        30\n",
      "          45       0.59      0.28      0.38        71\n",
      "          46       0.63      0.62      0.62        55\n",
      "          47       0.29      0.48      0.36        21\n",
      "          48       0.21      0.25      0.23        16\n",
      "          49       0.47      0.50      0.49        18\n",
      "          50       0.51      0.61      0.56        44\n",
      "          51       0.62      0.50      0.56        20\n",
      "          52       0.24      0.15      0.19        26\n",
      "          53       0.44      0.52      0.47        52\n",
      "          54       0.18      0.17      0.17        18\n",
      "          55       0.21      0.12      0.15        26\n",
      "          56       0.88      0.85      0.87        27\n",
      "          57       0.51      0.59      0.55       106\n",
      "          58       0.65      0.76      0.70       365\n",
      "          59       0.45      0.51      0.48        74\n",
      "          60       0.55      0.31      0.40        35\n",
      "          61       0.17      0.08      0.11        24\n",
      "          62       0.44      0.47      0.45        95\n",
      "          63       0.21      0.29      0.24        17\n",
      "          64       0.60      0.81      0.69        37\n",
      "          65       1.00      0.14      0.25        14\n",
      "          66       0.42      0.30      0.35        33\n",
      "          67       0.53      0.61      0.57       601\n",
      "          68       0.61      0.55      0.58       190\n",
      "          69       0.35      0.28      0.31       104\n",
      "          70       0.67      0.74      0.70        35\n",
      "          71       0.72      0.27      0.39        48\n",
      "          72       0.20      0.14      0.17        21\n",
      "          73       0.39      0.61      0.48        33\n",
      "          74       0.70      0.88      0.78        85\n",
      "          75       0.53      0.77      0.63        30\n",
      "          76       0.60      0.51      0.55        49\n",
      "          77       0.44      0.72      0.55        43\n",
      "          78       0.53      0.39      0.45       103\n",
      "          79       0.44      0.41      0.43       388\n",
      "          80       0.11      0.17      0.13        18\n",
      "          81       0.53      0.93      0.68        28\n",
      "          82       0.27      0.20      0.23        20\n",
      "          83       0.05      0.04      0.05        23\n",
      "          84       0.57      0.33      0.41        52\n",
      "          85       0.50      0.45      0.48        22\n",
      "          86       0.60      0.43      0.50        74\n",
      "          87       0.39      0.31      0.35        35\n",
      "          88       0.56      0.41      0.48       296\n",
      "          89       0.61      0.62      0.62        40\n",
      "          90       0.27      0.25      0.26        16\n",
      "          91       0.32      0.24      0.27        38\n",
      "          92       0.93      0.50      0.65        26\n",
      "          93       0.58      0.86      0.69        22\n",
      "          94       0.21      0.21      0.21        19\n",
      "          95       0.41      0.38      0.40        42\n",
      "          96       0.57      0.40      0.47        20\n",
      "          97       0.35      0.75      0.48        24\n",
      "          98       0.39      0.39      0.39        23\n",
      "          99       0.36      0.53      0.43        34\n",
      "         100       0.38      0.33      0.36        54\n",
      "         101       0.64      0.48      0.55       328\n",
      "         102       0.78      0.81      0.79        74\n",
      "         103       0.40      0.42      0.41        19\n",
      "         104       0.57      0.76      0.65        37\n",
      "         105       0.30      0.21      0.24        87\n",
      "         106       0.31      0.24      0.27        46\n",
      "         107       0.30      0.19      0.24        31\n",
      "         108       0.43      0.48      0.45        21\n",
      "         109       0.50      0.47      0.48       154\n",
      "         110       0.41      0.32      0.36        66\n",
      "         111       0.64      0.45      0.53        20\n",
      "         112       0.58      0.63      0.60        78\n",
      "         113       0.51      0.41      0.46        56\n",
      "         114       0.48      0.57      0.52       138\n",
      "         115       0.18      0.18      0.18        17\n",
      "         116       0.56      0.57      0.57       131\n",
      "         117       0.29      0.19      0.23        78\n",
      "         118       0.56      0.24      0.33        38\n",
      "         119       0.47      0.57      0.51        47\n",
      "         120       0.21      0.27      0.24        15\n",
      "         121       0.56      0.56      0.56       378\n",
      "         122       0.49      0.55      0.52        38\n",
      "         123       0.40      0.47      0.43        78\n",
      "         124       0.47      0.28      0.35        25\n",
      "         125       0.18      0.11      0.14        73\n",
      "         126       0.52      0.55      0.54        20\n",
      "         127       0.67      0.64      0.66       658\n",
      "         128       0.29      0.25      0.27        79\n",
      "         129       0.40      0.40      0.40        20\n",
      "         130       0.21      0.18      0.19        17\n",
      "         131       0.32      0.28      0.30       136\n",
      "         132       0.35      0.30      0.32        43\n",
      "         133       0.36      0.31      0.34        54\n",
      "         134       0.49      0.59      0.54        63\n",
      "         135       0.37      0.30      0.33        57\n",
      "         136       0.63      0.49      0.55        96\n",
      "         137       0.55      0.65      0.60        60\n",
      "         138       0.73      0.81      0.77      1958\n",
      "         139       0.34      0.47      0.40        53\n",
      "         140       0.21      0.20      0.21        15\n",
      "         141       0.36      0.48      0.41        25\n",
      "         142       0.57      0.47      0.52        17\n",
      "         143       0.47      0.34      0.40       293\n",
      "         144       0.29      0.40      0.33        40\n",
      "         145       0.50      0.67      0.57        81\n",
      "         146       0.50      0.44      0.47        25\n",
      "         147       0.33      0.20      0.25        25\n",
      "         148       0.46      0.36      0.41       207\n",
      "         149       0.56      0.33      0.42        15\n",
      "         150       0.60      0.43      0.50        60\n",
      "         151       0.35      0.35      0.35        20\n",
      "         152       0.50      0.43      0.46        21\n",
      "         153       0.22      0.27      0.24        33\n",
      "         154       0.67      0.65      0.66       141\n",
      "         155       0.48      0.39      0.43       383\n",
      "         156       0.39      0.38      0.38        56\n",
      "         157       0.32      0.30      0.31        23\n",
      "         158       0.50      0.52      0.51        52\n",
      "         159       0.78      0.61      0.68        23\n",
      "         160       0.34      0.23      0.27        44\n",
      "         161       0.55      0.49      0.52       239\n",
      "         162       0.73      0.31      0.43        26\n",
      "         163       0.52      0.52      0.52        21\n",
      "         164       0.52      0.48      0.50       161\n",
      "         165       0.49      0.42      0.45        67\n",
      "         166       0.38      0.35      0.36        71\n",
      "         167       0.72      0.85      0.78        62\n",
      "         168       0.25      0.21      0.22        92\n",
      "         169       0.35      0.53      0.42        34\n",
      "         170       0.50      0.51      0.51        37\n",
      "         171       0.44      0.54      0.48       224\n",
      "         172       0.30      0.12      0.18        24\n",
      "         173       0.70      0.68      0.69       247\n",
      "         174       0.57      0.59      0.58       191\n",
      "         175       0.43      0.25      0.32        52\n",
      "         176       0.48      0.57      0.52       235\n",
      "         177       0.35      0.33      0.34        39\n",
      "         178       0.69      0.55      0.61       198\n",
      "         179       0.39      0.29      0.33        31\n",
      "         180       0.60      0.64      0.62      1085\n",
      "         181       0.44      0.36      0.40       182\n",
      "         182       0.36      0.43      0.39        28\n",
      "         183       0.56      0.48      0.52       356\n",
      "         184       0.59      0.68      0.63        19\n",
      "         185       0.25      0.18      0.21        34\n",
      "         186       0.57      0.57      0.57        40\n",
      "         187       0.29      0.24      0.26        25\n",
      "\n",
      "   micro avg       0.55      0.55      0.55     18442\n",
      "   macro avg       0.46      0.45      0.44     18442\n",
      "weighted avg       0.54      0.55      0.54     18442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn2.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg2 = LogregModel(train_doc_vecs, train_topic_labels, test_doc_vecs, test_topic_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 314 ms, sys: 416 ms, total: 730 ms\n",
      "Wall time: 4min 32s\n"
     ]
    }
   ],
   "source": [
    "%time logreg2.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.48      0.48       330\n",
      "           1       0.90      0.68      0.77        40\n",
      "           2       0.53      0.51      0.52        78\n",
      "           3       0.54      0.36      0.43        39\n",
      "           4       0.60      0.14      0.22        22\n",
      "           5       0.53      0.56      0.54       106\n",
      "           6       0.33      0.30      0.32       141\n",
      "           7       0.65      0.52      0.58        62\n",
      "           8       0.72      0.77      0.74        30\n",
      "           9       0.56      0.64      0.60        22\n",
      "          10       0.77      0.83      0.80       145\n",
      "          11       0.56      0.17      0.26        29\n",
      "          12       0.93      0.62      0.74        21\n",
      "          13       0.55      0.25      0.34        44\n",
      "          14       0.32      0.24      0.27        84\n",
      "          15       0.50      0.31      0.38        16\n",
      "          16       0.53      0.59      0.56       120\n",
      "          17       0.20      0.07      0.10        15\n",
      "          18       0.33      0.25      0.28        53\n",
      "          19       0.71      0.25      0.37        20\n",
      "          20       0.60      0.19      0.29        16\n",
      "          21       0.40      0.32      0.36        25\n",
      "          22       0.52      0.54      0.53       192\n",
      "          23       0.73      0.73      0.73        51\n",
      "          24       0.63      0.48      0.54        46\n",
      "          25       0.52      0.46      0.49        28\n",
      "          26       0.56      0.36      0.44        25\n",
      "          27       0.68      0.68      0.68       938\n",
      "          28       0.55      0.54      0.54        56\n",
      "          29       0.31      0.29      0.30        63\n",
      "          30       0.35      0.26      0.30        43\n",
      "          31       0.15      0.08      0.11        25\n",
      "          32       0.76      0.68      0.72        95\n",
      "          33       0.68      0.62      0.64       128\n",
      "          34       0.50      0.48      0.49        44\n",
      "          35       0.30      0.26      0.28        35\n",
      "          36       0.33      0.20      0.25        49\n",
      "          37       0.35      0.18      0.24        39\n",
      "          38       0.72      0.74      0.73        38\n",
      "          39       0.47      0.42      0.44        43\n",
      "          40       0.65      0.66      0.66       115\n",
      "          41       0.46      0.52      0.49       143\n",
      "          42       0.64      0.66      0.65        62\n",
      "          43       0.55      0.53      0.54        40\n",
      "          44       0.26      0.17      0.20        30\n",
      "          45       0.49      0.45      0.47        71\n",
      "          46       0.71      0.65      0.68        55\n",
      "          47       0.47      0.38      0.42        21\n",
      "          48       0.12      0.06      0.08        16\n",
      "          49       0.42      0.28      0.33        18\n",
      "          50       0.63      0.39      0.48        44\n",
      "          51       0.62      0.50      0.56        20\n",
      "          52       0.30      0.12      0.17        26\n",
      "          53       0.51      0.42      0.46        52\n",
      "          54       0.18      0.11      0.14        18\n",
      "          55       0.15      0.08      0.10        26\n",
      "          56       0.95      0.67      0.78        27\n",
      "          57       0.64      0.58      0.61       106\n",
      "          58       0.74      0.70      0.72       365\n",
      "          59       0.44      0.49      0.46        74\n",
      "          60       0.50      0.20      0.29        35\n",
      "          61       0.43      0.12      0.19        24\n",
      "          62       0.40      0.37      0.38        95\n",
      "          63       0.33      0.24      0.28        17\n",
      "          64       0.69      0.73      0.71        37\n",
      "          65       1.00      0.14      0.25        14\n",
      "          66       0.61      0.42      0.50        33\n",
      "          67       0.61      0.63      0.62       601\n",
      "          68       0.58      0.58      0.58       190\n",
      "          69       0.32      0.36      0.34       104\n",
      "          70       0.82      0.51      0.63        35\n",
      "          71       0.60      0.31      0.41        48\n",
      "          72       0.40      0.19      0.26        21\n",
      "          73       0.49      0.58      0.53        33\n",
      "          74       0.85      0.87      0.86        85\n",
      "          75       0.66      0.70      0.68        30\n",
      "          76       0.57      0.49      0.53        49\n",
      "          77       0.63      0.63      0.63        43\n",
      "          78       0.68      0.47      0.55       103\n",
      "          79       0.46      0.44      0.45       388\n",
      "          80       0.58      0.39      0.47        18\n",
      "          81       0.81      0.61      0.69        28\n",
      "          82       0.80      0.20      0.32        20\n",
      "          83       0.12      0.09      0.10        23\n",
      "          84       0.59      0.31      0.41        52\n",
      "          85       0.64      0.32      0.42        22\n",
      "          86       0.48      0.47      0.48        74\n",
      "          87       0.33      0.26      0.29        35\n",
      "          88       0.54      0.50      0.52       296\n",
      "          89       0.74      0.62      0.68        40\n",
      "          90       0.43      0.19      0.26        16\n",
      "          91       0.37      0.34      0.36        38\n",
      "          92       0.65      0.42      0.51        26\n",
      "          93       0.88      0.68      0.77        22\n",
      "          94       0.17      0.16      0.16        19\n",
      "          95       0.28      0.31      0.30        42\n",
      "          96       0.64      0.35      0.45        20\n",
      "          97       0.55      0.75      0.63        24\n",
      "          98       0.50      0.26      0.34        23\n",
      "          99       0.47      0.47      0.47        34\n",
      "         100       0.37      0.30      0.33        54\n",
      "         101       0.49      0.50      0.49       328\n",
      "         102       0.87      0.78      0.82        74\n",
      "         103       0.67      0.42      0.52        19\n",
      "         104       0.88      0.76      0.81        37\n",
      "         105       0.29      0.24      0.26        87\n",
      "         106       0.13      0.15      0.14        46\n",
      "         107       0.50      0.16      0.24        31\n",
      "         108       0.88      0.33      0.48        21\n",
      "         109       0.45      0.40      0.42       154\n",
      "         110       0.34      0.21      0.26        66\n",
      "         111       0.70      0.35      0.47        20\n",
      "         112       0.68      0.56      0.62        78\n",
      "         113       0.57      0.29      0.38        56\n",
      "         114       0.50      0.54      0.52       138\n",
      "         115       0.25      0.18      0.21        17\n",
      "         116       0.59      0.57      0.58       131\n",
      "         117       0.27      0.24      0.26        78\n",
      "         118       0.60      0.24      0.34        38\n",
      "         119       0.53      0.53      0.53        47\n",
      "         120       0.50      0.27      0.35        15\n",
      "         121       0.61      0.60      0.60       378\n",
      "         122       0.75      0.47      0.58        38\n",
      "         123       0.43      0.47      0.45        78\n",
      "         124       0.38      0.24      0.29        25\n",
      "         125       0.42      0.29      0.34        73\n",
      "         126       0.69      0.45      0.55        20\n",
      "         127       0.61      0.70      0.65       658\n",
      "         128       0.30      0.28      0.29        79\n",
      "         129       0.41      0.35      0.38        20\n",
      "         130       0.25      0.12      0.16        17\n",
      "         131       0.26      0.25      0.25       136\n",
      "         132       0.41      0.26      0.31        43\n",
      "         133       0.38      0.31      0.34        54\n",
      "         134       0.62      0.52      0.57        63\n",
      "         135       0.28      0.21      0.24        57\n",
      "         136       0.65      0.54      0.59        96\n",
      "         137       0.67      0.75      0.71        60\n",
      "         138       0.62      0.84      0.71      1958\n",
      "         139       0.54      0.53      0.53        53\n",
      "         140       0.75      0.20      0.32        15\n",
      "         141       0.42      0.32      0.36        25\n",
      "         142       0.69      0.53      0.60        17\n",
      "         143       0.27      0.37      0.31       293\n",
      "         144       0.31      0.35      0.33        40\n",
      "         145       0.55      0.56      0.55        81\n",
      "         146       0.48      0.40      0.43        25\n",
      "         147       0.36      0.20      0.26        25\n",
      "         148       0.47      0.51      0.49       207\n",
      "         149       0.75      0.20      0.32        15\n",
      "         150       0.61      0.50      0.55        60\n",
      "         151       0.58      0.35      0.44        20\n",
      "         152       0.41      0.33      0.37        21\n",
      "         153       0.34      0.33      0.34        33\n",
      "         154       0.70      0.70      0.70       141\n",
      "         155       0.50      0.50      0.50       383\n",
      "         156       0.43      0.36      0.39        56\n",
      "         157       0.29      0.22      0.25        23\n",
      "         158       0.59      0.50      0.54        52\n",
      "         159       0.56      0.39      0.46        23\n",
      "         160       0.41      0.27      0.33        44\n",
      "         161       0.59      0.60      0.59       239\n",
      "         162       0.62      0.19      0.29        26\n",
      "         163       1.00      0.33      0.50        21\n",
      "         164       0.52      0.50      0.51       161\n",
      "         165       0.65      0.33      0.44        67\n",
      "         166       0.48      0.48      0.48        71\n",
      "         167       0.81      0.77      0.79        62\n",
      "         168       0.36      0.28      0.32        92\n",
      "         169       0.50      0.62      0.55        34\n",
      "         170       0.70      0.62      0.66        37\n",
      "         171       0.40      0.45      0.42       224\n",
      "         172       0.18      0.17      0.17        24\n",
      "         173       0.64      0.66      0.65       247\n",
      "         174       0.44      0.55      0.49       191\n",
      "         175       0.38      0.29      0.33        52\n",
      "         176       0.60      0.50      0.54       235\n",
      "         177       0.30      0.28      0.29        39\n",
      "         178       0.64      0.58      0.60       198\n",
      "         179       0.24      0.26      0.25        31\n",
      "         180       0.51      0.67      0.58      1085\n",
      "         181       0.51      0.38      0.44       182\n",
      "         182       0.35      0.25      0.29        28\n",
      "         183       0.53      0.53      0.53       356\n",
      "         184       0.72      0.68      0.70        19\n",
      "         185       0.44      0.24      0.31        34\n",
      "         186       0.47      0.40      0.43        40\n",
      "         187       0.50      0.20      0.29        25\n",
      "\n",
      "   micro avg       0.55      0.55      0.55     18442\n",
      "   macro avg       0.52      0.42      0.45     18442\n",
      "weighted avg       0.55      0.55      0.54     18442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg2.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conslusion\n",
    "\n",
    "Бачимо що вдалося покращити якість у порівнянні з бейзланойм більш ніж на 10% згідно F1. Логістична регресія в порівнянні з kNN у всіх випадках працювала краще. Вектори документів також дали покращення у всіх випадках."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Input, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "\n",
    "class FeedForwardNN(Model):\n",
    "    def __init__(self, train_vectors, train_labels, test_vectors, test_labels,\n",
    "                 input_size, hidden_size, epochs = 30):\n",
    "        super().__init__(train_vectors, \n",
    "                         to_categorical(train_labels), \n",
    "                         test_vectors, \n",
    "                         test_labels)        \n",
    "        self.epochs = epochs\n",
    "        self.model = Sequential()\n",
    "        self.model.add(Dense(hidden_size, activation='relu', input_shape=(input_size,)))        \n",
    "        self.model.add(Dense(188, activation='softmax'))\n",
    "        self.model.summary()\n",
    "        self.model.compile(optimizer=RMSprop(lr=1e-4),\n",
    "                           loss='categorical_crossentropy',\n",
    "                           metrics=['acc'])\n",
    "    \n",
    "    def train(self):\n",
    "        self.model.fit(self.train_vectors, self.train_labels, \n",
    "                       epochs = self.epochs, batch_size=128, \n",
    "                       verbose=0, callbacks=[TQDMNotebookCallback()])\n",
    "        self.topics_predicted = np.argmax(self.model.predict(self.test_vectors), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 1024)              308224    \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 188)               192700    \n",
      "=================================================================\n",
      "Total params: 500,924\n",
      "Trainable params: 500,924\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ff_model = FeedForwardNN(train_doc_vecs, train_topic_labels, test_doc_vecs, test_topic_labels, 300, 1024, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc956cb8d2a4495399fbf856433c60cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training', max=40, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 0', max=43031, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 1', max=43031, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 2', max=43031, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 3', max=43031, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 4', max=43031, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 5', max=43031, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 6', max=43031, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 7', max=43031, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 8', max=43031, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 9', max=43031, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 10', max=43031, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 11', max=43031, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 12', max=43031, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 13', max=43031, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 14', max=43031, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 15', max=43031, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 16', max=43031, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 17', max=43031, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 18', max=43031, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 19', max=43031, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 20', max=43031, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 21', max=43031, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 22', max=43031, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 23', max=43031, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 24', max=43031, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 25', max=43031, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 26', max=43031, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 27', max=43031, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 28', max=43031, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 29', max=43031, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 30', max=43031, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 31', max=43031, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 32', max=43031, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 33', max=43031, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 34', max=43031, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 35', max=43031, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 36', max=43031, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 37', max=43031, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 38', max=43031, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 39', max=43031, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ff_model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.46      0.51       330\n",
      "           1       0.82      0.35      0.49        40\n",
      "           2       0.52      0.54      0.53        78\n",
      "           3       0.54      0.38      0.45        39\n",
      "           4       1.00      0.23      0.37        22\n",
      "           5       0.50      0.69      0.58       106\n",
      "           6       0.34      0.33      0.33       141\n",
      "           7       0.75      0.48      0.59        62\n",
      "           8       0.73      0.73      0.73        30\n",
      "           9       0.79      0.50      0.61        22\n",
      "          10       0.81      0.81      0.81       145\n",
      "          11       0.50      0.14      0.22        29\n",
      "          12       1.00      0.29      0.44        21\n",
      "          13       0.60      0.20      0.31        44\n",
      "          14       0.37      0.26      0.31        84\n",
      "          15       0.83      0.31      0.45        16\n",
      "          16       0.57      0.61      0.59       120\n",
      "          17       0.60      0.20      0.30        15\n",
      "          18       0.35      0.21      0.26        53\n",
      "          19       0.67      0.10      0.17        20\n",
      "          20       0.40      0.12      0.19        16\n",
      "          21       0.69      0.36      0.47        25\n",
      "          22       0.58      0.51      0.54       192\n",
      "          23       0.92      0.71      0.80        51\n",
      "          24       0.53      0.35      0.42        46\n",
      "          25       0.67      0.43      0.52        28\n",
      "          26       0.67      0.24      0.35        25\n",
      "          27       0.62      0.69      0.66       938\n",
      "          28       0.74      0.52      0.61        56\n",
      "          29       0.40      0.27      0.32        63\n",
      "          30       0.50      0.26      0.34        43\n",
      "          31       0.50      0.08      0.14        25\n",
      "          32       0.90      0.60      0.72        95\n",
      "          33       0.82      0.56      0.67       128\n",
      "          34       0.59      0.43      0.50        44\n",
      "          35       0.50      0.26      0.34        35\n",
      "          36       0.29      0.12      0.17        49\n",
      "          37       0.58      0.18      0.27        39\n",
      "          38       0.89      0.63      0.74        38\n",
      "          39       0.47      0.37      0.42        43\n",
      "          40       0.72      0.66      0.69       115\n",
      "          41       0.53      0.48      0.51       143\n",
      "          42       0.67      0.63      0.65        62\n",
      "          43       0.66      0.53      0.58        40\n",
      "          44       0.44      0.23      0.30        30\n",
      "          45       0.67      0.39      0.50        71\n",
      "          46       0.78      0.64      0.70        55\n",
      "          47       0.59      0.48      0.53        21\n",
      "          48       0.14      0.06      0.09        16\n",
      "          49       0.67      0.33      0.44        18\n",
      "          50       0.85      0.39      0.53        44\n",
      "          51       0.67      0.50      0.57        20\n",
      "          52       0.43      0.12      0.18        26\n",
      "          53       0.69      0.52      0.59        52\n",
      "          54       0.40      0.11      0.17        18\n",
      "          55       0.00      0.00      0.00        26\n",
      "          56       1.00      0.52      0.68        27\n",
      "          57       0.74      0.51      0.60       106\n",
      "          58       0.70      0.74      0.72       365\n",
      "          59       0.51      0.47      0.49        74\n",
      "          60       0.70      0.20      0.31        35\n",
      "          61       0.40      0.08      0.14        24\n",
      "          62       0.49      0.37      0.42        95\n",
      "          63       0.50      0.24      0.32        17\n",
      "          64       0.75      0.65      0.70        37\n",
      "          65       0.00      0.00      0.00        14\n",
      "          66       0.71      0.36      0.48        33\n",
      "          67       0.58      0.66      0.62       601\n",
      "          68       0.65      0.58      0.62       190\n",
      "          69       0.33      0.34      0.33       104\n",
      "          70       0.92      0.31      0.47        35\n",
      "          71       0.84      0.33      0.48        48\n",
      "          72       0.33      0.19      0.24        21\n",
      "          73       0.79      0.58      0.67        33\n",
      "          74       0.91      0.84      0.87        85\n",
      "          75       0.81      0.70      0.75        30\n",
      "          76       0.86      0.49      0.62        49\n",
      "          77       0.74      0.53      0.62        43\n",
      "          78       0.69      0.41      0.51       103\n",
      "          79       0.43      0.44      0.44       388\n",
      "          80       0.70      0.39      0.50        18\n",
      "          81       0.90      0.64      0.75        28\n",
      "          82       0.75      0.15      0.25        20\n",
      "          83       0.00      0.00      0.00        23\n",
      "          84       0.77      0.19      0.31        52\n",
      "          85       0.64      0.32      0.42        22\n",
      "          86       0.52      0.47      0.50        74\n",
      "          87       0.44      0.23      0.30        35\n",
      "          88       0.55      0.52      0.53       296\n",
      "          89       0.81      0.42      0.56        40\n",
      "          90       0.67      0.12      0.21        16\n",
      "          91       0.44      0.29      0.35        38\n",
      "          92       0.64      0.27      0.38        26\n",
      "          93       1.00      0.64      0.78        22\n",
      "          94       0.20      0.11      0.14        19\n",
      "          95       0.40      0.40      0.40        42\n",
      "          96       0.78      0.35      0.48        20\n",
      "          97       0.79      0.62      0.70        24\n",
      "          98       0.60      0.26      0.36        23\n",
      "          99       0.62      0.44      0.52        34\n",
      "         100       0.41      0.20      0.27        54\n",
      "         101       0.49      0.58      0.53       328\n",
      "         102       0.95      0.73      0.82        74\n",
      "         103       0.67      0.42      0.52        19\n",
      "         104       1.00      0.51      0.68        37\n",
      "         105       0.35      0.34      0.35        87\n",
      "         106       0.33      0.13      0.19        46\n",
      "         107       0.38      0.10      0.15        31\n",
      "         108       0.67      0.10      0.17        21\n",
      "         109       0.51      0.45      0.48       154\n",
      "         110       0.52      0.21      0.30        66\n",
      "         111       0.73      0.40      0.52        20\n",
      "         112       0.86      0.56      0.68        78\n",
      "         113       0.68      0.38      0.48        56\n",
      "         114       0.53      0.51      0.52       138\n",
      "         115       0.38      0.18      0.24        17\n",
      "         116       0.59      0.60      0.59       131\n",
      "         117       0.40      0.23      0.29        78\n",
      "         118       0.82      0.24      0.37        38\n",
      "         119       0.70      0.40      0.51        47\n",
      "         120       0.50      0.27      0.35        15\n",
      "         121       0.55      0.61      0.58       378\n",
      "         122       0.89      0.42      0.57        38\n",
      "         123       0.52      0.35      0.42        78\n",
      "         124       0.50      0.12      0.19        25\n",
      "         125       0.34      0.14      0.20        73\n",
      "         126       0.80      0.20      0.32        20\n",
      "         127       0.59      0.73      0.65       658\n",
      "         128       0.36      0.20      0.26        79\n",
      "         129       0.50      0.30      0.37        20\n",
      "         130       0.25      0.06      0.10        17\n",
      "         131       0.36      0.27      0.31       136\n",
      "         132       0.38      0.23      0.29        43\n",
      "         133       0.55      0.30      0.39        54\n",
      "         134       0.58      0.57      0.58        63\n",
      "         135       0.71      0.21      0.32        57\n",
      "         136       0.72      0.55      0.62        96\n",
      "         137       0.70      0.78      0.74        60\n",
      "         138       0.51      0.89      0.65      1958\n",
      "         139       0.67      0.57      0.61        53\n",
      "         140       1.00      0.20      0.33        15\n",
      "         141       0.53      0.36      0.43        25\n",
      "         142       0.73      0.47      0.57        17\n",
      "         143       0.28      0.41      0.33       293\n",
      "         144       0.33      0.33      0.33        40\n",
      "         145       0.75      0.56      0.64        81\n",
      "         146       1.00      0.36      0.53        25\n",
      "         147       0.50      0.12      0.19        25\n",
      "         148       0.47      0.49      0.48       207\n",
      "         149       0.50      0.07      0.12        15\n",
      "         150       0.65      0.28      0.40        60\n",
      "         151       0.75      0.30      0.43        20\n",
      "         152       0.62      0.24      0.34        21\n",
      "         153       0.40      0.30      0.34        33\n",
      "         154       0.81      0.63      0.71       141\n",
      "         155       0.46      0.54      0.50       383\n",
      "         156       0.63      0.34      0.44        56\n",
      "         157       0.67      0.17      0.28        23\n",
      "         158       0.60      0.48      0.53        52\n",
      "         159       1.00      0.39      0.56        23\n",
      "         160       0.57      0.27      0.37        44\n",
      "         161       0.58      0.66      0.62       239\n",
      "         162       1.00      0.12      0.21        26\n",
      "         163       0.73      0.38      0.50        21\n",
      "         164       0.52      0.52      0.52       161\n",
      "         165       0.68      0.37      0.48        67\n",
      "         166       0.52      0.51      0.51        71\n",
      "         167       0.88      0.69      0.77        62\n",
      "         168       0.61      0.29      0.40        92\n",
      "         169       0.66      0.62      0.64        34\n",
      "         170       0.79      0.51      0.62        37\n",
      "         171       0.37      0.50      0.42       224\n",
      "         172       0.44      0.17      0.24        24\n",
      "         173       0.73      0.60      0.66       247\n",
      "         174       0.54      0.50      0.52       191\n",
      "         175       0.45      0.25      0.32        52\n",
      "         176       0.60      0.42      0.50       235\n",
      "         177       0.62      0.38      0.48        39\n",
      "         178       0.70      0.58      0.63       198\n",
      "         179       0.59      0.32      0.42        31\n",
      "         180       0.48      0.71      0.57      1085\n",
      "         181       0.53      0.42      0.47       182\n",
      "         182       0.82      0.32      0.46        28\n",
      "         183       0.51      0.63      0.56       356\n",
      "         184       0.92      0.58      0.71        19\n",
      "         185       0.50      0.18      0.26        34\n",
      "         186       0.71      0.42      0.53        40\n",
      "         187       0.56      0.20      0.29        25\n",
      "\n",
      "   micro avg       0.55      0.55      0.55     18442\n",
      "   macro avg       0.61      0.39      0.45     18442\n",
      "weighted avg       0.57      0.55      0.54     18442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ff_model.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_17 (Dense)             (None, 1024)              308224    \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 188)               192700    \n",
      "=================================================================\n",
      "Total params: 500,924\n",
      "Trainable params: 500,924\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ff_sum_model = FeedForwardNN(train_doc_sum_vecs, train_topic_labels, \n",
    "                             test_doc_sum_vecs, test_topic_labels, 300, 1024, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f63588d50e9d407d85123ba066c524bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training', max=40, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 0', max=43031, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 1', max=43031, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 2', max=43031, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 3', max=43031, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 4', max=43031, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 5', max=43031, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 6', max=43031, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 7', max=43031, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 8', max=43031, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 9', max=43031, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 10', max=43031, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 11', max=43031, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 12', max=43031, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 13', max=43031, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 14', max=43031, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 15', max=43031, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 16', max=43031, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 17', max=43031, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 18', max=43031, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 19', max=43031, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 20', max=43031, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 21', max=43031, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 22', max=43031, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 23', max=43031, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 24', max=43031, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 25', max=43031, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 26', max=43031, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 27', max=43031, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 28', max=43031, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 29', max=43031, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 30', max=43031, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 31', max=43031, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 32', max=43031, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 33', max=43031, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 34', max=43031, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 35', max=43031, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 36', max=43031, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 37', max=43031, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 38', max=43031, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 39', max=43031, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ff_sum_model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.66      0.62       330\n",
      "           1       0.93      0.65      0.76        40\n",
      "           2       0.67      0.56      0.61        78\n",
      "           3       0.46      0.28      0.35        39\n",
      "           4       0.62      0.23      0.33        22\n",
      "           5       0.51      0.46      0.49       106\n",
      "           6       0.38      0.23      0.29       141\n",
      "           7       0.54      0.50      0.52        62\n",
      "           8       0.82      0.77      0.79        30\n",
      "           9       0.29      0.23      0.26        22\n",
      "          10       0.75      0.70      0.72       145\n",
      "          11       0.28      0.28      0.28        29\n",
      "          12       0.91      0.48      0.62        21\n",
      "          13       0.28      0.30      0.29        44\n",
      "          14       0.34      0.19      0.24        84\n",
      "          15       0.38      0.19      0.25        16\n",
      "          16       0.67      0.58      0.62       120\n",
      "          17       0.40      0.27      0.32        15\n",
      "          18       0.31      0.19      0.24        53\n",
      "          19       0.50      0.30      0.37        20\n",
      "          20       0.00      0.00      0.00        16\n",
      "          21       0.58      0.28      0.38        25\n",
      "          22       0.53      0.58      0.55       192\n",
      "          23       0.80      0.76      0.78        51\n",
      "          24       0.53      0.59      0.56        46\n",
      "          25       0.43      0.21      0.29        28\n",
      "          26       0.50      0.40      0.44        25\n",
      "          27       0.71      0.74      0.72       938\n",
      "          28       0.51      0.41      0.46        56\n",
      "          29       0.44      0.43      0.43        63\n",
      "          30       0.30      0.21      0.25        43\n",
      "          31       0.27      0.12      0.17        25\n",
      "          32       0.76      0.64      0.70        95\n",
      "          33       0.64      0.71      0.67       128\n",
      "          34       0.55      0.48      0.51        44\n",
      "          35       0.28      0.37      0.32        35\n",
      "          36       0.34      0.20      0.26        49\n",
      "          37       0.16      0.13      0.14        39\n",
      "          38       0.93      0.68      0.79        38\n",
      "          39       0.39      0.37      0.38        43\n",
      "          40       0.70      0.70      0.70       115\n",
      "          41       0.48      0.57      0.52       143\n",
      "          42       0.57      0.48      0.52        62\n",
      "          43       0.68      0.38      0.48        40\n",
      "          44       0.31      0.13      0.19        30\n",
      "          45       0.60      0.45      0.52        71\n",
      "          46       0.75      0.65      0.70        55\n",
      "          47       0.33      0.14      0.20        21\n",
      "          48       0.14      0.06      0.09        16\n",
      "          49       0.00      0.00      0.00        18\n",
      "          50       0.57      0.36      0.44        44\n",
      "          51       0.67      0.40      0.50        20\n",
      "          52       0.28      0.19      0.23        26\n",
      "          53       0.61      0.52      0.56        52\n",
      "          54       0.25      0.11      0.15        18\n",
      "          55       0.00      0.00      0.00        26\n",
      "          56       0.65      0.48      0.55        27\n",
      "          57       0.57      0.62      0.59       106\n",
      "          58       0.68      0.68      0.68       365\n",
      "          59       0.32      0.28      0.30        74\n",
      "          60       0.00      0.00      0.00        35\n",
      "          61       0.12      0.04      0.06        24\n",
      "          62       0.36      0.35      0.35        95\n",
      "          63       0.36      0.24      0.29        17\n",
      "          64       0.76      0.68      0.71        37\n",
      "          65       0.50      0.21      0.30        14\n",
      "          66       0.00      0.00      0.00        33\n",
      "          67       0.62      0.64      0.63       601\n",
      "          68       0.64      0.66      0.65       190\n",
      "          69       0.29      0.46      0.36       104\n",
      "          70       0.68      0.54      0.60        35\n",
      "          71       0.40      0.21      0.27        48\n",
      "          72       0.40      0.10      0.15        21\n",
      "          73       0.46      0.48      0.47        33\n",
      "          74       0.88      0.79      0.83        85\n",
      "          75       0.71      0.67      0.69        30\n",
      "          76       0.66      0.55      0.60        49\n",
      "          77       0.34      0.26      0.29        43\n",
      "          78       0.59      0.55      0.57       103\n",
      "          79       0.49      0.46      0.47       388\n",
      "          80       0.62      0.28      0.38        18\n",
      "          81       0.85      0.61      0.71        28\n",
      "          82       0.00      0.00      0.00        20\n",
      "          83       0.50      0.09      0.15        23\n",
      "          84       0.38      0.35      0.36        52\n",
      "          85       0.47      0.32      0.38        22\n",
      "          86       0.43      0.31      0.36        74\n",
      "          87       0.60      0.09      0.15        35\n",
      "          88       0.53      0.51      0.52       296\n",
      "          89       0.72      0.57      0.64        40\n",
      "          90       0.00      0.00      0.00        16\n",
      "          91       0.43      0.24      0.31        38\n",
      "          92       0.43      0.38      0.41        26\n",
      "          93       0.95      0.82      0.88        22\n",
      "          94       0.18      0.11      0.13        19\n",
      "          95       0.53      0.38      0.44        42\n",
      "          96       0.80      0.40      0.53        20\n",
      "          97       0.45      0.58      0.51        24\n",
      "          98       0.48      0.43      0.45        23\n",
      "          99       0.48      0.32      0.39        34\n",
      "         100       0.40      0.22      0.29        54\n",
      "         101       0.51      0.58      0.54       328\n",
      "         102       0.66      0.66      0.66        74\n",
      "         103       0.43      0.32      0.36        19\n",
      "         104       0.73      0.65      0.69        37\n",
      "         105       0.29      0.36      0.32        87\n",
      "         106       0.27      0.26      0.27        46\n",
      "         107       0.00      0.00      0.00        31\n",
      "         108       0.56      0.24      0.33        21\n",
      "         109       0.47      0.42      0.44       154\n",
      "         110       0.41      0.36      0.38        66\n",
      "         111       1.00      0.05      0.10        20\n",
      "         112       0.53      0.40      0.45        78\n",
      "         113       0.50      0.38      0.43        56\n",
      "         114       0.47      0.59      0.52       138\n",
      "         115       0.17      0.12      0.14        17\n",
      "         116       0.68      0.59      0.63       131\n",
      "         117       0.17      0.18      0.17        78\n",
      "         118       0.32      0.18      0.23        38\n",
      "         119       0.63      0.47      0.54        47\n",
      "         120       0.56      0.33      0.42        15\n",
      "         121       0.52      0.72      0.60       378\n",
      "         122       0.64      0.66      0.65        38\n",
      "         123       0.51      0.42      0.46        78\n",
      "         124       0.38      0.20      0.26        25\n",
      "         125       0.34      0.30      0.32        73\n",
      "         126       0.00      0.00      0.00        20\n",
      "         127       0.67      0.56      0.61       658\n",
      "         128       0.24      0.24      0.24        79\n",
      "         129       0.53      0.45      0.49        20\n",
      "         130       0.00      0.00      0.00        17\n",
      "         131       0.27      0.31      0.29       136\n",
      "         132       0.20      0.14      0.16        43\n",
      "         133       0.33      0.26      0.29        54\n",
      "         134       0.57      0.44      0.50        63\n",
      "         135       0.26      0.26      0.26        57\n",
      "         136       0.57      0.59      0.58        96\n",
      "         137       0.42      0.48      0.45        60\n",
      "         138       0.63      0.85      0.72      1958\n",
      "         139       0.59      0.42      0.49        53\n",
      "         140       0.56      0.33      0.42        15\n",
      "         141       0.29      0.20      0.24        25\n",
      "         142       0.44      0.24      0.31        17\n",
      "         143       0.26      0.39      0.31       293\n",
      "         144       0.23      0.25      0.24        40\n",
      "         145       0.54      0.44      0.49        81\n",
      "         146       0.57      0.32      0.41        25\n",
      "         147       0.24      0.28      0.26        25\n",
      "         148       0.48      0.44      0.46       207\n",
      "         149       0.56      0.33      0.42        15\n",
      "         150       0.44      0.40      0.42        60\n",
      "         151       0.27      0.30      0.29        20\n",
      "         152       0.56      0.24      0.33        21\n",
      "         153       0.31      0.24      0.27        33\n",
      "         154       0.68      0.65      0.66       141\n",
      "         155       0.46      0.56      0.50       383\n",
      "         156       0.37      0.27      0.31        56\n",
      "         157       0.78      0.30      0.44        23\n",
      "         158       0.44      0.40      0.42        52\n",
      "         159       0.77      0.43      0.56        23\n",
      "         160       0.23      0.18      0.20        44\n",
      "         161       0.52      0.66      0.58       239\n",
      "         162       0.47      0.31      0.37        26\n",
      "         163       0.75      0.14      0.24        21\n",
      "         164       0.41      0.49      0.45       161\n",
      "         165       0.54      0.51      0.52        67\n",
      "         166       0.32      0.35      0.34        71\n",
      "         167       0.77      0.77      0.77        62\n",
      "         168       0.39      0.29      0.34        92\n",
      "         169       0.67      0.71      0.69        34\n",
      "         170       0.47      0.54      0.50        37\n",
      "         171       0.52      0.38      0.44       224\n",
      "         172       0.31      0.17      0.22        24\n",
      "         173       0.69      0.74      0.71       247\n",
      "         174       0.59      0.56      0.58       191\n",
      "         175       0.35      0.33      0.34        52\n",
      "         176       0.62      0.60      0.61       235\n",
      "         177       0.37      0.28      0.32        39\n",
      "         178       0.63      0.61      0.62       198\n",
      "         179       0.32      0.23      0.26        31\n",
      "         180       0.56      0.66      0.60      1085\n",
      "         181       0.44      0.42      0.43       182\n",
      "         182       0.62      0.18      0.28        28\n",
      "         183       0.54      0.57      0.56       356\n",
      "         184       0.69      0.58      0.63        19\n",
      "         185       0.26      0.29      0.28        34\n",
      "         186       0.56      0.25      0.34        40\n",
      "         187       0.39      0.36      0.37        25\n",
      "\n",
      "   micro avg       0.55      0.55      0.55     18442\n",
      "   macro avg       0.47      0.38      0.41     18442\n",
      "weighted avg       0.54      0.55      0.54     18442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ff_sum_model.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_vecs(x_vecs, y_vecs):\n",
    "    return np.array([np.append(x,y) for x,y in zip(x_vecs, y_vecs)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_29 (Dense)             (None, 2048)              1230848   \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 188)               385212    \n",
      "=================================================================\n",
      "Total params: 1,616,060\n",
      "Trainable params: 1,616,060\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ff_combined_model = FeedForwardNN(combine_vecs(train_doc_sum_vecs, train_doc_vecs), \n",
    "                                  train_topic_labels, \n",
    "                                  combine_vecs(test_doc_sum_vecs, test_doc_vecs), test_topic_labels, 600, 2048, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec47669188c3481db1e05a94b39696b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training', max=40, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 0', max=43031, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 1', max=43031, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 2', max=43031, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 3', max=43031, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 4', max=43031, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 5', max=43031, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 6', max=43031, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 7', max=43031, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 8', max=43031, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 9', max=43031, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 10', max=43031, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 11', max=43031, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 12', max=43031, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 13', max=43031, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 14', max=43031, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 15', max=43031, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 16', max=43031, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 17', max=43031, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 18', max=43031, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 19', max=43031, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 20', max=43031, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 21', max=43031, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 22', max=43031, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 23', max=43031, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 24', max=43031, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 25', max=43031, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 26', max=43031, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 27', max=43031, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 28', max=43031, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 29', max=43031, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 30', max=43031, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 31', max=43031, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 32', max=43031, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 33', max=43031, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 34', max=43031, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 35', max=43031, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 36', max=43031, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 37', max=43031, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 38', max=43031, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 39', max=43031, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ff_combined_model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.50      0.56       330\n",
      "           1       0.93      0.65      0.76        40\n",
      "           2       0.71      0.59      0.64        78\n",
      "           3       0.47      0.36      0.41        39\n",
      "           4       1.00      0.32      0.48        22\n",
      "           5       0.45      0.61      0.52       106\n",
      "           6       0.32      0.34      0.33       141\n",
      "           7       0.55      0.76      0.64        62\n",
      "           8       0.83      0.83      0.83        30\n",
      "           9       0.50      0.27      0.35        22\n",
      "          10       0.87      0.72      0.79       145\n",
      "          11       0.33      0.24      0.28        29\n",
      "          12       0.92      0.57      0.71        21\n",
      "          13       0.38      0.18      0.25        44\n",
      "          14       0.39      0.19      0.26        84\n",
      "          15       0.57      0.25      0.35        16\n",
      "          16       0.55      0.64      0.59       120\n",
      "          17       0.27      0.27      0.27        15\n",
      "          18       0.39      0.23      0.29        53\n",
      "          19       0.50      0.30      0.37        20\n",
      "          20       0.08      0.06      0.07        16\n",
      "          21       0.59      0.40      0.48        25\n",
      "          22       0.47      0.67      0.55       192\n",
      "          23       0.90      0.75      0.82        51\n",
      "          24       0.56      0.50      0.53        46\n",
      "          25       0.44      0.29      0.35        28\n",
      "          26       0.48      0.52      0.50        25\n",
      "          27       0.73      0.72      0.73       938\n",
      "          28       0.78      0.45      0.57        56\n",
      "          29       0.36      0.40      0.38        63\n",
      "          30       0.34      0.28      0.31        43\n",
      "          31       0.33      0.12      0.18        25\n",
      "          32       0.86      0.68      0.76        95\n",
      "          33       0.81      0.62      0.70       128\n",
      "          34       0.46      0.59      0.52        44\n",
      "          35       0.31      0.34      0.32        35\n",
      "          36       0.24      0.14      0.18        49\n",
      "          37       0.21      0.15      0.18        39\n",
      "          38       0.87      0.71      0.78        38\n",
      "          39       0.54      0.44      0.49        43\n",
      "          40       0.75      0.70      0.72       115\n",
      "          41       0.58      0.52      0.55       143\n",
      "          42       0.58      0.61      0.60        62\n",
      "          43       0.54      0.50      0.52        40\n",
      "          44       0.42      0.27      0.33        30\n",
      "          45       0.50      0.55      0.52        71\n",
      "          46       0.86      0.65      0.74        55\n",
      "          47       0.53      0.38      0.44        21\n",
      "          48       0.25      0.06      0.10        16\n",
      "          49       0.57      0.44      0.50        18\n",
      "          50       0.57      0.45      0.51        44\n",
      "          51       0.44      0.40      0.42        20\n",
      "          52       0.00      0.00      0.00        26\n",
      "          53       0.64      0.58      0.61        52\n",
      "          54       0.27      0.17      0.21        18\n",
      "          55       0.19      0.23      0.21        26\n",
      "          56       0.69      0.41      0.51        27\n",
      "          57       0.59      0.65      0.62       106\n",
      "          58       0.76      0.67      0.72       365\n",
      "          59       0.44      0.49      0.46        74\n",
      "          60       0.36      0.46      0.40        35\n",
      "          61       0.18      0.12      0.15        24\n",
      "          62       0.49      0.48      0.49        95\n",
      "          63       0.60      0.18      0.27        17\n",
      "          64       0.90      0.70      0.79        37\n",
      "          65       0.50      0.21      0.30        14\n",
      "          66       0.45      0.55      0.49        33\n",
      "          67       0.64      0.67      0.65       601\n",
      "          68       0.65      0.69      0.67       190\n",
      "          69       0.46      0.23      0.31       104\n",
      "          70       0.68      0.54      0.60        35\n",
      "          71       0.44      0.23      0.30        48\n",
      "          72       0.00      0.00      0.00        21\n",
      "          73       0.56      0.55      0.55        33\n",
      "          74       0.80      0.86      0.83        85\n",
      "          75       0.86      0.80      0.83        30\n",
      "          76       0.62      0.53      0.57        49\n",
      "          77       0.58      0.26      0.35        43\n",
      "          78       0.61      0.60      0.61       103\n",
      "          79       0.47      0.55      0.50       388\n",
      "          80       0.75      0.33      0.46        18\n",
      "          81       0.91      0.75      0.82        28\n",
      "          82       0.31      0.25      0.28        20\n",
      "          83       0.33      0.09      0.14        23\n",
      "          84       0.45      0.37      0.40        52\n",
      "          85       0.47      0.32      0.38        22\n",
      "          86       0.65      0.38      0.48        74\n",
      "          87       0.32      0.26      0.29        35\n",
      "          88       0.55      0.58      0.57       296\n",
      "          89       0.73      0.60      0.66        40\n",
      "          90       0.00      0.00      0.00        16\n",
      "          91       0.33      0.34      0.34        38\n",
      "          92       0.39      0.27      0.32        26\n",
      "          93       0.83      0.68      0.75        22\n",
      "          94       0.22      0.11      0.14        19\n",
      "          95       0.58      0.45      0.51        42\n",
      "          96       0.55      0.60      0.57        20\n",
      "          97       0.47      0.67      0.55        24\n",
      "          98       0.46      0.48      0.47        23\n",
      "          99       0.36      0.47      0.41        34\n",
      "         100       0.47      0.28      0.35        54\n",
      "         101       0.53      0.59      0.56       328\n",
      "         102       0.77      0.72      0.74        74\n",
      "         103       0.75      0.47      0.58        19\n",
      "         104       0.84      0.73      0.78        37\n",
      "         105       0.32      0.34      0.33        87\n",
      "         106       0.27      0.20      0.23        46\n",
      "         107       0.38      0.42      0.40        31\n",
      "         108       0.75      0.29      0.41        21\n",
      "         109       0.47      0.48      0.47       154\n",
      "         110       0.48      0.38      0.42        66\n",
      "         111       1.00      0.05      0.10        20\n",
      "         112       0.75      0.50      0.60        78\n",
      "         113       0.62      0.38      0.47        56\n",
      "         114       0.54      0.50      0.52       138\n",
      "         115       0.22      0.12      0.15        17\n",
      "         116       0.69      0.61      0.65       131\n",
      "         117       0.31      0.15      0.21        78\n",
      "         118       0.25      0.26      0.26        38\n",
      "         119       0.51      0.47      0.49        47\n",
      "         120       0.43      0.20      0.27        15\n",
      "         121       0.58      0.66      0.62       378\n",
      "         122       0.60      0.55      0.58        38\n",
      "         123       0.68      0.41      0.51        78\n",
      "         124       0.38      0.32      0.35        25\n",
      "         125       0.34      0.21      0.26        73\n",
      "         126       0.87      0.65      0.74        20\n",
      "         127       0.57      0.77      0.66       658\n",
      "         128       0.22      0.30      0.25        79\n",
      "         129       0.73      0.40      0.52        20\n",
      "         130       0.14      0.06      0.08        17\n",
      "         131       0.29      0.29      0.29       136\n",
      "         132       0.26      0.21      0.23        43\n",
      "         133       0.35      0.24      0.29        54\n",
      "         134       0.68      0.40      0.50        63\n",
      "         135       0.26      0.26      0.26        57\n",
      "         136       0.53      0.65      0.58        96\n",
      "         137       0.63      0.55      0.59        60\n",
      "         138       0.63      0.88      0.73      1958\n",
      "         139       0.50      0.45      0.48        53\n",
      "         140       0.75      0.20      0.32        15\n",
      "         141       0.25      0.32      0.28        25\n",
      "         142       0.64      0.41      0.50        17\n",
      "         143       0.27      0.37      0.31       293\n",
      "         144       0.23      0.25      0.24        40\n",
      "         145       0.55      0.59      0.57        81\n",
      "         146       0.53      0.32      0.40        25\n",
      "         147       0.33      0.12      0.18        25\n",
      "         148       0.49      0.55      0.52       207\n",
      "         149       0.00      0.00      0.00        15\n",
      "         150       0.59      0.43      0.50        60\n",
      "         151       0.44      0.40      0.42        20\n",
      "         152       0.67      0.29      0.40        21\n",
      "         153       0.31      0.30      0.31        33\n",
      "         154       0.61      0.74      0.67       141\n",
      "         155       0.54      0.55      0.54       383\n",
      "         156       0.42      0.36      0.38        56\n",
      "         157       0.78      0.30      0.44        23\n",
      "         158       0.40      0.50      0.44        52\n",
      "         159       0.59      0.43      0.50        23\n",
      "         160       0.36      0.20      0.26        44\n",
      "         161       0.63      0.61      0.62       239\n",
      "         162       0.35      0.35      0.35        26\n",
      "         163       0.80      0.38      0.52        21\n",
      "         164       0.53      0.43      0.48       161\n",
      "         165       0.69      0.36      0.47        67\n",
      "         166       0.48      0.34      0.40        71\n",
      "         167       0.74      0.73      0.73        62\n",
      "         168       0.60      0.34      0.43        92\n",
      "         169       0.65      0.59      0.62        34\n",
      "         170       0.67      0.54      0.60        37\n",
      "         171       0.52      0.46      0.49       224\n",
      "         172       0.25      0.17      0.20        24\n",
      "         173       0.76      0.72      0.74       247\n",
      "         174       0.63      0.59      0.61       191\n",
      "         175       0.65      0.25      0.36        52\n",
      "         176       0.69      0.50      0.58       235\n",
      "         177       0.32      0.31      0.32        39\n",
      "         178       0.64      0.73      0.68       198\n",
      "         179       0.43      0.29      0.35        31\n",
      "         180       0.61      0.65      0.63      1085\n",
      "         181       0.48      0.38      0.43       182\n",
      "         182       0.46      0.39      0.42        28\n",
      "         183       0.56      0.60      0.58       356\n",
      "         184       0.74      0.74      0.74        19\n",
      "         185       0.27      0.29      0.28        34\n",
      "         186       0.68      0.33      0.44        40\n",
      "         187       0.53      0.32      0.40        25\n",
      "\n",
      "   micro avg       0.57      0.57      0.57     18442\n",
      "   macro avg       0.52      0.43      0.46     18442\n",
      "weighted avg       0.57      0.57      0.56     18442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ff_combined_model.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa4041c5917042eeb08aaa724a302d5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=43026), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_docs_tokenized = [tokenize_uk.tokenize_words(doc.content) for doc in tqdm_notebook(train_documents)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98ea594fe2fb472a8fc8696459bbc44b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=18440), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_docs_tokenized = [tokenize_uk.tokenize_words(doc.content) for doc in tqdm_notebook(test_documents)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "\n",
    "vocab = Dictionary([doc.words for doc in (train_tagged_docs + test_tagged_docs)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_sequence(text):\n",
    "    return [vocab.token2id[word] + 1 for word in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43026"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sequences = [text_to_sequence(doc.words) for doc in train_tagged_docs]\n",
    "\n",
    "len(train_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18440"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sequences = [text_to_sequence(doc.words) for doc in test_tagged_docs]\n",
    "\n",
    "len(test_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = train_sequences + test_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average length: 30.3\n",
      "max length: 211\n"
     ]
    }
   ],
   "source": [
    "seq_lens = [len(s) for s in sequences]\n",
    "print(\"average length: %0.1f\" % np.mean(seq_lens))\n",
    "print(\"max length: %d\" % max(seq_lens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(seq_lens, bins=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (43026, 211)\n",
      "Shape of data test tensor: (18440, 211)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 211\n",
    "\n",
    "# pad sequences with 0s\n",
    "x_train = pad_sequences(train_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "x_test = pad_sequences(test_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "print('Shape of data tensor:', x_train.shape)\n",
    "print('Shape of data test tensor:', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of label tensor: (43026, 188)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "y_train = to_categorical(np.asarray(train_topic_labels))\n",
    "print('Shape of label tensor:', y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111898"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "\n",
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique(train_topic_labels),\n",
    "                                                 train_topic_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw = {}\n",
    "for i, w in enumerate(class_weights):\n",
    "    cw[i] = w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "будинку 0\n"
     ]
    }
   ],
   "source": [
    "for w,i in vocab.token2id.items(): \n",
    "    print(w,i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e87e5e8698634b98855fd28543544242",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=111897), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "added 62930 words in the embedding matrix\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_DIM = 300\n",
    "MAX_NB_WORDS = len(vocab) + 1\n",
    "\n",
    "# prepare embedding matrix\n",
    "nb_words_in_matrix = 0\n",
    "nb_words = MAX_NB_WORDS #min(MAX_NB_WORDS, len(word_index))\n",
    "embedding_matrix = np.zeros((nb_words, EMBEDDING_DIM))\n",
    "for word, i in tqdm_notebook(vocab.token2id.items()):\n",
    "    #if i >= MAX_NB_WORDS:\n",
    "    #    continue\n",
    "    embedding_vector = None\n",
    "    try:\n",
    "        embedding_vector = wv[word]\n",
    "    except KeyError as e:\n",
    "        pass\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        nb_words_in_matrix = nb_words_in_matrix + 1\n",
    "        \n",
    "print(\"added %d words in the embedding matrix\" % nb_words_in_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, LSTM, GlobalMaxPooling1D, AveragePooling1D,MaxPooling1D, GlobalMaxPooling1D, Embedding, Dense, Input, Dropout\n",
    "from keras.models import Model\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "EMBEDDING_DIM = 50\n",
    "MAX_NB_WORDS = len(vocab) + 1\n",
    "N_CLASSES = 188\n",
    "\n",
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "embedding_layer = Embedding(MAX_NB_WORDS, EMBEDDING_DIM,\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=True)\n",
    "# pretrained_embedding_layer = Embedding(\n",
    "#     MAX_NB_WORDS, EMBEDDING_DIM,\n",
    "#     weights=[embedding_matrix],\n",
    "#     input_length=MAX_SEQUENCE_LENGTH,\n",
    "# )\n",
    "x = embedding_layer(sequence_input)\n",
    "#x = pretrained_embedding_layer(sequence_input)\n",
    "x = Dropout(0.3)(x)\n",
    "# A 1D convolution with 128 output channels\n",
    "x = Conv1D(128, 5, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "# MaxPool divides the length of the sequence by 5\n",
    "x = AveragePooling1D(5)(x)\n",
    "x = Flatten()(x)\n",
    "# A 1D convolution with 64 output channels\n",
    "#activity_regularizer=keras.regularizers.l2(0.001)\n",
    "#x = Conv1D(32, 5, activation='relu')(x)\n",
    "x = Dense(1000, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(400, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "# MaxPool divides the length of the sequence by 5\n",
    "#x = MaxPooling1D(5)(x)\n",
    "#x = LSTM(64)(x)\n",
    "#x = Flatten()(x)\n",
    "\n",
    "x = Dense(188, activation='softmax')(x)\n",
    "\n",
    "model = Model(sequence_input, x)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 211, 64)           7164544   \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 205, 32)           14368     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 41, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 35, 32)            7200      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 188)               6204      \n",
      "=================================================================\n",
      "Total params: 7,192,316\n",
      "Trainable params: 7,192,316\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.optimizers import RMSprop\n",
    "model = Sequential()\n",
    "#model.add(pretrained_embedding_layer)\n",
    "model.add(layers.Embedding(MAX_NB_WORDS, 64, input_length=MAX_SEQUENCE_LENGTH))\n",
    "model.add(layers.Conv1D(32, 7, activation='relu'))\n",
    "model.add(layers.MaxPooling1D(5))\n",
    "model.add(layers.Conv1D(32, 7, activation='relu'))\n",
    "model.add(layers.GlobalMaxPooling1D())\n",
    "model.add(Dense(188, activation='softmax'))\n",
    "#model.add(layers.Dense(1))\n",
    "model.summary()\n",
    "model.compile(optimizer=RMSprop(lr=1e-4),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 38723 samples, validate on 4303 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[128,32,41,1] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node max_pooling1d_6/MaxPool}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node metrics_5/acc/Mean}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-1b1668c0d6af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                     validation_split=0.1)\n\u001b[0m",
      "\u001b[0;32m~/.virtualenvs/nlp/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/.virtualenvs/nlp/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/nlp/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/nlp/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/nlp/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/nlp/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    529\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[128,32,41,1] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node max_pooling1d_6/MaxPool}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node metrics_5/acc/Mean}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=128,\n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_test = model.predict(x_test)\n",
    "predicted_topics = np.argmax(output_test, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: 0.46832971800433837\n"
     ]
    }
   ],
   "source": [
    "print(\"test accuracy:\", np.mean(predicted_topics == test_topic_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.56      0.54       336\n",
      "           1       0.85      0.40      0.54        43\n",
      "           2       0.44      0.42      0.43        76\n",
      "           3       0.33      0.17      0.23        46\n",
      "           4       0.40      0.08      0.13        25\n",
      "           5       0.44      0.56      0.49       114\n",
      "           6       0.30      0.25      0.27       142\n",
      "           7       0.35      0.46      0.40        50\n",
      "           8       0.45      0.52      0.48        29\n",
      "           9       0.37      0.28      0.32        25\n",
      "          10       0.66      0.53      0.59       159\n",
      "          11       0.17      0.09      0.12        34\n",
      "          12       0.22      0.33      0.26        21\n",
      "          13       0.33      0.39      0.36        33\n",
      "          14       0.23      0.22      0.23        78\n",
      "          15       0.22      0.31      0.26        13\n",
      "          16       0.55      0.43      0.48       128\n",
      "          17       0.00      0.00      0.00        12\n",
      "          18       0.37      0.33      0.35        60\n",
      "          19       0.21      0.20      0.21        20\n",
      "          20       0.04      0.07      0.05        14\n",
      "          21       0.21      0.17      0.19        18\n",
      "          22       0.43      0.37      0.39       189\n",
      "          23       0.66      0.53      0.59        66\n",
      "          24       0.50      0.40      0.44        43\n",
      "          25       0.31      0.50      0.38        18\n",
      "          26       0.10      0.09      0.09        23\n",
      "          27       0.69      0.55      0.61       956\n",
      "          28       0.48      0.37      0.42        57\n",
      "          29       0.24      0.19      0.21        67\n",
      "          30       0.24      0.20      0.21        41\n",
      "          31       0.11      0.11      0.11        27\n",
      "          32       0.66      0.65      0.66        98\n",
      "          33       0.66      0.61      0.63       127\n",
      "          34       0.41      0.39      0.40        41\n",
      "          35       0.26      0.25      0.26        36\n",
      "          36       0.35      0.27      0.30        49\n",
      "          37       0.04      0.03      0.03        40\n",
      "          38       0.39      0.36      0.37        45\n",
      "          39       0.41      0.40      0.41        40\n",
      "          40       0.46      0.53      0.49       120\n",
      "          41       0.44      0.43      0.44       150\n",
      "          42       0.58      0.60      0.59        62\n",
      "          43       0.23      0.29      0.26        34\n",
      "          44       0.14      0.21      0.17        28\n",
      "          45       0.41      0.24      0.30        79\n",
      "          46       0.34      0.46      0.39        63\n",
      "          47       0.24      0.19      0.21        21\n",
      "          48       0.03      0.06      0.04        16\n",
      "          49       0.50      0.24      0.32        17\n",
      "          50       0.30      0.40      0.34        45\n",
      "          51       0.22      0.09      0.12        23\n",
      "          52       0.21      0.22      0.22        32\n",
      "          53       0.32      0.53      0.40        45\n",
      "          54       0.09      0.25      0.13        12\n",
      "          55       0.18      0.21      0.19        24\n",
      "          56       0.38      0.36      0.37        28\n",
      "          57       0.60      0.47      0.53       116\n",
      "          58       0.61      0.56      0.58       362\n",
      "          59       0.23      0.27      0.25        77\n",
      "          60       0.24      0.31      0.27        36\n",
      "          61       0.15      0.22      0.18        23\n",
      "          62       0.41      0.21      0.28        90\n",
      "          63       0.33      0.20      0.25        20\n",
      "          64       0.65      0.41      0.51        41\n",
      "          65       0.26      0.36      0.30        14\n",
      "          66       0.25      0.17      0.20        29\n",
      "          67       0.54      0.53      0.54       591\n",
      "          68       0.50      0.53      0.52       192\n",
      "          69       0.22      0.39      0.28       101\n",
      "          70       0.40      0.32      0.36        31\n",
      "          71       0.41      0.34      0.37        56\n",
      "          72       0.20      0.19      0.20        31\n",
      "          73       0.40      0.32      0.36        37\n",
      "          74       0.80      0.89      0.84        85\n",
      "          75       0.55      0.62      0.58        29\n",
      "          76       0.56      0.47      0.51        40\n",
      "          77       0.34      0.38      0.36        39\n",
      "          78       0.33      0.40      0.36        99\n",
      "          79       0.43      0.44      0.43       390\n",
      "          80       0.30      0.17      0.21        18\n",
      "          81       0.62      0.42      0.50        38\n",
      "          82       0.07      0.08      0.07        13\n",
      "          83       0.43      0.27      0.33        22\n",
      "          84       0.19      0.22      0.20        50\n",
      "          85       0.33      0.23      0.27        31\n",
      "          86       0.34      0.45      0.39        75\n",
      "          87       0.18      0.33      0.23        33\n",
      "          88       0.57      0.42      0.48       324\n",
      "          89       0.52      0.43      0.47        37\n",
      "          90       0.00      0.00      0.00        10\n",
      "          91       0.28      0.11      0.16        44\n",
      "          92       0.25      0.24      0.24        25\n",
      "          93       0.71      0.67      0.69        18\n",
      "          94       0.05      0.06      0.05        18\n",
      "          95       0.26      0.26      0.26        34\n",
      "          96       0.43      0.39      0.41        23\n",
      "          97       0.90      0.33      0.49        27\n",
      "          98       0.40      0.17      0.24        23\n",
      "          99       0.38      0.54      0.44        28\n",
      "         100       0.21      0.20      0.20        56\n",
      "         101       0.49      0.40      0.44       334\n",
      "         102       0.75      0.67      0.71        86\n",
      "         103       0.30      0.28      0.29        25\n",
      "         104       0.81      0.35      0.49        37\n",
      "         105       0.21      0.29      0.24        91\n",
      "         106       0.10      0.18      0.13        44\n",
      "         107       0.15      0.10      0.12        29\n",
      "         108       0.25      0.25      0.25        16\n",
      "         109       0.37      0.37      0.37       145\n",
      "         110       0.24      0.29      0.26        73\n",
      "         111       0.60      0.38      0.46        24\n",
      "         112       0.51      0.58      0.54        93\n",
      "         113       0.28      0.50      0.36        40\n",
      "         114       0.55      0.45      0.50       138\n",
      "         115       0.07      0.04      0.05        24\n",
      "         116       0.65      0.42      0.51       129\n",
      "         117       0.08      0.10      0.09        79\n",
      "         118       0.35      0.12      0.18        49\n",
      "         119       0.34      0.24      0.28        46\n",
      "         120       0.18      0.12      0.15        16\n",
      "         121       0.51      0.60      0.55       381\n",
      "         122       0.46      0.32      0.37        38\n",
      "         123       0.25      0.30      0.27        66\n",
      "         124       0.30      0.11      0.16        27\n",
      "         125       0.20      0.08      0.12        72\n",
      "         126       0.35      0.38      0.36        16\n",
      "         127       0.70      0.64      0.67       687\n",
      "         128       0.24      0.33      0.28        73\n",
      "         129       0.35      0.25      0.29        24\n",
      "         130       0.11      0.07      0.08        15\n",
      "         131       0.22      0.18      0.20       131\n",
      "         132       0.27      0.29      0.28        42\n",
      "         133       0.22      0.17      0.19        59\n",
      "         134       0.50      0.37      0.42        65\n",
      "         135       0.17      0.17      0.17        63\n",
      "         136       0.54      0.53      0.54       103\n",
      "         137       0.58      0.38      0.46        55\n",
      "         138       0.52      0.83      0.64      1882\n",
      "         139       0.61      0.39      0.47        70\n",
      "         140       0.10      0.24      0.14        17\n",
      "         141       0.14      0.33      0.20        21\n",
      "         142       0.14      0.08      0.10        13\n",
      "         143       0.26      0.30      0.28       298\n",
      "         144       0.20      0.21      0.21        38\n",
      "         145       0.39      0.52      0.44        75\n",
      "         146       0.20      0.16      0.18        19\n",
      "         147       0.14      0.09      0.11        32\n",
      "         148       0.39      0.38      0.39       192\n",
      "         149       0.00      0.00      0.00        18\n",
      "         150       0.36      0.15      0.21        67\n",
      "         151       0.41      0.37      0.39        19\n",
      "         152       0.33      0.23      0.27        22\n",
      "         153       0.17      0.21      0.19        24\n",
      "         154       0.58      0.62      0.60       135\n",
      "         155       0.51      0.41      0.46       374\n",
      "         156       0.26      0.20      0.22        61\n",
      "         157       0.14      0.20      0.17        20\n",
      "         158       0.33      0.38      0.36        42\n",
      "         159       0.36      0.45      0.40        22\n",
      "         160       0.22      0.18      0.20        38\n",
      "         161       0.53      0.32      0.40       256\n",
      "         162       0.30      0.29      0.30        24\n",
      "         163       0.43      0.50      0.46        18\n",
      "         164       0.45      0.38      0.41       165\n",
      "         165       0.40      0.40      0.40        60\n",
      "         166       0.26      0.33      0.29        72\n",
      "         167       0.69      0.62      0.65        56\n",
      "         168       0.39      0.22      0.28       104\n",
      "         169       0.54      0.55      0.55        38\n",
      "         170       0.36      0.54      0.43        24\n",
      "         171       0.42      0.34      0.38       228\n",
      "         172       0.08      0.14      0.10        22\n",
      "         173       0.64      0.57      0.60       244\n",
      "         174       0.50      0.40      0.44       181\n",
      "         175       0.15      0.11      0.12        56\n",
      "         176       0.59      0.41      0.48       226\n",
      "         177       0.18      0.19      0.19        31\n",
      "         178       0.58      0.63      0.60       186\n",
      "         179       0.31      0.26      0.28        35\n",
      "         180       0.61      0.57      0.59      1078\n",
      "         181       0.39      0.34      0.36       192\n",
      "         182       0.30      0.48      0.37        21\n",
      "         183       0.60      0.44      0.50       362\n",
      "         184       0.38      0.43      0.40        14\n",
      "         185       0.15      0.09      0.11        35\n",
      "         186       0.33      0.44      0.38        39\n",
      "         187       0.42      0.40      0.41        25\n",
      "\n",
      "   micro avg       0.47      0.47      0.47     18440\n",
      "   macro avg       0.36      0.33      0.33     18440\n",
      "weighted avg       0.48      0.47      0.46     18440\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_topic_labels, predicted_topics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
