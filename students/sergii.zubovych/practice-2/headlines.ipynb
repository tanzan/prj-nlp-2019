{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "labeled_corpus = []\n",
    "with open('mds/headlines_corpus.txt') as corpus:\n",
    "    for line in corpus:\n",
    "        if re.match(r'^\\#+\\s+\\w+', line):\n",
    "            labeled_corpus.append((line, True))\n",
    "        elif line.strip():\n",
    "            labeled_corpus.append((line, False))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('# Awesome WAF [![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg \"Awesome\")](https://github.com/0xinfection/awesome-waf)\\n',\n",
       "  True),\n",
       " ('### Contents:\\n', True),\n",
       " ('## Introduction:\\n', True),\n",
       " ('### How WAFs Work:\\n', True),\n",
       " ('### Operation Modes:\\n', True),\n",
       " ('## Testing Methodology:\\n', True),\n",
       " ('### Where To Look:\\n', True),\n",
       " ('### Detection Techniques:\\n', True),\n",
       " ('## WAF Fingerprints\\n', True),\n",
       " ('## Evasion Techniques\\n', True),\n",
       " ('### Fuzzing/Bruteforcing:\\n', True),\n",
       " ('#### Method:  \\n', True),\n",
       " ('#### Technique:\\n', True),\n",
       " ('#### Drawbacks:\\n', True),\n",
       " ('### Regex-Reversing:\\n', True),\n",
       " ('#### Method:\\n', True),\n",
       " ('#### Techniques:\\n', True),\n",
       " ('### Keyword Filter Detection/Bypass\\n', True),\n",
       " ('### Obfuscation:\\n', True),\n",
       " ('#### Method:\\n', True),\n",
       " ('#### Techniques:\\n', True),\n",
       " ('### Browser Bugs:\\n', True),\n",
       " ('#### Charset Bugs:\\n', True),\n",
       " ('#### Null Bytes:\\n', True),\n",
       " ('#### Parsing Bugs:\\n', True),\n",
       " ('#### Unicode Separators:\\n', True),\n",
       " ('### Request Header Spoofing:\\n', True),\n",
       " ('#### Method:\\n', True),\n",
       " ('#### Technique:\\n', True),\n",
       " ('### Google Dorks Approach:\\n', True),\n",
       " ('#### Method:\\n', True),\n",
       " ('#### Techniques:  \\n', True),\n",
       " ('## Known Bypasses:\\n', True),\n",
       " ('### Airlock Ergon\\n', True),\n",
       " ('### AWS\\n', True),\n",
       " ('### Barracuda \\n', True),\n",
       " ('### Cerber (WordPress)\\n', True),\n",
       " ('### Citrix NetScaler\\n', True),\n",
       " ('### Cloudflare\\n', True),\n",
       " ('### Comodo \\n', True),\n",
       " ('### DotDefender\\n', True),\n",
       " ('### Fortinet Fortiweb\\n', True),\n",
       " ('### F5 ASM \\n', True),\n",
       " ('### F5 BIG-IP\\n', True),\n",
       " ('### F5 FirePass\\n', True),\n",
       " ('### Imperva SecureSphere\\n', True),\n",
       " ('### Kona SiteDefender\\n', True),\n",
       " ('### Profense\\n', True),\n",
       " ('### QuickDefense\\n', True),\n",
       " ('### WebKnight\\n', True),\n",
       " ('### Wordfence\\n', True),\n",
       " ('### Apache Generic\\n', True),\n",
       " ('### IIS Generic\\n', True),\n",
       " ('## Awesome Tools\\n', True),\n",
       " ('### Fingerprinting:\\n', True),\n",
       " ('### Testing:\\n', True),\n",
       " ('### Evasion:  \\n', True),\n",
       " ('## Blogs and Writeups\\n', True),\n",
       " ('## Video Presentations\\n', True),\n",
       " ('## Presentations & Research Papers\\n', True),\n",
       " ('### Research Papers:\\n', True),\n",
       " ('### Presentations:\\n', True),\n",
       " ('## Credits & License:\\n', True),\n",
       " ('# IntruderPayloads\\n', True),\n",
       " ('## LICENSE:\\n', True),\n",
       " ('## DONATIONS:\\n', True),\n",
       " ('## PENTEST METHODOLOGY v2.0\\n', True),\n",
       " ('### BASIC PASSIVE AND ACTIVE CHECKS:\\n', True),\n",
       " ('### ENUMERATION:\\n', True),\n",
       " ('### VECTORS:\\n', True),\n",
       " ('### SEARCH STRINGS:\\n', True),\n",
       " ('### QUICK ATTACK STRINGS:\\n', True),\n",
       " ('### OWASP TESTING CHECKLIST:\\n', True),\n",
       " ('### LOW SEVERITY:\\n', True),\n",
       " ('# ia-3B5\\n', True),\n",
       " ('## Module 3\\n', True),\n",
       " ('## Team members:\\n', True),\n",
       " ('## Submodules:\\n', True),\n",
       " ('## Resources and tehnologies:\\n', True),\n",
       " ('## Useful Links\\n', True),\n",
       " ('## 皮皮书屋电驴下载资源 \\n', True),\n",
       " ('## 皮皮书屋电驴下载资源 \\n', True),\n",
       " ('## 皮皮书屋电驴下载资源 \\n', True),\n",
       " ('## 皮皮书屋电驴下载资源 \\n', True),\n",
       " ('## 皮皮书屋电驴下载资源 \\n', True),\n",
       " ('## 皮皮书屋电驴下载资源 \\n', True),\n",
       " ('## 皮皮书屋电驴下载资源 \\n', True),\n",
       " ('## 皮皮书屋电驴下载资源 \\n', True),\n",
       " ('# Keyword Spotting on Arm Cortex-M boards.\\n', True),\n",
       " ('## Get the CMSIS-NN library and install mbed-cli\\n', True),\n",
       " ('## Build and run a simple KWS inference \\n', True),\n",
       " ('## Run KWS inference on live audio on [STM32F746NG development kit](http://www.st.com/en/evaluation-tools/32f746gdiscovery.html)\\n',\n",
       "  True),\n",
       " ('## Build an example on [FRDM-K64F](https://os.mbed.com/platforms/FRDM-K64F/) using gcc and make\\n',\n",
       "  True),\n",
       " ('# Clone CMSIS_5 repository (if not done already)\\n', True),\n",
       " ('# copy binary to the device\\n', True),\n",
       " ('# Contribution Guidelines\\n', True),\n",
       " ('## Code of conduct\\n', True),\n",
       " ('## Guidelines\\n', True),\n",
       " ('## Adding content to this awesome list (Pull Request)\\n', True),\n",
       " ('## If we ask you to update your Pull Request\\n', True)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(filter(lambda e: e[1],labeled_corpus))[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146202\n",
      "62658\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random.shuffle(labeled_corpus)\n",
    "\n",
    "train_idx = int(len(labeled_corpus) * 0.7)\n",
    "train_data = labeled_corpus[:train_idx]\n",
    "test_data = labeled_corpus[train_idx:]\n",
    "\n",
    "headlines = list(filter(lambda h: h[1], train_data))\n",
    "non_headlines = list(filter(lambda h: not h[1], train_data))\n",
    "\n",
    "print(len(train_data))\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_by_words(entry):\n",
    "    words = list(filter(lambda w: len(w.strip()) > 0, entry[0].split(' ')))\n",
    "    if entry[1]:\n",
    "        return words[1:]\n",
    "    return words\n",
    "\n",
    "def isCapitalized(words):\n",
    "    return words[0].istitle()\n",
    "\n",
    "\n",
    "def num_words_lt_15(words):\n",
    "    return len(words) < 15\n",
    "\n",
    "def all_alpha(words):\n",
    "    for w in words:\n",
    "        if not re.match('[a-zA-Z0-9\\-\\:\\?\\!\\)\\)]', w):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def num_of_capitalized(words):\n",
    "    n = 0\n",
    "    for w in words:\n",
    "\n",
    "        if w.istitle():\n",
    "            n +=1\n",
    "    return n        \n",
    "\n",
    "\n",
    "ws = split_by_words(non_headlines[1])\n",
    "\n",
    "print(isCapitalized(ws))\n",
    "print(num_words_lt_15(ws))\n",
    "print(all_alpha(split_by_words(\"DFf adas df-sf 1!\")))\n",
    "num_of_capitalized(split_by_words((\"Ddfa adas df-sf 1!\", False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "vdata = []\n",
    "ldata = []\n",
    "\n",
    "def feature_vector(e):\n",
    "    ws = split_by_words(e)\n",
    "    return [int(isCapitalized(ws)), len(ws), all_alpha(ws), num_of_capitalized(ws)]\n",
    "    #return [int(isCapitalized(ws)), len(ws), all_alpha(ws)]\n",
    "\n",
    "for e in train_data:\n",
    "    vdata.append(feature_vector(e))\n",
    "    ldata.append(e[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, False, False, False, False, False, False, True, False, False]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vdata[:10]\n",
    "ldata[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(vdata, ldata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "vtdata = []\n",
    "ltdata = []\n",
    "pdata = []\n",
    "\n",
    "for e in train_data:\n",
    "    vtdata.append(feature_vector(e))\n",
    "    ltdata.append(e[1])\n",
    "    \n",
    "pdata = clf.predict(vtdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 4, False], [0, 9, False], [0, 1, False], [0, 52, False], [1, 5, False], [1, 63, False], [1, 4, False], [1, 1, True], [0, 2, False], [0, 4, False]]\n",
      "[False False False False False False False  True False False]\n",
      "[True, False, False, False, False, False, False, True, False, False]\n"
     ]
    }
   ],
   "source": [
    "print(vtdata[:10])\n",
    "print(pdata[:10])\n",
    "print(ltdata[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4803 1660 4465 135274\n",
      "Accuracy: 0.9581059082639088\n",
      "Precicison: 0.7431533343648461\n",
      "Recall: 0.5182347863616745\n",
      "F1: 0.6106414086834913\n"
     ]
    }
   ],
   "source": [
    "tp = 0\n",
    "tn = 0\n",
    "fp = 0\n",
    "fn = 0\n",
    "\n",
    "for i in range(len(vtdata)):\n",
    "    if pdata[i] and ldata[i]:\n",
    "        tp += 1\n",
    "    elif pdata[i] and not ldata[i]:\n",
    "        fp += 1\n",
    "    elif not pdata[i] and ldata[i]:\n",
    "        fn += 1\n",
    "    else:\n",
    "        tn += 1\n",
    "\n",
    "print(tp, fp, fn, tn)        \n",
    "\n",
    "pr = tp/(tp + fp)\n",
    "rc = tp/(tp + fn)\n",
    "f1 = 2 * (pr * rc)/(pr + rc)\n",
    "\n",
    "print(\"Accuracy: {}\".format((tp + tn)/len(ldata)))\n",
    "print(\"Precicison: {}\".format(pr))\n",
    "print(\"Recall: {}\".format(rc))\n",
    "print(\"F1: {}\".format(f1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
